{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet essai on va utiliser chaque capteur à part entière et ensuite classer suivant chaque capteur et par la suite voir quels sont les capteurs qui classent le mieux suivant nos 4 classes et puis tenter un vote entre les différents capteurs.\n",
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_air = pd.read_csv('./csv_files/AIR.csv', sep=\";\", header=None)\n",
    "data_control = pd.read_csv('./csv_files/CONTROL.csv', sep=\";\", header=None)\n",
    "data_copd = pd.read_csv('./csv_files/COPD.csv', sep=\";\", header=None)\n",
    "data_smokers = pd.read_csv('./csv_files/SMOKERS.csv', sep=\";\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smokers.drop(list(range(64,128)), inplace=True, axis=1)\n",
    "data_air.drop(list(range(4000,4080)), inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "On va prendre pour chaque datasets chaque capteurs à part entière"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_capteur(data, samples) :\n",
    "    data_capteur1 = []\n",
    "    data_capteur2 = []\n",
    "    data_capteur3 = []\n",
    "    data_capteur4 = []\n",
    "    data_capteur5 = []\n",
    "    data_capteur6 = []\n",
    "    data_capteur7 = []\n",
    "    data_capteur8 = []\n",
    "    for i in range(8) :\n",
    "        for j in range(0,samples) :\n",
    "            if i==0 : \n",
    "                data_capteur1.append(list(data[8*j]))\n",
    "            elif i==1 :\n",
    "                data_capteur2.append(list(data[i + 8*j]))\n",
    "            elif i==2 :\n",
    "                data_capteur3.append(list(data[i + 8*j]))\n",
    "            elif i==3 :\n",
    "                data_capteur4.append(list(data[i + 8*j]))\n",
    "            elif i==4 :\n",
    "                data_capteur5.append(list(data[i + 8*j]))\n",
    "            elif i==5 :\n",
    "                data_capteur6.append(list(data[i + 8*j]))\n",
    "            elif i==6 :\n",
    "                data_capteur7.append(list(data[i + 8*j]))\n",
    "            elif i==7 :\n",
    "                data_capteur8.append(list(data[i + 8*j]))\n",
    "    return pd.DataFrame(data_capteur1),pd.DataFrame(data_capteur2),pd.DataFrame(data_capteur3),pd.DataFrame(data_capteur4),pd.DataFrame(data_capteur5),pd.DataFrame(data_capteur6),pd.DataFrame(data_capteur7),pd.DataFrame(data_capteur8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capteur1_smoker, data_capteur2_smoker, data_capteur3_smoker, data_capteur4_smoker, data_capteur5_smoker, data_capteur6_smoker, data_capteur7_smoker, data_capteur8_smoker = extract_capteur(data_smokers, 8)\n",
    "\n",
    "data_capteur1_copd, data_capteur2_copd, data_capteur3_copd, data_capteur4_copd, data_capteur5_copd, data_capteur6_copd, data_capteur7_copd, data_capteur8_copd = extract_capteur(data_copd, 40)\n",
    "\n",
    "data_capteur1_control, data_capteur2_control, data_capteur3_control, data_capteur4_control, data_capteur5_control, data_capteur6_control, data_capteur7_control, data_capteur8_control = extract_capteur(data_control, 20)\n",
    "\n",
    "data_capteur1_air, data_capteur2_air, data_capteur3_air, data_capteur4_air, data_capteur5_air, data_capteur6_air, data_capteur7_air, data_capteur8_air = extract_capteur(data_air, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède maintenant à la concaténation des données pour avoir 8 datasets distincts. Mais avant cela on passe à la labelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(data_capteur1,data_capteur2,data_capteur3,data_capteur4,data_capteur5,data_capteur6,data_capteur7,data_capteur8, label) :\n",
    "    data_capteur1.insert(4000,\"class\",label)\n",
    "    data_capteur2.insert(4000,\"class\",label)\n",
    "    data_capteur3.insert(4000,\"class\",label)\n",
    "    data_capteur4.insert(4000,\"class\",label)\n",
    "    data_capteur5.insert(4000,\"class\",label)\n",
    "    data_capteur6.insert(4000,\"class\",label)\n",
    "    data_capteur7.insert(4000,\"class\",label)\n",
    "    data_capteur8.insert(4000,\"class\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label(data_capteur1_smoker,data_capteur2_smoker,data_capteur3_smoker,data_capteur4_smoker,data_capteur5_smoker,data_capteur6_smoker,data_capteur7_smoker,data_capteur8_smoker, \"smoker\")\n",
    "\n",
    "label(data_capteur1_copd,data_capteur2_copd,data_capteur3_copd,data_capteur4_copd,data_capteur5_copd,data_capteur6_copd,data_capteur7_copd,data_capteur8_copd, \"copd\")\n",
    "\n",
    "label(data_capteur1_control,data_capteur2_control,data_capteur3_control,data_capteur4_control,data_capteur5_control,data_capteur6_control,data_capteur7_control,data_capteur8_control, \"control\")\n",
    "\n",
    "label(data_capteur1_air,data_capteur2_air,data_capteur3_air,data_capteur4_air,data_capteur5_air,data_capteur6_air,data_capteur7_air,data_capteur8_air, \"air\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capteur1 = pd.concat([data_capteur1_smoker,data_capteur1_copd, data_capteur1_control, data_capteur1_air])\n",
    "\n",
    "data_capteur2 = pd.concat([data_capteur2_smoker,data_capteur2_copd, data_capteur2_control, data_capteur2_air])\n",
    "\n",
    "data_capteur3 = pd.concat([data_capteur3_smoker,data_capteur3_copd, data_capteur3_control, data_capteur3_air])\n",
    "\n",
    "data_capteur4 = pd.concat([data_capteur4_smoker,data_capteur4_copd, data_capteur4_control, data_capteur4_air])\n",
    "\n",
    "data_capteur5 = pd.concat([data_capteur5_smoker,data_capteur5_copd, data_capteur5_control, data_capteur5_air])\n",
    "\n",
    "data_capteur6 = pd.concat([data_capteur6_smoker,data_capteur6_copd, data_capteur6_control, data_capteur6_air])\n",
    "\n",
    "data_capteur7 = pd.concat([data_capteur7_smoker,data_capteur7_copd, data_capteur7_control, data_capteur7_air])\n",
    "\n",
    "data_capteur8 = pd.concat([data_capteur8_smoker,data_capteur8_copd, data_capteur8_control, data_capteur8_air])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des datasets\n",
    "On sauvegarde les datasets pour une utilisation future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
