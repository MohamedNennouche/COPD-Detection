{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For data preparation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsaug.visualization import plot\n",
    "from tsaug import TimeWarp, Drift, AddNoise\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# For Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPool1D, GlobalAvgPool1D, Conv1D, Dropout, BatchNormalization\n",
    "\n",
    "# for callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0   0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  ...   \n",
       "1   0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  ...   \n",
       "2   0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  ...   \n",
       "3   0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  ...   \n",
       "4   0.311  0.311  0.310  0.310  0.311  0.311  0.311  0.311  0.310  0.310  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "73  0.534  0.534  0.534  0.533  0.534  0.534  0.534  0.534  0.534  0.534  ...   \n",
       "74  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  ...   \n",
       "75  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  ...   \n",
       "76  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  ...   \n",
       "77  0.499  0.498  0.498  0.500  0.501  0.500  0.499  0.498  0.498  0.500  ...   \n",
       "\n",
       "     3990   3991   3992   3993   3994   3995   3996   3997   3998   3999  \n",
       "0   0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  \n",
       "1   0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  \n",
       "2   0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  \n",
       "3   0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  \n",
       "4   0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "73  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  \n",
       "74  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  \n",
       "75  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  \n",
       "76  0.533  0.533  0.534  0.534  0.533  0.533  0.532  0.533  0.534  0.534  \n",
       "77  0.537  0.536  0.536  0.538  0.538  0.538  0.537  0.536  0.536  0.537  \n",
       "\n",
       "[78 rows x 4000 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur = pd.read_csv('./capteurs/capteur1.csv')\n",
    "moncapteur.drop(['class'], inplace=True, axis=1)\n",
    "moncapteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_augmentor(data, min_drift=0.01, max_drift=0.5, noise_scale=0.01) :\n",
    "    aug = list()\n",
    "    data_np = data.to_numpy()\n",
    "    my_augmenter = (\n",
    "    TimeWarp() * 9  # random time warping 5 times in parallel\n",
    "    + Drift(max_drift=(min_drift, max_drift), normalize=False) @ 0.8  # with 80% probability, random drift the signal up to 10% - 50%\n",
    "    + AddNoise(scale = noise_scale, normalize=False)\n",
    "    )\n",
    "    for i in range(len(data_np)) :\n",
    "        data_aug = my_augmenter.augment(data_np[i])\n",
    "        aug.append(data_np[i])\n",
    "        for j in range(len(data_aug)) :\n",
    "            aug.append(data_aug[j])\n",
    "    aug = pd.DataFrame(np.array(aug))\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.369714</td>\n",
       "      <td>0.361276</td>\n",
       "      <td>0.345816</td>\n",
       "      <td>0.367791</td>\n",
       "      <td>0.360672</td>\n",
       "      <td>0.367356</td>\n",
       "      <td>0.372397</td>\n",
       "      <td>0.357874</td>\n",
       "      <td>0.360182</td>\n",
       "      <td>0.357883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531677</td>\n",
       "      <td>0.523764</td>\n",
       "      <td>0.521768</td>\n",
       "      <td>0.508339</td>\n",
       "      <td>0.502464</td>\n",
       "      <td>0.519459</td>\n",
       "      <td>0.519373</td>\n",
       "      <td>0.504260</td>\n",
       "      <td>0.509974</td>\n",
       "      <td>0.516243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.374986</td>\n",
       "      <td>0.365697</td>\n",
       "      <td>0.369180</td>\n",
       "      <td>0.351559</td>\n",
       "      <td>0.356612</td>\n",
       "      <td>0.357425</td>\n",
       "      <td>0.352256</td>\n",
       "      <td>0.389227</td>\n",
       "      <td>0.357649</td>\n",
       "      <td>0.343118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502479</td>\n",
       "      <td>0.497114</td>\n",
       "      <td>0.493239</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.493973</td>\n",
       "      <td>0.506169</td>\n",
       "      <td>0.492655</td>\n",
       "      <td>0.485949</td>\n",
       "      <td>0.501487</td>\n",
       "      <td>0.498655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383010</td>\n",
       "      <td>0.356574</td>\n",
       "      <td>0.357441</td>\n",
       "      <td>0.378211</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.348418</td>\n",
       "      <td>0.366246</td>\n",
       "      <td>0.346355</td>\n",
       "      <td>0.382340</td>\n",
       "      <td>0.385788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552711</td>\n",
       "      <td>0.565801</td>\n",
       "      <td>0.568132</td>\n",
       "      <td>0.574477</td>\n",
       "      <td>0.576833</td>\n",
       "      <td>0.554762</td>\n",
       "      <td>0.560810</td>\n",
       "      <td>0.558128</td>\n",
       "      <td>0.550884</td>\n",
       "      <td>0.553367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.358807</td>\n",
       "      <td>0.356505</td>\n",
       "      <td>0.345976</td>\n",
       "      <td>0.373369</td>\n",
       "      <td>0.345949</td>\n",
       "      <td>0.355188</td>\n",
       "      <td>0.360137</td>\n",
       "      <td>0.350247</td>\n",
       "      <td>0.359759</td>\n",
       "      <td>0.375290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654881</td>\n",
       "      <td>0.678361</td>\n",
       "      <td>0.678024</td>\n",
       "      <td>0.657965</td>\n",
       "      <td>0.659863</td>\n",
       "      <td>0.675613</td>\n",
       "      <td>0.666951</td>\n",
       "      <td>0.662598</td>\n",
       "      <td>0.670446</td>\n",
       "      <td>0.660086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.493510</td>\n",
       "      <td>0.507030</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.490276</td>\n",
       "      <td>0.489990</td>\n",
       "      <td>0.497902</td>\n",
       "      <td>0.515172</td>\n",
       "      <td>0.506406</td>\n",
       "      <td>0.505061</td>\n",
       "      <td>0.518358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776343</td>\n",
       "      <td>0.769559</td>\n",
       "      <td>0.775962</td>\n",
       "      <td>0.783777</td>\n",
       "      <td>0.774009</td>\n",
       "      <td>0.762631</td>\n",
       "      <td>0.757028</td>\n",
       "      <td>0.760280</td>\n",
       "      <td>0.782288</td>\n",
       "      <td>0.772169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.502150</td>\n",
       "      <td>0.501704</td>\n",
       "      <td>0.501294</td>\n",
       "      <td>0.499839</td>\n",
       "      <td>0.507675</td>\n",
       "      <td>0.506450</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>0.493972</td>\n",
       "      <td>0.495685</td>\n",
       "      <td>0.491438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973715</td>\n",
       "      <td>0.979150</td>\n",
       "      <td>0.965004</td>\n",
       "      <td>0.980488</td>\n",
       "      <td>0.962086</td>\n",
       "      <td>0.992629</td>\n",
       "      <td>0.961087</td>\n",
       "      <td>0.976360</td>\n",
       "      <td>0.985664</td>\n",
       "      <td>1.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.498274</td>\n",
       "      <td>0.489916</td>\n",
       "      <td>0.488637</td>\n",
       "      <td>0.507562</td>\n",
       "      <td>0.502973</td>\n",
       "      <td>0.498603</td>\n",
       "      <td>0.484972</td>\n",
       "      <td>0.503714</td>\n",
       "      <td>0.513439</td>\n",
       "      <td>0.503050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547671</td>\n",
       "      <td>0.532184</td>\n",
       "      <td>0.550577</td>\n",
       "      <td>0.535320</td>\n",
       "      <td>0.540899</td>\n",
       "      <td>0.542471</td>\n",
       "      <td>0.532826</td>\n",
       "      <td>0.543223</td>\n",
       "      <td>0.542971</td>\n",
       "      <td>0.526953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.497356</td>\n",
       "      <td>0.481382</td>\n",
       "      <td>0.494537</td>\n",
       "      <td>0.490077</td>\n",
       "      <td>0.506484</td>\n",
       "      <td>0.493487</td>\n",
       "      <td>0.505372</td>\n",
       "      <td>0.506151</td>\n",
       "      <td>0.499197</td>\n",
       "      <td>0.478857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093194</td>\n",
       "      <td>0.114108</td>\n",
       "      <td>0.086827</td>\n",
       "      <td>0.105090</td>\n",
       "      <td>0.107040</td>\n",
       "      <td>0.111043</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>0.080957</td>\n",
       "      <td>0.107283</td>\n",
       "      <td>0.102745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.504738</td>\n",
       "      <td>0.502698</td>\n",
       "      <td>0.505745</td>\n",
       "      <td>0.501803</td>\n",
       "      <td>0.504579</td>\n",
       "      <td>0.490243</td>\n",
       "      <td>0.502072</td>\n",
       "      <td>0.505256</td>\n",
       "      <td>0.504156</td>\n",
       "      <td>0.506419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564373</td>\n",
       "      <td>0.564659</td>\n",
       "      <td>0.562438</td>\n",
       "      <td>0.576039</td>\n",
       "      <td>0.573380</td>\n",
       "      <td>0.554136</td>\n",
       "      <td>0.569571</td>\n",
       "      <td>0.569586</td>\n",
       "      <td>0.577486</td>\n",
       "      <td>0.571450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    0.361000  0.361000  0.361000  0.361000  0.361000  0.361000  0.361000   \n",
       "1    0.369714  0.361276  0.345816  0.367791  0.360672  0.367356  0.372397   \n",
       "2    0.374986  0.365697  0.369180  0.351559  0.356612  0.357425  0.352256   \n",
       "3    0.383010  0.356574  0.357441  0.378211  0.362718  0.348418  0.366246   \n",
       "4    0.358807  0.356505  0.345976  0.373369  0.345949  0.355188  0.360137   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "775  0.493510  0.507030  0.508442  0.490276  0.489990  0.497902  0.515172   \n",
       "776  0.502150  0.501704  0.501294  0.499839  0.507675  0.506450  0.506826   \n",
       "777  0.498274  0.489916  0.488637  0.507562  0.502973  0.498603  0.484972   \n",
       "778  0.497356  0.481382  0.494537  0.490077  0.506484  0.493487  0.505372   \n",
       "779  0.504738  0.502698  0.505745  0.501803  0.504579  0.490243  0.502072   \n",
       "\n",
       "         7         8         9     ...      3990      3991      3992  \\\n",
       "0    0.361000  0.361000  0.361000  ...  0.405000  0.405000  0.405000   \n",
       "1    0.357874  0.360182  0.357883  ...  0.531677  0.523764  0.521768   \n",
       "2    0.389227  0.357649  0.343118  ...  0.502479  0.497114  0.493239   \n",
       "3    0.346355  0.382340  0.385788  ...  0.552711  0.565801  0.568132   \n",
       "4    0.350247  0.359759  0.375290  ...  0.654881  0.678361  0.678024   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "775  0.506406  0.505061  0.518358  ...  0.776343  0.769559  0.775962   \n",
       "776  0.493972  0.495685  0.491438  ...  0.973715  0.979150  0.965004   \n",
       "777  0.503714  0.513439  0.503050  ...  0.547671  0.532184  0.550577   \n",
       "778  0.506151  0.499197  0.478857  ...  0.093194  0.114108  0.086827   \n",
       "779  0.505256  0.504156  0.506419  ...  0.564373  0.564659  0.562438   \n",
       "\n",
       "         3993      3994      3995      3996      3997      3998      3999  \n",
       "0    0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  \n",
       "1    0.508339  0.502464  0.519459  0.519373  0.504260  0.509974  0.516243  \n",
       "2    0.519200  0.493973  0.506169  0.492655  0.485949  0.501487  0.498655  \n",
       "3    0.574477  0.576833  0.554762  0.560810  0.558128  0.550884  0.553367  \n",
       "4    0.657965  0.659863  0.675613  0.666951  0.662598  0.670446  0.660086  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "775  0.783777  0.774009  0.762631  0.757028  0.760280  0.782288  0.772169  \n",
       "776  0.980488  0.962086  0.992629  0.961087  0.976360  0.985664  1.003054  \n",
       "777  0.535320  0.540899  0.542471  0.532826  0.543223  0.542971  0.526953  \n",
       "778  0.105090  0.107040  0.111043  0.102222  0.080957  0.107283  0.102745  \n",
       "779  0.576039  0.573380  0.554136  0.569571  0.569586  0.577486  0.571450  \n",
       "\n",
       "[780 rows x 4000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur_aug = sensor_augmentor(moncapteur)\n",
    "moncapteur_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les signaux concaténés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataset(path, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    monDataset = list()\n",
    "    etiq = 0\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            monfichier.reset_index(inplace=True, drop=True)\n",
    "            monDataset.append(monfichier)\n",
    "        else :\n",
    "            monfichier = os.listdir(all_path)\n",
    "            all_path_etiq = os.path.join(all_path,monfichier[0])\n",
    "            etiq = pd.read_csv(all_path_etiq)\n",
    "            etiq[\"class\"] = etiq[\"class\"].astype('category').cat.codes\n",
    "    monDataset = pd.concat(monDataset, axis=1)\n",
    "    fv_train, fv_test, etiq_train, etiq_test = train_test_split(monDataset, etiq, test_size=test_size, random_state=42)\n",
    "    return fv_train, fv_test, etiq_train, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 32000), (24, 32000), (54, 1), (24, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./capteurs\"\n",
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 32000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiq_augmentor(etiq) : \n",
    "    etiq_np = etiq.to_numpy()\n",
    "    etiq_aug = list()\n",
    "    for i in range(len(etiq_np)) :\n",
    "        for j in range(10) :\n",
    "            etiq_aug.append(etiq_np[i])\n",
    "    return pd.DataFrame(etiq_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_train_aug = etiq_augmentor(etiq_train)\n",
    "etiq_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.5255\n",
      "Epoch 1: accuracy improved from -inf to 0.52546, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 59s 529ms/step - loss: 1.2220 - accuracy: 0.5255 - val_loss: 1.2981 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1736 - accuracy: 0.5347\n",
      "Epoch 2: accuracy improved from 0.52546 to 0.53472, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 47s 441ms/step - loss: 1.1736 - accuracy: 0.5347 - val_loss: 1.2628 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6620\n",
      "Epoch 3: accuracy improved from 0.53472 to 0.66204, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 48s 447ms/step - loss: 0.8564 - accuracy: 0.6620 - val_loss: 0.9742 - val_accuracy: 0.5463\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6852\n",
      "Epoch 4: accuracy improved from 0.66204 to 0.68519, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 586ms/step - loss: 0.7615 - accuracy: 0.6852 - val_loss: 0.8974 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7106\n",
      "Epoch 5: accuracy improved from 0.68519 to 0.71065, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 53s 492ms/step - loss: 0.6782 - accuracy: 0.7106 - val_loss: 0.8265 - val_accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.7338\n",
      "Epoch 6: accuracy improved from 0.71065 to 0.73380, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 54s 499ms/step - loss: 0.6749 - accuracy: 0.7338 - val_loss: 0.8168 - val_accuracy: 0.6389\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7222\n",
      "Epoch 7: accuracy did not improve from 0.73380\n",
      "108/108 [==============================] - 52s 486ms/step - loss: 0.6923 - accuracy: 0.7222 - val_loss: 0.8588 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7569\n",
      "Epoch 8: accuracy improved from 0.73380 to 0.75694, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 70s 645ms/step - loss: 0.6460 - accuracy: 0.7569 - val_loss: 0.8738 - val_accuracy: 0.7315\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7106\n",
      "Epoch 9: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 66s 615ms/step - loss: 0.7092 - accuracy: 0.7106 - val_loss: 0.8857 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7500\n",
      "Epoch 10: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 68s 631ms/step - loss: 0.6209 - accuracy: 0.7500 - val_loss: 0.7919 - val_accuracy: 0.6296\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7454\n",
      "Epoch 11: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 635ms/step - loss: 0.6163 - accuracy: 0.7454 - val_loss: 0.8248 - val_accuracy: 0.5648\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7384\n",
      "Epoch 12: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.6250 - accuracy: 0.7384 - val_loss: 0.8651 - val_accuracy: 0.5926\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7315\n",
      "Epoch 13: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 67s 618ms/step - loss: 0.6576 - accuracy: 0.7315 - val_loss: 0.8066 - val_accuracy: 0.6111\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7685\n",
      "Epoch 14: accuracy improved from 0.75694 to 0.76852, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 580ms/step - loss: 0.5973 - accuracy: 0.7685 - val_loss: 0.7505 - val_accuracy: 0.6204\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7338\n",
      "Epoch 15: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 536ms/step - loss: 0.6462 - accuracy: 0.7338 - val_loss: 0.7762 - val_accuracy: 0.6111\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.7315\n",
      "Epoch 16: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 0.7790 - accuracy: 0.7315 - val_loss: 0.7598 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7477\n",
      "Epoch 17: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 63s 583ms/step - loss: 0.6375 - accuracy: 0.7477 - val_loss: 0.7674 - val_accuracy: 0.7685\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7431\n",
      "Epoch 18: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 541ms/step - loss: 0.6131 - accuracy: 0.7431 - val_loss: 0.8928 - val_accuracy: 0.5370\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.7454\n",
      "Epoch 19: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 54s 503ms/step - loss: 0.6195 - accuracy: 0.7454 - val_loss: 0.9111 - val_accuracy: 0.5370\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.7361\n",
      "Epoch 20: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 62s 577ms/step - loss: 1.6257 - accuracy: 0.7361 - val_loss: 0.8013 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.6829\n",
      "Epoch 21: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.7483 - accuracy: 0.6829 - val_loss: 0.7993 - val_accuracy: 0.5833\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7292\n",
      "Epoch 22: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.6588 - accuracy: 0.7292 - val_loss: 0.7822 - val_accuracy: 0.6204\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7523\n",
      "Epoch 23: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 644ms/step - loss: 0.6137 - accuracy: 0.7523 - val_loss: 0.7414 - val_accuracy: 0.6481\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7384\n",
      "Epoch 24: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 68s 626ms/step - loss: 0.6227 - accuracy: 0.7384 - val_loss: 0.7636 - val_accuracy: 0.6019\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7708\n",
      "Epoch 25: accuracy improved from 0.76852 to 0.77083, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 72s 662ms/step - loss: 0.5843 - accuracy: 0.7708 - val_loss: 0.7146 - val_accuracy: 0.6574\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7569\n",
      "Epoch 26: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.5474 - accuracy: 0.7569 - val_loss: 0.7628 - val_accuracy: 0.5741\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7454\n",
      "Epoch 27: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.5668 - accuracy: 0.7454 - val_loss: 0.6763 - val_accuracy: 0.6852\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7708\n",
      "Epoch 28: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 630ms/step - loss: 0.5229 - accuracy: 0.7708 - val_loss: 0.7059 - val_accuracy: 0.6204\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7593\n",
      "Epoch 29: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5250 - accuracy: 0.7593 - val_loss: 0.7393 - val_accuracy: 0.5741\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7569\n",
      "Epoch 30: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 639ms/step - loss: 0.5652 - accuracy: 0.7569 - val_loss: 0.8189 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7639\n",
      "Epoch 31: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 647ms/step - loss: 0.5143 - accuracy: 0.7639 - val_loss: 0.7004 - val_accuracy: 0.6111\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7708\n",
      "Epoch 32: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.6931 - val_accuracy: 0.6019\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7801\n",
      "Epoch 33: accuracy improved from 0.77083 to 0.78009, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 71s 662ms/step - loss: 0.4928 - accuracy: 0.7801 - val_loss: 0.7624 - val_accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7569\n",
      "Epoch 34: accuracy did not improve from 0.78009\n",
      "108/108 [==============================] - 70s 648ms/step - loss: 0.5300 - accuracy: 0.7569 - val_loss: 0.6581 - val_accuracy: 0.6389\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.7917\n",
      "Epoch 35: accuracy improved from 0.78009 to 0.79167, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4880 - accuracy: 0.7917 - val_loss: 0.5843 - val_accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7801\n",
      "Epoch 36: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4671 - accuracy: 0.7801 - val_loss: 0.6422 - val_accuracy: 0.6204\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.7778\n",
      "Epoch 37: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 679ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7940\n",
      "Epoch 38: accuracy improved from 0.79167 to 0.79398, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 79s 728ms/step - loss: 0.4951 - accuracy: 0.7940 - val_loss: 0.6788 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7778\n",
      "Epoch 39: accuracy did not improve from 0.79398\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4953 - accuracy: 0.7778 - val_loss: 0.6452 - val_accuracy: 0.6204\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7963\n",
      "Epoch 40: accuracy improved from 0.79398 to 0.79630, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 78s 725ms/step - loss: 0.4604 - accuracy: 0.7963 - val_loss: 0.5846 - val_accuracy: 0.6944\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7870\n",
      "Epoch 41: accuracy did not improve from 0.79630\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4502 - accuracy: 0.7870 - val_loss: 0.5741 - val_accuracy: 0.7130\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.8079\n",
      "Epoch 42: accuracy improved from 0.79630 to 0.80787, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 77s 716ms/step - loss: 0.4457 - accuracy: 0.8079 - val_loss: 0.5664 - val_accuracy: 0.6574\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7986\n",
      "Epoch 43: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 692ms/step - loss: 0.4567 - accuracy: 0.7986 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7801\n",
      "Epoch 44: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 690ms/step - loss: 0.4811 - accuracy: 0.7801 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7755\n",
      "Epoch 45: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 669ms/step - loss: 0.4563 - accuracy: 0.7755 - val_loss: 0.6284 - val_accuracy: 0.6296\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8056\n",
      "Epoch 46: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 671ms/step - loss: 0.4378 - accuracy: 0.8056 - val_loss: 0.5989 - val_accuracy: 0.6852\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8102\n",
      "Epoch 47: accuracy improved from 0.80787 to 0.81019, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.4459 - accuracy: 0.8102 - val_loss: 0.5648 - val_accuracy: 0.6852\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7894\n",
      "Epoch 48: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 75s 697ms/step - loss: 0.4452 - accuracy: 0.7894 - val_loss: 0.6263 - val_accuracy: 0.5926\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7894\n",
      "Epoch 49: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 74s 681ms/step - loss: 0.4409 - accuracy: 0.7894 - val_loss: 0.4967 - val_accuracy: 0.7407\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8148\n",
      "Epoch 50: accuracy improved from 0.81019 to 0.81481, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 81s 749ms/step - loss: 0.4634 - accuracy: 0.8148 - val_loss: 0.5925 - val_accuracy: 0.6574\n",
      "====== Modele evaluation ======\n",
      "6/6 [==============================] - 2s 179ms/step - loss: 0.5821 - accuracy: 0.7083\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec une autre disposition du dataset (on prend 50-50 test entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2876 - accuracy: 0.4744\n",
      "Epoch 1: accuracy improved from -inf to 0.47436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 44s 561ms/step - loss: 1.2876 - accuracy: 0.4744 - val_loss: 1.2897 - val_accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2548 - accuracy: 0.4872\n",
      "Epoch 2: accuracy improved from 0.47436 to 0.48718, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 48s 612ms/step - loss: 1.2548 - accuracy: 0.4872 - val_loss: 1.2656 - val_accuracy: 0.4872\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2293 - accuracy: 0.4872\n",
      "Epoch 3: accuracy did not improve from 0.48718\n",
      "78/78 [==============================] - 43s 551ms/step - loss: 1.2293 - accuracy: 0.4872 - val_loss: 1.2371 - val_accuracy: 0.4872\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1603 - accuracy: 0.5288\n",
      "Epoch 4: accuracy improved from 0.48718 to 0.52885, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 38s 491ms/step - loss: 1.1603 - accuracy: 0.5288 - val_loss: 1.0273 - val_accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6346\n",
      "Epoch 5: accuracy improved from 0.52885 to 0.63462, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 36s 460ms/step - loss: 0.8944 - accuracy: 0.6346 - val_loss: 0.8807 - val_accuracy: 0.6282\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.6571\n",
      "Epoch 6: accuracy improved from 0.63462 to 0.65705, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.8453 - accuracy: 0.6571 - val_loss: 0.8299 - val_accuracy: 0.7179\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.6859\n",
      "Epoch 7: accuracy improved from 0.65705 to 0.68590, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 35s 456ms/step - loss: 0.7266 - accuracy: 0.6859 - val_loss: 0.7660 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.6378\n",
      "Epoch 8: accuracy did not improve from 0.68590\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.7929 - accuracy: 0.6378 - val_loss: 0.8949 - val_accuracy: 0.6026\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.7115\n",
      "Epoch 9: accuracy improved from 0.68590 to 0.71154, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 44s 560ms/step - loss: 0.6993 - accuracy: 0.7115 - val_loss: 0.9557 - val_accuracy: 0.5256\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7564 - accuracy: 0.6795\n",
      "Epoch 10: accuracy did not improve from 0.71154\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.7564 - accuracy: 0.6795 - val_loss: 0.8713 - val_accuracy: 0.6538\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.7147\n",
      "Epoch 11: accuracy improved from 0.71154 to 0.71474, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 43s 551ms/step - loss: 0.6728 - accuracy: 0.7147 - val_loss: 0.7354 - val_accuracy: 0.7308\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7212\n",
      "Epoch 12: accuracy improved from 0.71474 to 0.72115, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 544ms/step - loss: 0.6372 - accuracy: 0.7212 - val_loss: 0.6706 - val_accuracy: 0.8077\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.7019\n",
      "Epoch 13: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 522ms/step - loss: 0.6402 - accuracy: 0.7019 - val_loss: 0.6819 - val_accuracy: 0.7308\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7212\n",
      "Epoch 14: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 530ms/step - loss: 0.6129 - accuracy: 0.7212 - val_loss: 0.8202 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7051\n",
      "Epoch 15: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 0.6588 - accuracy: 0.7051 - val_loss: 0.8742 - val_accuracy: 0.6026\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.6987\n",
      "Epoch 16: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 40s 510ms/step - loss: 0.6555 - accuracy: 0.6987 - val_loss: 0.7781 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.7212\n",
      "Epoch 17: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.6204 - accuracy: 0.7212 - val_loss: 0.7299 - val_accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.7051\n",
      "Epoch 18: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.6360 - accuracy: 0.7051 - val_loss: 0.7110 - val_accuracy: 0.7308\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6318 - accuracy: 0.7179\n",
      "Epoch 19: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 0.6318 - accuracy: 0.7179 - val_loss: 0.8609 - val_accuracy: 0.6026\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.7244\n",
      "Epoch 20: accuracy improved from 0.72115 to 0.72436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.6297 - accuracy: 0.7244 - val_loss: 0.6788 - val_accuracy: 0.7308\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.7244\n",
      "Epoch 21: accuracy did not improve from 0.72436\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.6132 - accuracy: 0.7244 - val_loss: 0.6193 - val_accuracy: 0.7308\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7340\n",
      "Epoch 22: accuracy improved from 0.72436 to 0.73397, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 531ms/step - loss: 0.6127 - accuracy: 0.7340 - val_loss: 0.6713 - val_accuracy: 0.7308\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7115\n",
      "Epoch 23: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.6794 - accuracy: 0.7115 - val_loss: 0.5675 - val_accuracy: 0.7821\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.7083\n",
      "Epoch 24: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6427 - accuracy: 0.7083 - val_loss: 0.7387 - val_accuracy: 0.6538\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7115\n",
      "Epoch 25: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.7141 - accuracy: 0.7115 - val_loss: 0.6177 - val_accuracy: 0.7692\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7179\n",
      "Epoch 26: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 0.6191 - accuracy: 0.7179 - val_loss: 0.6374 - val_accuracy: 0.7436\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7147\n",
      "Epoch 27: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 33s 427ms/step - loss: 0.6098 - accuracy: 0.7147 - val_loss: 0.5601 - val_accuracy: 0.7436\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6116 - accuracy: 0.7051\n",
      "Epoch 28: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 32s 411ms/step - loss: 0.6116 - accuracy: 0.7051 - val_loss: 0.6067 - val_accuracy: 0.7179\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.6955\n",
      "Epoch 29: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 32s 416ms/step - loss: 0.6346 - accuracy: 0.6955 - val_loss: 0.6143 - val_accuracy: 0.7436\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7500\n",
      "Epoch 30: accuracy improved from 0.73397 to 0.75000, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 37s 472ms/step - loss: 0.5588 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7308\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.7628\n",
      "Epoch 31: accuracy improved from 0.75000 to 0.76282, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 538ms/step - loss: 0.5247 - accuracy: 0.7628 - val_loss: 0.6115 - val_accuracy: 0.7179\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7276\n",
      "Epoch 32: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.5745 - accuracy: 0.7276 - val_loss: 0.6677 - val_accuracy: 0.6538\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7115\n",
      "Epoch 33: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 0.5732 - accuracy: 0.7115 - val_loss: 0.5990 - val_accuracy: 0.8462\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7596\n",
      "Epoch 34: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 38s 492ms/step - loss: 0.5522 - accuracy: 0.7596 - val_loss: 0.6097 - val_accuracy: 0.7179\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7821\n",
      "Epoch 35: accuracy improved from 0.76282 to 0.78205, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 522ms/step - loss: 0.5238 - accuracy: 0.7821 - val_loss: 0.7427 - val_accuracy: 0.7051\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7500\n",
      "Epoch 36: accuracy did not improve from 0.78205\n",
      "78/78 [==============================] - 39s 496ms/step - loss: 0.5312 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7436\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7821\n",
      "Epoch 37: accuracy did not improve from 0.78205\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 0.4932 - accuracy: 0.7821 - val_loss: 0.4978 - val_accuracy: 0.7436\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.7949\n",
      "Epoch 38: accuracy improved from 0.78205 to 0.79487, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 40s 519ms/step - loss: 0.4802 - accuracy: 0.7949 - val_loss: 0.5058 - val_accuracy: 0.9103\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.7404\n",
      "Epoch 39: accuracy did not improve from 0.79487\n",
      "78/78 [==============================] - 40s 509ms/step - loss: 0.5290 - accuracy: 0.7404 - val_loss: 0.5708 - val_accuracy: 0.7821\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8141\n",
      "Epoch 40: accuracy improved from 0.79487 to 0.81410, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 526ms/step - loss: 0.4459 - accuracy: 0.8141 - val_loss: 0.4636 - val_accuracy: 0.8205\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8045\n",
      "Epoch 41: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.4801 - accuracy: 0.8045 - val_loss: 0.4322 - val_accuracy: 0.8462\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8109\n",
      "Epoch 42: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 40s 517ms/step - loss: 0.4358 - accuracy: 0.8109 - val_loss: 0.4631 - val_accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7853\n",
      "Epoch 43: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.4529 - accuracy: 0.7853 - val_loss: 0.4692 - val_accuracy: 0.8590\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.8173\n",
      "Epoch 44: accuracy improved from 0.81410 to 0.81731, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 0.4334 - accuracy: 0.8173 - val_loss: 0.4261 - val_accuracy: 0.8205\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8205\n",
      "Epoch 45: accuracy improved from 0.81731 to 0.82051, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 545ms/step - loss: 0.4072 - accuracy: 0.8205 - val_loss: 0.6082 - val_accuracy: 0.7692\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.7821\n",
      "Epoch 46: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 41s 528ms/step - loss: 0.4761 - accuracy: 0.7821 - val_loss: 0.4299 - val_accuracy: 0.8718\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7949\n",
      "Epoch 47: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.4353 - accuracy: 0.7949 - val_loss: 0.5750 - val_accuracy: 0.7949\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.7885\n",
      "Epoch 48: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 40s 512ms/step - loss: 0.4605 - accuracy: 0.7885 - val_loss: 0.5117 - val_accuracy: 0.8205\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.8109\n",
      "Epoch 49: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 0.4186 - accuracy: 0.8109 - val_loss: 0.5938 - val_accuracy: 0.7821\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8013\n",
      "Epoch 50: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.4579 - accuracy: 0.8013 - val_loss: 0.5292 - val_accuracy: 0.7692\n",
      "====== Modele evaluation ======\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4963 - accuracy: 0.8205\n",
      "===============================\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024A629D3A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.5)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tente maintenant de rééquilibrer les classes et voir l'impact d'une telle opération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    190\n",
       "1    100\n",
       "0     60\n",
       "3     40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_train_aug.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 32000, 1), (390, 32000))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train_aug_res = np.add.reduce(fv_train_aug, axis=2)\n",
    "fv_train_aug.shape, fv_train_aug_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    190\n",
       "1    190\n",
       "2    190\n",
       "3    190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "fv_train_aug_res, etiq_train_aug_res = sm.fit_resample(fv_train_aug_res, etiq_train_aug)\n",
    "etiq_train_aug_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On restructure la matrices des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_train_aug_res = np.expand_dims(fv_train_aug_res, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 1.2420 - accuracy: 0.3569\n",
      "Epoch 1: accuracy improved from -inf to 0.35691, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 512ms/step - loss: 1.2420 - accuracy: 0.3569 - val_loss: 1.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.8672 - accuracy: 0.6382\n",
      "Epoch 2: accuracy improved from 0.35691 to 0.63816, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 84s 557ms/step - loss: 0.8672 - accuracy: 0.6382 - val_loss: 1.5540 - val_accuracy: 0.0066\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.7155\n",
      "Epoch 3: accuracy improved from 0.63816 to 0.71546, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 84s 553ms/step - loss: 0.6582 - accuracy: 0.7155 - val_loss: 1.4605 - val_accuracy: 0.0066\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7319\n",
      "Epoch 4: accuracy improved from 0.71546 to 0.73191, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 82s 542ms/step - loss: 0.6249 - accuracy: 0.7319 - val_loss: 1.2720 - val_accuracy: 0.0066\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7368\n",
      "Epoch 5: accuracy improved from 0.73191 to 0.73684, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 527ms/step - loss: 0.5970 - accuracy: 0.7368 - val_loss: 1.2002 - val_accuracy: 0.0066\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.7336\n",
      "Epoch 6: accuracy did not improve from 0.73684\n",
      "152/152 [==============================] - 77s 510ms/step - loss: 0.5893 - accuracy: 0.7336 - val_loss: 1.3993 - val_accuracy: 0.0066\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7434\n",
      "Epoch 7: accuracy improved from 0.73684 to 0.74342, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 82s 537ms/step - loss: 0.5684 - accuracy: 0.7434 - val_loss: 1.0069 - val_accuracy: 0.0066\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.7303\n",
      "Epoch 8: accuracy did not improve from 0.74342\n",
      "152/152 [==============================] - 79s 523ms/step - loss: 0.6518 - accuracy: 0.7303 - val_loss: 1.3450 - val_accuracy: 0.0132\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.7549\n",
      "Epoch 9: accuracy improved from 0.74342 to 0.75493, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 83s 550ms/step - loss: 0.5685 - accuracy: 0.7549 - val_loss: 0.9886 - val_accuracy: 0.0066\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7385\n",
      "Epoch 10: accuracy did not improve from 0.75493\n",
      "152/152 [==============================] - 81s 534ms/step - loss: 0.5838 - accuracy: 0.7385 - val_loss: 1.0963 - val_accuracy: 0.0066\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7582\n",
      "Epoch 11: accuracy improved from 0.75493 to 0.75822, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 85s 560ms/step - loss: 0.5368 - accuracy: 0.7582 - val_loss: 1.3550 - val_accuracy: 0.0132\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7484\n",
      "Epoch 12: accuracy did not improve from 0.75822\n",
      "152/152 [==============================] - 78s 511ms/step - loss: 0.5236 - accuracy: 0.7484 - val_loss: 1.0154 - val_accuracy: 0.0132\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7796\n",
      "Epoch 13: accuracy improved from 0.75822 to 0.77961, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 524ms/step - loss: 0.4800 - accuracy: 0.7796 - val_loss: 1.3345 - val_accuracy: 0.0066\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.7401\n",
      "Epoch 14: accuracy did not improve from 0.77961\n",
      "152/152 [==============================] - 70s 464ms/step - loss: 0.5595 - accuracy: 0.7401 - val_loss: 1.2105 - val_accuracy: 0.0132\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7911\n",
      "Epoch 15: accuracy improved from 0.77961 to 0.79112, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 64s 424ms/step - loss: 0.4543 - accuracy: 0.7911 - val_loss: 1.3838 - val_accuracy: 0.0066\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8174\n",
      "Epoch 16: accuracy improved from 0.79112 to 0.81743, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 73s 480ms/step - loss: 0.4134 - accuracy: 0.8174 - val_loss: 1.2903 - val_accuracy: 0.1645\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.7993\n",
      "Epoch 17: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 78s 515ms/step - loss: 0.4412 - accuracy: 0.7993 - val_loss: 1.2466 - val_accuracy: 0.1908\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.7796\n",
      "Epoch 18: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 79s 523ms/step - loss: 0.4343 - accuracy: 0.7796 - val_loss: 1.3134 - val_accuracy: 0.1908\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.7993\n",
      "Epoch 19: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 80s 524ms/step - loss: 0.3976 - accuracy: 0.7993 - val_loss: 1.2405 - val_accuracy: 0.3092\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7961\n",
      "Epoch 20: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 80s 525ms/step - loss: 0.4972 - accuracy: 0.7961 - val_loss: 1.2137 - val_accuracy: 0.2171\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8125\n",
      "Epoch 21: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 77s 506ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 1.7915 - val_accuracy: 0.0724\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8026\n",
      "Epoch 22: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 76s 499ms/step - loss: 0.4262 - accuracy: 0.8026 - val_loss: 2.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8043\n",
      "Epoch 23: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.4009 - accuracy: 0.8043 - val_loss: 1.8837 - val_accuracy: 0.1447\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8355\n",
      "Epoch 24: accuracy improved from 0.81743 to 0.83553, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 521ms/step - loss: 0.3741 - accuracy: 0.8355 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8158\n",
      "Epoch 25: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 78s 511ms/step - loss: 0.3864 - accuracy: 0.8158 - val_loss: 1.4892 - val_accuracy: 0.2171\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8141\n",
      "Epoch 26: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 78s 514ms/step - loss: 0.3871 - accuracy: 0.8141 - val_loss: 1.0401 - val_accuracy: 0.4276\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8306\n",
      "Epoch 27: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 79s 521ms/step - loss: 0.3736 - accuracy: 0.8306 - val_loss: 1.3841 - val_accuracy: 0.2632\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.7993\n",
      "Epoch 28: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.3818 - accuracy: 0.7993 - val_loss: 1.8269 - val_accuracy: 0.2105\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8224\n",
      "Epoch 29: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 76s 500ms/step - loss: 0.3597 - accuracy: 0.8224 - val_loss: 1.2364 - val_accuracy: 0.2697\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8240\n",
      "Epoch 30: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 77s 505ms/step - loss: 0.3517 - accuracy: 0.8240 - val_loss: 1.3795 - val_accuracy: 0.2434\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8421\n",
      "Epoch 31: accuracy improved from 0.83553 to 0.84211, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 518ms/step - loss: 0.3399 - accuracy: 0.8421 - val_loss: 1.8186 - val_accuracy: 0.2368\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.8322\n",
      "Epoch 32: accuracy did not improve from 0.84211\n",
      "152/152 [==============================] - 77s 510ms/step - loss: 0.3475 - accuracy: 0.8322 - val_loss: 1.8173 - val_accuracy: 0.2171\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8503\n",
      "Epoch 33: accuracy improved from 0.84211 to 0.85033, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 527ms/step - loss: 0.3739 - accuracy: 0.8503 - val_loss: 2.9008 - val_accuracy: 0.0921\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8257\n",
      "Epoch 34: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 79s 519ms/step - loss: 0.3684 - accuracy: 0.8257 - val_loss: 1.1877 - val_accuracy: 0.4145\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.8289\n",
      "Epoch 35: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 76s 499ms/step - loss: 0.3629 - accuracy: 0.8289 - val_loss: 1.5839 - val_accuracy: 0.2632\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8438\n",
      "Epoch 36: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 73s 479ms/step - loss: 0.3401 - accuracy: 0.8438 - val_loss: 1.8477 - val_accuracy: 0.2039\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8224\n",
      "Epoch 37: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 435ms/step - loss: 0.3424 - accuracy: 0.8224 - val_loss: 1.2970 - val_accuracy: 0.3553\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8405\n",
      "Epoch 38: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 437ms/step - loss: 0.3501 - accuracy: 0.8405 - val_loss: 1.5855 - val_accuracy: 0.3092\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8339\n",
      "Epoch 39: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 433ms/step - loss: 0.3587 - accuracy: 0.8339 - val_loss: 1.6373 - val_accuracy: 0.2961\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8257\n",
      "Epoch 40: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 68s 448ms/step - loss: 0.3482 - accuracy: 0.8257 - val_loss: 1.9749 - val_accuracy: 0.2368\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.7928\n",
      "Epoch 41: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 68s 447ms/step - loss: 0.3764 - accuracy: 0.7928 - val_loss: 1.5320 - val_accuracy: 0.3355\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8569\n",
      "Epoch 42: accuracy improved from 0.85033 to 0.85691, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 72s 472ms/step - loss: 0.3333 - accuracy: 0.8569 - val_loss: 1.3635 - val_accuracy: 0.3553\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8355\n",
      "Epoch 43: accuracy did not improve from 0.85691\n",
      "152/152 [==============================] - 72s 476ms/step - loss: 0.3628 - accuracy: 0.8355 - val_loss: 1.5731 - val_accuracy: 0.3026\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8651\n",
      "Epoch 44: accuracy improved from 0.85691 to 0.86513, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 75s 496ms/step - loss: 0.3113 - accuracy: 0.8651 - val_loss: 1.4154 - val_accuracy: 0.3421\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.8454\n",
      "Epoch 45: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 72s 473ms/step - loss: 0.3355 - accuracy: 0.8454 - val_loss: 2.1457 - val_accuracy: 0.2039\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306\n",
      "Epoch 46: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.3815 - accuracy: 0.8306 - val_loss: 1.9493 - val_accuracy: 0.2566\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8470\n",
      "Epoch 47: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 78s 516ms/step - loss: 0.3528 - accuracy: 0.8470 - val_loss: 2.0758 - val_accuracy: 0.2434\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.8388\n",
      "Epoch 48: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 83s 544ms/step - loss: 0.3241 - accuracy: 0.8388 - val_loss: 1.7179 - val_accuracy: 0.2105\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8651\n",
      "Epoch 49: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 82s 539ms/step - loss: 0.3055 - accuracy: 0.8651 - val_loss: 2.6262 - val_accuracy: 0.1842\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8339\n",
      "Epoch 50: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 82s 541ms/step - loss: 0.3311 - accuracy: 0.8339 - val_loss: 1.6475 - val_accuracy: 0.3224\n",
      "====== Modele evaluation ======\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4125 - accuracy: 0.8462\n",
      "===============================\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024A62C70430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_4'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug_res, etiq_train_aug_res, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essai maintenant avec un ratio 60% de test - 40% d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.2785 - accuracy: 0.4718\n",
      "Epoch 1: accuracy improved from -inf to 0.47177, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 536ms/step - loss: 1.2785 - accuracy: 0.4718 - val_loss: 1.2889 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.2400 - accuracy: 0.4839\n",
      "Epoch 2: accuracy improved from 0.47177 to 0.48387, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 535ms/step - loss: 1.2400 - accuracy: 0.4839 - val_loss: 1.2202 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.0836 - accuracy: 0.5726\n",
      "Epoch 3: accuracy improved from 0.48387 to 0.57258, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 566ms/step - loss: 1.0836 - accuracy: 0.5726 - val_loss: 0.9509 - val_accuracy: 0.6452\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.6895\n",
      "Epoch 4: accuracy improved from 0.57258 to 0.68952, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 570ms/step - loss: 0.8477 - accuracy: 0.6895 - val_loss: 0.8375 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.7218\n",
      "Epoch 5: accuracy improved from 0.68952 to 0.72177, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 584ms/step - loss: 0.7584 - accuracy: 0.7218 - val_loss: 0.9001 - val_accuracy: 0.6290\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7379\n",
      "Epoch 6: accuracy improved from 0.72177 to 0.73790, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 38s 607ms/step - loss: 0.6992 - accuracy: 0.7379 - val_loss: 0.7414 - val_accuracy: 0.7903\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7419\n",
      "Epoch 7: accuracy improved from 0.73790 to 0.74194, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 565ms/step - loss: 0.6853 - accuracy: 0.7419 - val_loss: 0.8746 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7742\n",
      "Epoch 8: accuracy improved from 0.74194 to 0.77419, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 40s 641ms/step - loss: 0.5776 - accuracy: 0.7742 - val_loss: 0.7738 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7500\n",
      "Epoch 9: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 508ms/step - loss: 0.6071 - accuracy: 0.7500 - val_loss: 0.7004 - val_accuracy: 0.7258\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.7460\n",
      "Epoch 10: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 503ms/step - loss: 0.5984 - accuracy: 0.7460 - val_loss: 0.6509 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7581\n",
      "Epoch 11: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 504ms/step - loss: 0.5692 - accuracy: 0.7581 - val_loss: 0.6081 - val_accuracy: 0.8065\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.7621\n",
      "Epoch 12: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 505ms/step - loss: 0.5429 - accuracy: 0.7621 - val_loss: 0.5334 - val_accuracy: 0.9032\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7621\n",
      "Epoch 13: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 521ms/step - loss: 0.5655 - accuracy: 0.7621 - val_loss: 0.6077 - val_accuracy: 0.7903\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.7621\n",
      "Epoch 14: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 523ms/step - loss: 0.5263 - accuracy: 0.7621 - val_loss: 0.5933 - val_accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7944\n",
      "Epoch 15: accuracy improved from 0.77419 to 0.79435, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 587ms/step - loss: 0.4744 - accuracy: 0.7944 - val_loss: 0.6004 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7661\n",
      "Epoch 16: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 43s 690ms/step - loss: 0.5270 - accuracy: 0.7661 - val_loss: 0.7878 - val_accuracy: 0.6935\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7782\n",
      "Epoch 17: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 40s 646ms/step - loss: 0.4915 - accuracy: 0.7782 - val_loss: 0.8171 - val_accuracy: 0.6613\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.7903\n",
      "Epoch 18: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 43s 692ms/step - loss: 0.5114 - accuracy: 0.7903 - val_loss: 0.5651 - val_accuracy: 0.7742\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.7863\n",
      "Epoch 19: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 33s 540ms/step - loss: 0.4820 - accuracy: 0.7863 - val_loss: 0.5375 - val_accuracy: 0.8065\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7661\n",
      "Epoch 20: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 516ms/step - loss: 0.4686 - accuracy: 0.7661 - val_loss: 0.6606 - val_accuracy: 0.7581\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.7379\n",
      "Epoch 21: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 520ms/step - loss: 0.5800 - accuracy: 0.7379 - val_loss: 0.6668 - val_accuracy: 0.6452\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7782\n",
      "Epoch 22: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 524ms/step - loss: 0.4928 - accuracy: 0.7782 - val_loss: 0.6197 - val_accuracy: 0.7581\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7903\n",
      "Epoch 23: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.4386 - accuracy: 0.7903 - val_loss: 0.4940 - val_accuracy: 0.8226\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7823\n",
      "Epoch 24: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 523ms/step - loss: 0.4565 - accuracy: 0.7823 - val_loss: 0.5896 - val_accuracy: 0.7419\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.7702\n",
      "Epoch 25: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 38s 607ms/step - loss: 0.5017 - accuracy: 0.7702 - val_loss: 0.6688 - val_accuracy: 0.7581\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8065\n",
      "Epoch 26: accuracy improved from 0.79435 to 0.80645, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 40s 647ms/step - loss: 0.4315 - accuracy: 0.8065 - val_loss: 0.7249 - val_accuracy: 0.6935\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.7903\n",
      "Epoch 27: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.4878 - accuracy: 0.7903 - val_loss: 0.6290 - val_accuracy: 0.7258\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.7984\n",
      "Epoch 28: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 561ms/step - loss: 0.4322 - accuracy: 0.7984 - val_loss: 0.6581 - val_accuracy: 0.7258\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.8024\n",
      "Epoch 29: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 563ms/step - loss: 0.4647 - accuracy: 0.8024 - val_loss: 0.6840 - val_accuracy: 0.6774\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8065\n",
      "Epoch 30: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 563ms/step - loss: 0.4415 - accuracy: 0.8065 - val_loss: 0.4839 - val_accuracy: 0.7903\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8065\n",
      "Epoch 31: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 30s 491ms/step - loss: 0.4318 - accuracy: 0.8065 - val_loss: 0.5981 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.8105\n",
      "Epoch 32: accuracy improved from 0.80645 to 0.81048, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 576ms/step - loss: 0.4260 - accuracy: 0.8105 - val_loss: 0.5798 - val_accuracy: 0.7581\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.7903\n",
      "Epoch 33: accuracy did not improve from 0.81048\n",
      "62/62 [==============================] - 32s 509ms/step - loss: 0.4334 - accuracy: 0.7903 - val_loss: 0.6283 - val_accuracy: 0.7581\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8145\n",
      "Epoch 34: accuracy improved from 0.81048 to 0.81452, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 571ms/step - loss: 0.4169 - accuracy: 0.8145 - val_loss: 0.6161 - val_accuracy: 0.7258\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.7500\n",
      "Epoch 35: accuracy did not improve from 0.81452\n",
      "62/62 [==============================] - 32s 513ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.5458 - val_accuracy: 0.7903\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.7903\n",
      "Epoch 36: accuracy did not improve from 0.81452\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.4028 - accuracy: 0.7903 - val_loss: 0.5064 - val_accuracy: 0.7903\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8468\n",
      "Epoch 37: accuracy improved from 0.81452 to 0.84677, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.3756 - accuracy: 0.8468 - val_loss: 0.4874 - val_accuracy: 0.7742\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8024\n",
      "Epoch 38: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.4148 - accuracy: 0.8024 - val_loss: 0.5318 - val_accuracy: 0.7903\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8387\n",
      "Epoch 39: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 31s 509ms/step - loss: 0.3586 - accuracy: 0.8387 - val_loss: 0.5351 - val_accuracy: 0.7903\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.7588 - accuracy: 0.7903\n",
      "Epoch 40: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 30s 487ms/step - loss: 0.7588 - accuracy: 0.7903 - val_loss: 0.6496 - val_accuracy: 0.6935\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.8347\n",
      "Epoch 41: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.4307 - accuracy: 0.8347 - val_loss: 0.3593 - val_accuracy: 0.8871\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8266\n",
      "Epoch 42: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 532ms/step - loss: 0.3742 - accuracy: 0.8266 - val_loss: 0.8458 - val_accuracy: 0.6613\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8266\n",
      "Epoch 43: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 532ms/step - loss: 0.3964 - accuracy: 0.8266 - val_loss: 0.4944 - val_accuracy: 0.7581\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8065\n",
      "Epoch 44: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 32s 521ms/step - loss: 0.3805 - accuracy: 0.8065 - val_loss: 0.3971 - val_accuracy: 0.7581\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8347\n",
      "Epoch 45: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 31s 502ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.5147 - val_accuracy: 0.7903\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8629\n",
      "Epoch 46: accuracy improved from 0.84677 to 0.86290, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.3253 - accuracy: 0.8629 - val_loss: 0.4234 - val_accuracy: 0.8226\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.8468\n",
      "Epoch 47: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 28s 453ms/step - loss: 0.3553 - accuracy: 0.8468 - val_loss: 0.5469 - val_accuracy: 0.7419\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8468\n",
      "Epoch 48: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.3287 - accuracy: 0.8468 - val_loss: 0.5762 - val_accuracy: 0.7419\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.8629\n",
      "Epoch 49: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 32s 511ms/step - loss: 0.3263 - accuracy: 0.8629 - val_loss: 0.3746 - val_accuracy: 0.7903\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8710\n",
      "Epoch 50: accuracy improved from 0.86290 to 0.87097, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 527ms/step - loss: 0.3401 - accuracy: 0.8710 - val_loss: 0.4033 - val_accuracy: 0.7903\n",
      "====== Modele evaluation ======\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4510 - accuracy: 0.8085\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.6)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat/np.sum(con_mat), annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signaux empilés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dataset(path, etiq, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    fv_train_list = list()\n",
    "    fv_test_list = list()\n",
    "    etiq[\"class\"] = etiq[\"class\"].astype('category').cat.codes\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            fv_train, fv_test, etiq_train, etiq_test = train_test_split(monfichier, etiq, test_size=test_size, random_state=42)\n",
    "            fv_train_aug = sensor_augmentor(fv_train)\n",
    "            etiq_train_aug = etiq_augmentor(etiq_train)\n",
    "            fv_train_list.append(fv_train_aug)\n",
    "            fv_test_list.append(fv_test)\n",
    "    fv_train_list = np.dstack(fv_train_list)\n",
    "    fv_test_list = np.dstack(fv_test_list)\n",
    "    return fv_train_list, fv_test_list, etiq_train_aug, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiq = pd.read_csv(\"./capteurs/labels/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((540, 4000, 8), (24, 4000, 8), (540, 1), (24, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = stack_dataset(path, etiq)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.9293 - accuracy: 0.6273\n",
      "Epoch 1: accuracy improved from -inf to 0.62731, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 94ms/step - loss: 0.9293 - accuracy: 0.6273 - val_loss: 1.0156 - val_accuracy: 0.6481\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.7708\n",
      "Epoch 2: accuracy improved from 0.62731 to 0.77083, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 98ms/step - loss: 0.6218 - accuracy: 0.7708 - val_loss: 0.9346 - val_accuracy: 0.5926\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5009 - accuracy: 0.8009\n",
      "Epoch 3: accuracy improved from 0.77083 to 0.80093, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.5009 - accuracy: 0.8009 - val_loss: 0.8214 - val_accuracy: 0.5926\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8565\n",
      "Epoch 4: accuracy improved from 0.80093 to 0.85648, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.3927 - accuracy: 0.8565 - val_loss: 0.6321 - val_accuracy: 0.7685\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.8565\n",
      "Epoch 5: accuracy did not improve from 0.85648\n",
      "108/108 [==============================] - 9s 81ms/step - loss: 0.4229 - accuracy: 0.8565 - val_loss: 0.7056 - val_accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8542\n",
      "Epoch 6: accuracy did not improve from 0.85648\n",
      "108/108 [==============================] - 8s 76ms/step - loss: 0.3377 - accuracy: 0.8542 - val_loss: 0.6703 - val_accuracy: 0.6389\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9074\n",
      "Epoch 7: accuracy improved from 0.85648 to 0.90741, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 10s 94ms/step - loss: 0.2925 - accuracy: 0.9074 - val_loss: 0.6348 - val_accuracy: 0.6481\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9097\n",
      "Epoch 8: accuracy improved from 0.90741 to 0.90972, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 98ms/step - loss: 0.2226 - accuracy: 0.9097 - val_loss: 0.7137 - val_accuracy: 0.6296\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.9167\n",
      "Epoch 9: accuracy improved from 0.90972 to 0.91667, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 103ms/step - loss: 0.1931 - accuracy: 0.9167 - val_loss: 0.3492 - val_accuracy: 0.8704\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.8866\n",
      "Epoch 10: accuracy did not improve from 0.91667\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.2740 - accuracy: 0.8866 - val_loss: 0.4216 - val_accuracy: 0.8148\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.9352\n",
      "Epoch 11: accuracy improved from 0.91667 to 0.93519, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 10s 97ms/step - loss: 0.1923 - accuracy: 0.9352 - val_loss: 0.3497 - val_accuracy: 0.8704\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9398\n",
      "Epoch 12: accuracy improved from 0.93519 to 0.93981, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 101ms/step - loss: 0.1599 - accuracy: 0.9398 - val_loss: 0.3645 - val_accuracy: 0.8519\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1597 - accuracy: 0.9282\n",
      "Epoch 13: accuracy did not improve from 0.93981\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.1597 - accuracy: 0.9282 - val_loss: 0.7509 - val_accuracy: 0.7222\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9421\n",
      "Epoch 14: accuracy improved from 0.93981 to 0.94213, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 98ms/step - loss: 0.1396 - accuracy: 0.9421 - val_loss: 0.4662 - val_accuracy: 0.7963\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9421\n",
      "Epoch 15: accuracy did not improve from 0.94213\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.1295 - accuracy: 0.9421 - val_loss: 0.6677 - val_accuracy: 0.7222\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1988 - accuracy: 0.9144\n",
      "Epoch 16: accuracy did not improve from 0.94213\n",
      "108/108 [==============================] - 9s 79ms/step - loss: 0.1988 - accuracy: 0.9144 - val_loss: 0.5261 - val_accuracy: 0.7315\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9468\n",
      "Epoch 17: accuracy improved from 0.94213 to 0.94676, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 98ms/step - loss: 0.1440 - accuracy: 0.9468 - val_loss: 0.5508 - val_accuracy: 0.6481\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9329\n",
      "Epoch 18: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 9s 80ms/step - loss: 0.1645 - accuracy: 0.9329 - val_loss: 0.3667 - val_accuracy: 0.8519\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1516 - accuracy: 0.9444\n",
      "Epoch 19: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1516 - accuracy: 0.9444 - val_loss: 0.7606 - val_accuracy: 0.7037\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9398\n",
      "Epoch 20: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 8s 78ms/step - loss: 0.1238 - accuracy: 0.9398 - val_loss: 0.3512 - val_accuracy: 0.8333\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9421\n",
      "Epoch 21: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1517 - accuracy: 0.9421 - val_loss: 0.4585 - val_accuracy: 0.7685\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9421\n",
      "Epoch 22: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 8s 78ms/step - loss: 0.1283 - accuracy: 0.9421 - val_loss: 0.5337 - val_accuracy: 0.7963\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9259\n",
      "Epoch 23: accuracy did not improve from 0.94676\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1728 - accuracy: 0.9259 - val_loss: 0.1973 - val_accuracy: 0.9630\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9491\n",
      "Epoch 24: accuracy improved from 0.94676 to 0.94907, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 99ms/step - loss: 0.1134 - accuracy: 0.9491 - val_loss: 0.4890 - val_accuracy: 0.8241\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9398\n",
      "Epoch 25: accuracy did not improve from 0.94907\n",
      "108/108 [==============================] - 9s 84ms/step - loss: 0.1819 - accuracy: 0.9398 - val_loss: 0.5800 - val_accuracy: 0.7037\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9583\n",
      "Epoch 26: accuracy improved from 0.94907 to 0.95833, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 104ms/step - loss: 0.1244 - accuracy: 0.9583 - val_loss: 0.2731 - val_accuracy: 0.8981\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9699\n",
      "Epoch 27: accuracy improved from 0.95833 to 0.96991, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 11s 100ms/step - loss: 0.0954 - accuracy: 0.9699 - val_loss: 0.4689 - val_accuracy: 0.7870\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9583\n",
      "Epoch 28: accuracy did not improve from 0.96991\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.1113 - accuracy: 0.9583 - val_loss: 0.4083 - val_accuracy: 0.8148\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9606\n",
      "Epoch 29: accuracy did not improve from 0.96991\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1032 - accuracy: 0.9606 - val_loss: 0.3013 - val_accuracy: 0.8704\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9537\n",
      "Epoch 30: accuracy did not improve from 0.96991\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1217 - accuracy: 0.9537 - val_loss: 0.4419 - val_accuracy: 0.8426\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9560\n",
      "Epoch 31: accuracy did not improve from 0.96991\n",
      "108/108 [==============================] - 8s 76ms/step - loss: 0.1119 - accuracy: 0.9560 - val_loss: 0.4394 - val_accuracy: 0.8056\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9676\n",
      "Epoch 32: accuracy did not improve from 0.96991\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.0644 - accuracy: 0.9676 - val_loss: 0.2694 - val_accuracy: 0.8796\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9815\n",
      "Epoch 33: accuracy improved from 0.96991 to 0.98148, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 10s 92ms/step - loss: 0.0566 - accuracy: 0.9815 - val_loss: 0.4518 - val_accuracy: 0.8148\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9769\n",
      "Epoch 34: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.8383 - val_accuracy: 0.7315\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9537\n",
      "Epoch 35: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 73ms/step - loss: 0.1303 - accuracy: 0.9537 - val_loss: 0.4956 - val_accuracy: 0.7778\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9653\n",
      "Epoch 36: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.1049 - accuracy: 0.9653 - val_loss: 0.7145 - val_accuracy: 0.7778\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9352\n",
      "Epoch 37: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.1582 - accuracy: 0.9352 - val_loss: 0.3768 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9699\n",
      "Epoch 38: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 73ms/step - loss: 0.0656 - accuracy: 0.9699 - val_loss: 0.4389 - val_accuracy: 0.8056\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9792\n",
      "Epoch 39: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 76ms/step - loss: 0.0543 - accuracy: 0.9792 - val_loss: 0.2287 - val_accuracy: 0.8889\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9537\n",
      "Epoch 40: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 74ms/step - loss: 0.1090 - accuracy: 0.9537 - val_loss: 0.3695 - val_accuracy: 0.8333\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9769\n",
      "Epoch 41: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 74ms/step - loss: 0.0510 - accuracy: 0.9769 - val_loss: 0.4063 - val_accuracy: 0.8519\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9583\n",
      "Epoch 42: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.1111 - accuracy: 0.9583 - val_loss: 0.3719 - val_accuracy: 0.8241\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9606\n",
      "Epoch 43: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.1016 - accuracy: 0.9606 - val_loss: 0.4183 - val_accuracy: 0.8241\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9815\n",
      "Epoch 44: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 75ms/step - loss: 0.0465 - accuracy: 0.9815 - val_loss: 0.6437 - val_accuracy: 0.7870\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9745\n",
      "Epoch 45: accuracy did not improve from 0.98148\n",
      "108/108 [==============================] - 8s 74ms/step - loss: 0.0610 - accuracy: 0.9745 - val_loss: 0.3841 - val_accuracy: 0.8333\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9954\n",
      "Epoch 46: accuracy improved from 0.98148 to 0.99537, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "108/108 [==============================] - 10s 93ms/step - loss: 0.0275 - accuracy: 0.9954 - val_loss: 0.4066 - val_accuracy: 0.8611\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9792\n",
      "Epoch 47: accuracy did not improve from 0.99537\n",
      "108/108 [==============================] - 9s 82ms/step - loss: 0.0774 - accuracy: 0.9792 - val_loss: 0.5095 - val_accuracy: 0.7870\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9630\n",
      "Epoch 48: accuracy did not improve from 0.99537\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.0828 - accuracy: 0.9630 - val_loss: 0.9161 - val_accuracy: 0.7315\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9884\n",
      "Epoch 49: accuracy did not improve from 0.99537\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.4401 - val_accuracy: 0.8611\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9583\n",
      "Epoch 50: accuracy did not improve from 0.99537\n",
      "108/108 [==============================] - 8s 77ms/step - loss: 0.1346 - accuracy: 0.9583 - val_loss: 0.6047 - val_accuracy: 0.7037\n",
      "\n",
      "\n",
      "==================================== Modele evaluation ====================================\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3415 - accuracy: 0.8333\n",
      "===========================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 8.959999999999994, 'Predicted label')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAGkCAYAAAC1uHUXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABNlUlEQVR4nO3dd3gU5fr/8c+mbAgloJJigEMVUQRUVJAjxULvxQJKEQ2gNIFDERAUpAhIEVSaiiBIUepRmiBICShYQIqI9JYEAoRAIMnu/P7I7yyEVL67m0l23y+vvS5n5pmZezK7m4c79/OMxTAMQwAAAAAAAPBqPmYHAAAAAAAAAPORJAIAAAAAAABJIgAAAAAAAJAkAgAAAAAAgEgSAQAAAAAAQCSJAAAAAAAAIJJEAAAAAAAAeVZ8fLyaNGmiU6dOpdl24MABtWrVSvXr19eQIUOUnJyc6bFIEgEAAAAAAORBf/zxh9q2batjx46lu71///4aNmyY1q5dK8MwtHjx4kyPR5IIAAAAAAAgD1q8eLGGDx+ukJCQNNtOnz6t69ev6+GHH5YktWrVSmvWrMn0eH7uCBIAAAAAAAB3Li4uTnFxcWnWBwUFKSgoKNW6UaNGZXic6OhoBQcHO5aDg4MVFRWV6bnzRJKoTvHnzA4BOWhr9AGzQwAAuEFy4mmzQ8hQ0vkjZoeAHBQYXtPsEAAAbmBmX8OVfYkvv/5O06ZNS7O+R48e6tmzZ7aPY7fbZbFYHMuGYaRaTk+eSBIBAAAAAAB4g44dO6ply5Zp1t9eRZSVsLAwxcTEOJbPnz+f7rC0W5EkAgAAAAAAcIbd5rJDpTes7P+iWLFiCggI0O7du1W1alWtWLFCtWrVynQfJq4GAAAAAABwhmF33ctJERER2rt3ryRpwoQJGjNmjBo0aKBr166pQ4cOme5rMQzDcDoCN2NOIu/CnEQA4JmYkwi5BXMSAYBnMnVOoqi/XHYs/9D7XXasO8VwMwAAAAAAAGfYna8Ayg1IEgEAAAAAADjBcMEwsdyAJBEAAAAAAIAzPKSSiImrAQAAAAAAQCURAAAAAACAUxhuBgAAAAAAANltZkfgEgw3AwAAAAAAAJVEAAAAAAAATmG4GQAAAAAAAHi6GQAAAAAAADwGlUQAAAAAAABOMBhuBgAAAAAAAE8ZbkaSCAAAAAAAwBkeUknEnEQAAAAAAACgkggAAAAAAMApdpvZEbgESSIAAAAAAABnMNwMAAAAAAAAnoJKIgAAAAAAAGfwdDMAAAAAAAAw3AwAAAAAAAAeg0oiAAAAAAAAZzDcDAAAAAAAAIZhMzsEl2C4GQAAAAAAAKgkAgAAAAAAcIqHTFxNkggAAAAAAMAZzEkEAAAAAAAAT6kkYk4iAAAAAAAAUEkEAAAAAADgFLtnPN2MJBEAAAAAAIAzGG4GAAAAAAAAT0ElEQAAAAAAgDN4uhkAAAAAAAAYbgYAAAAAAACPQSURAAAAAACAMxhuBgAAAAAAAE9JEjHcDAAAAAAAACSJcqO6rZ7V7HUzNHvtdE1bPkX3Vy5vdkjIAY0aPqtfd6/Xvj9/0sKvZ6hQoYJmhwQ34557H+45nGEYhgaPnKAvFnwjSbLZbBo7ebqato1Qwxc6a9Gy7xxtj588rY5v9lezl7vopdd768jxk+keM7N2S/+7Vs1e7qJGL76mEeOnKik5WZK0Z99BNW0boaZtI/TT9p8d7ad/sUDfrlrrjkvHbbLzXZJRGx8fH3044T39uXezDu7fqi4R7R37RLz+iv46sE07Ir9XqVIlHOtXrZirChXKuf/CkCHuuffhnuc9hmFz2ctMJIlymRJliqvbkC4a8Mrber1+N837aL5GzHrX7LDgZkWL3q3ZsybqhRe7qOJDtXT06HGNHjXY7LDgRtxz78M9hzP+OXZCr/V6W+s3bXWsW7JitY6fPK1l86Zr4ewp+mrxcu3d/5ckaeB74/RCi0ZaOX+mur/2ivoOGSXDMNIcN6N2fx85po8/+0pzpo3Tf7+epSvxVzVv0TJJ0mdfLdHIIX31xbQPNG32V5Kks+eitWP372rVpF4O/DS8W3a+SzJr0yWivcrfV1pVHn5G1Ws0Vq9er+vxxx6WJA3o312VH35GEydN15vdOkmSWrduogMH/tbBg4dz8jJxC+659+Ge51F2u+teJnJbkuiff/7RJ598omHDhundd9/VJ598or1797rrdB4jKTFJ4/tPVGx0rCTprz8O6e7gu+Tnz/RRnqxu3dratesPHT58VJI0fcZctWvb0uSo4E7cc+/DPXc9b+prLPz2v2rdtL7qPV3Tse6HzdvVonE9+fn5qnBQITV4rrZWrd2oqJjzOnr8pBo+V1uSVPPJx3UtIUEHDv2T6piZtdu4JVJPP1Vdd99VRD4+Pnq+eSOtWrtRkmS1+uvatQRdib8m///fPxk/bZb6vfmaLBZLTvw4vFp2vksya9OieQPNmbtYNptNly5d1uLFK9SuXStJUlJysvLnD1ThoCAlJiUpMDCf+vXpqhHvT8zBK8TtuOfeh3ueRxl2171M5JYk0fz589W3b19JUqVKlVSxYkVJ0jvvvKPPP//cHaf0GOdORWnHxp2O5e7Du2n7+kglJyWbGBXcrUTxcJ08dcaxfOrUWRUuHMRQFA/GPfc+3HPX8ra+xpB+b6pxvadTrYuKjlFYSFHHcmhwUUVFn9e5qBiFFL1HPj43u3mhISnbbpVZu3NR5xUWEuxYH3bL/t06tdXHn32lQSPG6T89XlfkL7+pYIECqvTg/S69ZqQvO98lmbUpXiJcp06m3la8+L2SpCFDx2jDD0vUskVDfTR1tga/3VsffzpH8fFXc+DKkBHuuffhnsNMbilPmTt3rpYvX67AwMBU61999VW1bNlSnTt3dsdpPUq+wHwaNKm/QsJDNOCVQWaHAzfz8fFJdxiAzWbueFS4D/fc+3DPXYu+hmQ3jNsqdwz5+vrIbhjSbRU9hiH5+Pqk2T+jdoZhT7XJMFKOLUllS5fU/Bkpf3FOSk5Wpzf7a+oHw/XtqrX6YdNWhQQX1ZC+b8hqtbruYuGQne+SzNrcvs1ischmS/mr9bJl32vZsu8lSWXKlFS1Jx7VsOHj9OGE91T+vtLasHGrJk+Z6epLQha4596He55H8XSzjPn5+Sk5OW3ly/Xr1+Xv7++OU3qUkPAQTVsxRXabXW+90E/xcWR1Pd2Jk6cVHh7qWC5WLEyxsRd17VqCiVHBnbjn3od77lr0NaR7Q4MVff6CYzn6fKxCg4vq3tBgnb8Qm+ofCDHnLyg0uGia/TNqd29oiKLPx95y7LT7S9K8RcvVsG4d5QsI0NyFS/Xx+PcUHhaiVWt/dOWl4hbZ+S7JrM3JE6d17y3bwsNDdfrU2TTnmTB+uAYMGqHnnq2pQoUKqGnzDmpQ/2mVLVvKPReGDHHPvQ/3PI9iuFnGunXrphYtWmjo0KGaMmWKPvroIw0dOlTPP/+8unXr5o5TeozAAoGavORDbVm9VSO6j1Li9USzQ0IOWL9+s6o98ajKlSstSerapb1WrlpnclRwJ+659+GeuxZ9Denpp6pr2XfrlJxsU9yVeK3+YbOeqfWkwkKCVaJYuFZv2CxJ2rZztywWi8rf1unPrF2dp6pr09YdunDxkgzD0DcrVuuZWjVS7R9zPlYbt0Sqbasmsht2GUqpbLJYLLp+/XqO/Ay8UXa+SzJrs3LVWr3a6SX5+vqqcOEgvfBCc61YuSbV/o0bPafTp8/p99/3KSAgQMnJKdULhmEoMDCfuy8Rt+Geex/uOcxkMdKrUXOBqKgoRUZGKjo6Wna7XWFhYXryyScVGhqa9c63qVP8OTdEmDu1695Wrw3opKMHj6Za3/fFAYq7FGdSVDlra/QBs0MwRcMGz+j999+W1eqvI/8cV6fOvXXx4iWzw4Ibcc+9j7ff8+TE0y49niv7Gknnj7g0NncZ8v6HKlempF5t10bJyTZNmDZLkb/8pqTkZD3fvKFebddGUsqj7Yd/MEWXLsXJarXq3YG99OD9KY82bt2xu94b1FsPPVA+03bLvlunL79equTkZFWqWEHvDuilgICbQ8gGvjdOrZs20BOPVpYkTZ4+R2s2bFZocFF9NHaYCgcVyuGfTvYFhtfMulEult53SZnS/9KMGRP02OP1Mmxz8eIl+fr6atwHw/TcczVl9bdq1ux5mjhphuPYVqtVmzZ+q8ZN2+vixUuyWq1a9u3nKlu2lDb+uE1vdh9o1mV7Ne659+Ge/9+4uq9xJxLWfeKyYwXWe9Nlx7pTbksSuZI3JYngvUkiAPB0ZnbcspJXkkRwjbyeJAIApM/UJNHaaS47VmD9Hi471p1yy3AzAAAAAAAA5C1ueboZAAAAAACA1/CQp5uRJAIAAAAAAHAGSSIAAAAAAACY/eh6V2FOIgAAAAAAAFBJBAAAAAAA4BSGmwEAAAAAAIDhZgAAAAAAAPAYVBIBAAAAAAA4g+FmAAAAAAAAYLgZAAAAAAAAPAaVRAAAAAAAAM5guBkAAAAAAAA8JUnEcDMAAAAAAABQSQQAAAAAAOAUwzA7ApcgSQQAAAAAAOAMDxluRpIIAAAAAADAGR6SJGJOIgAAAAAAAFBJBAAAAAAA4BTDMyqJSBIBAAAAAAA4g+FmAAAAAAAAMMuqVavUqFEj1atXT/Pnz0+zfd++fWrdurWaNWumrl27Ki4uLtPjkSQCAAAAAABwhmG47pVNUVFRmjRpkhYsWKDly5dr0aJFOnz4cKo2o0aNUq9evbRy5UqVLl1an332WabHZLgZAAAAAACAM1w43CwuLi7dip+goCAFBQU5lrdv367q1aurSJEikqT69etrzZo16tGjxy1h2XX16lVJUkJCggoXLpzpuUkSAQAAAAAA5BJffvmlpk2blmZ9jx491LNnT8dydHS0goODHcshISHas2dPqn0GDRqkzp07a/To0QoMDNTixYszPTdJIgAAAAAAAGe4sJKoY8eOatmyZZr1t1YRpZzSLovF4lg2DCPV8vXr1zVkyBDNmTNHlStX1hdffKGBAwdq5syZGZ6bJBEAAAAAAIAzDNcliW4fVpaRsLAw7dq1y7EcExOjkJAQx/KhQ4cUEBCgypUrS5JefPFFTZkyJdNjMnE1AAAAAABAHlOjRg1FRkYqNjZWCQkJWrdunWrVquXYXrJkSZ07d05HjhyRJG3YsEGVKlXK9JhUEgEAAAAAADjBsGf/qWSuEhoaqj59+qhDhw5KSkpSmzZtVLlyZUVERKhXr16qVKmSxowZo7feekuGYeiee+7R6NGjMz2mxTDu4PlqJqlT/DmzQ0AO2hp9wOwQAABukJx42uwQMpR0/ojZISAHBYbXNDsEAIAbmNnXuDa9t8uOlb9b5kPC3IlKIgAAAAAAAGe4cE4iMzEnEQAAAAAAAKgkAgAAAAAAcIoJcxK5A0kiAAAAAAAAZ9gZbgYAAAAAAAAPQSURAAAAAACAMzykkogkEQAAAAAAgDMMz5iTiOFmAAAAAAAAoJIIAAAAAADAKQw3AwAAAAAAgOyeMdyMJBEAAAAAAIAzDM+oJGJOIgAAAAAAAOSNSqKt0QfMDgE5aP49dcwOATnsU98os0OACfhuR24SGF7T7BCQgy71qWZ2CMhh7yyymh0CTDD1zBazQ4A3YbgZAAAAAAAADA+ZuJrhZgAAAAAAAKCSCAAAAAAAwCkMNwMAAAAAAABPNwMAAAAAAIDHoJIIAAAAAADAGQw3AwAAAAAAgHi6GQAAAAAAADwFlUQAAAAAAADOYLgZAAAAAAAAPOXpZiSJAAAAAAAAnOEhlUTMSQQAAAAAAAAqiQAAAAAAAJxheMjTzUgSAQAAAAAAOIPhZgAAAAAAAPAUVBIBAAAAAAA4w0MqiUgSAQAAAAAAOMPwjDmJGG4GAAAAAAAAKokAAAAAAACcwnAzAAAAAAAAGB6SJGK4GQAAAAAAAKgkAgAAAAAAcIqHVBKRJAIAAAAAAHCG3TOebkaSCAAAAAAAwBkeUknEnEQAAAAAAACgkggAAAAAAMApHlJJRJIIAAAAAADACYbhGUkihpsBAAAAAACASiIAAAAAAACnMNwMAAAAAAAAnpIkYrgZAAAAAAAAqCQCAAAAAABwhuEhlUQkiQAAAAAAAJxBkggAAAAAAACymx2AazAnEQAAAAAAAKgkAgAAAAAAcAZzEgEAAAAAAMBj5iRiuBkAAAAAAACoJAIAAAAAAHCKh0xcTZIIAAAAAADACZ4yJxHDzQAAAAAAAEAlUW7UqOGzev/9QQoICNDevQcU0aWfrlyJNzssuNnDw19W8aZPKPHiVUnSlX/OKrLbVJOjgjvVbfWsXuz2gmQYup5wQ1OHfay/9hwyOyy4Ed/vcIfsvK8yauPj46Px44arfv068vP11cRJMzRz1jxJUsTrr+g//d7QxUuX9VLbrjp27KQkadWKueo/cIQOHjyc49fqrfwerSP/mk0dy5Z8+WUpfI+ujY6QEX9ZlsL3KLD7WF2b3Fe6diXTY+VrP0D2uFglrpgtSfIt85CsjTtIPn5ScqJurJgt+6nDkq+f8nUYKJ+i4bL9s1c3lk5POffdoQpo1U3XZ7/nvguGJKlqi6f0dNemkmEoMSFRy96do1P7jqr1iM4qW+0BSdKBH3/XytFfpbv/yF9n6vK5WMfyxhmrdHrfMbX/qKdjncXHR+EV/qXPu36o/Rt/VeeZ/1Fw6Xv19/Y/tWRwynvknn+F6oXRr+vTV0a58WpxO77b8yAPGW5GJVEuU7To3Zo9a6JeeLGLKj5US0ePHtfoUYPNDgs54J7H7lNkt2laV3ew1tUdTILIw5UoU1zdhnTRgFfe1uv1u2neR/M1Yta7ZocFN+L7He6QnfdVZm26RLRX+ftKq8rDz6h6jcbq1et1Pf7Yw5KkAf27q/LDz2jipOl6s1snSVLr1k104MDf/CMihyX/ukkJU/qlvKYOkHHlkm6smC0j/rL8Hq2jwG7vy6fwPVkex792C/mWeuDmCl8/BbzcTze+/VQJU/oqccMS5Xupd8qm8o/IuHxB18Z3l6VIsHxC/yVJCmjyqhK/+9It14mbgsvcq2aDX9bMDmM0odEgrZ+6VK9O76vHWtVSSJl7Na5+f41vOFBlqz2gKo2qpbv/tUtXNaHRIMfr1xXbFHX4dKp1f23Zo90rtmnv2l9UofbDunT2gkbXeUt3FSuqsPLFJUnN32mvFaPm5fSPwKvx3Z43GXbDZS8zkSTKZerWra1du/7Q4cNHJUnTZ8xVu7YtTY4K7uZj9dNdD5VUhe5NVH/jWNWY3Vv5i2Xd2UPelZSYpPH9Jyo2OuUvfH/9cUh3B98lP38KPD0V3+9wh+y8rzJr06J5A82Zu1g2m02XLl3W4sUr1K5dK0lSUnKy8ucPVOGgICUmJSkwMJ/69emqEe9PzMErxO3867SUEX9ZyTvXyVLoLvlVfEIJn43Icj/fMhXlW/4RJe1cd3OlLVnXRr0u+5mU94bP3aEy/leJZEuS/AMkXz9Z/K0ybEnyrVBV9svnZT97zA1XhlslJyZr0cCZiou5JEk6ufeICgUXkZ/VT9b8+eRn9Zef1U++Vj8l30hKs3/pquVl2O3qufhd9V/9ger1aiWLjyVVmzKPV1CVhtW0ZMjs/3/OJFkDA+Tr7ytrvgDZkmx68JlHdenMBZ05cMLt14yb+G6HmUgS5TIliofr5KkzjuVTp86qcOEgFSpU0MSo4G6BoXcpatt+/Tl2idY+M0gXdh/WU1/0NTssuNG5U1HasXGnY7n78G7avj5SyUnJJkYFd+L7He6QnfdVZm2KlwjXqZOptxUvfq8kacjQMdrwwxK1bNFQH02drcFv99bHn85RfPzVHLgypCt/IVlrNtON/34hSTKuXNT1eeNknD+b6W6WQnfJ2vQ13Vg4WbLfNh7CbpOlYGHlHzxL1sYdlbhpuSTJ9vcfUnKS8vf+ULYjf8q4GCPrs88rcd3Xbrgw3O7iqRjt//E3x3Lzoe2174fd2rFwo65djte7Oz/Rez9P1/lj57Rvw69p9vfx9dWhrXs1o+MYTX3xPVWoVUU1OzVI1abp4Jf1/YRFuhGfIEk6tGWvkm8k6T/ff6DDO/Yp9nSM6vZsqdUfLnbvxSINvtvzKLsLXybiT9a5jI+PjwwjbXmZzWYzIRrklKsnY7TllfGO5b8+/U4V+7RUgRLBunoyxsTI4G75AvNp0KT+CgkP0YBXBpkdDtyI73e4Q3beV5m1uX2bxWKRzZbSO1227HstW/a9JKlMmZKq9sSjGjZ8nD6c8J7K31daGzZu1eQpM119SciEf7V6St7/s4zYqOzv5OOrfO36KvG/n8u4cjHdJkb8ZV0bHSGf8DIKjHhX1z4eKOP8Wd349pOb5372eSX98oMs+YMU0KaH5OurxHVfO6qQ4B7WwAC1nfCGioTfoxkdx6h+7za6euGKhj3WVf75rOo88z+q83pjbZr9Xar9dizceHMhQdo0+zvVfLWBfvp8tSSp1KPlVfDuIP26YpujmWEYWjTo5me6bs9W2rnoRxW4u5BeGt9Vvn5+Wj1xsU7vO+bWawbf7XmVwZxEGTtz5kymL2TsxMnTCg8PdSwXKxam2NiLunYtwcSo4G6FHyihkm2eSr3SItmT+cejJwsJD9G0FVNkt9n11gv9FB/HX3A8Gd/vrkVfI0V23leZtTl54rTuvWVbeHioTp9KW5UyYfxwDRg0Qs89W1OFChVQ0+Yd1KD+0ypbtpR7Lgzp8qv8byXt2ph1w1v4FC8ry92hsjZ5VYG9P5Rf9Xryr/xvBbR+U8qXX74Vb85nYz9zRPazx+QTVjLVMSxFisqvXGUl/7JB1rovKnHLSt1YNkMBzV5zyXUhfUXC71GvpSNkt9v1yUsjdD3umio3eEI7l/woW5JN168k6Jdvf1K5Jyum2fexljV1b4V/OZYtFovsSTf7lY80fVK7lv6UbpLhf+cu/9RD2rnoRzXo87w2z/5eS4bMVqvhnVx+nUiL7/Y8ikqijHXt2lXHjh1TSEhImi8ei8WiDRs2uOO0HmH9+s0a/8EwlStXWocPH1XXLu21ctW6rHdE3mY39OjIDjq/8y9dPRmjch2f0+X9J5VwNjbrfZEnBRYI1OQlH2rtN+v05SQmg/QGfL+7Fn2NFNl5X2XWZuWqtXq100v673/Xq2DBAnrhhebq3j11VWPjRs/p9Olz+v33fWrSuK6S//8fMAzDUGBgvpy5UEiBBeRTNEz243/d0W72E4d0bUwXx7L1uRelAoVSnm5mzad8bborIf6y7McPyie0hCwhxWQ/+XeqYwQ07qQbq+dJhiGLn79kt6UMW/MPcMmlIa2AAvnUY+Ew/fLtT1o75VvH+lN/HtXDjZ/U4cj98vHz1UPPVdXx3/5Os3/Y/SVUueET+qLbRPn5++mpjvW1e/lWx/ay1R7Qt8O+yPD8zYe013/HLpBhGPKz+slms8mwG/IPtLr2QpEuvtthJrckib7++mu1a9dOw4cPV9WqVd1xCo8VE3NBr0f01aKFM2W1+uvIP8fVqXNvs8OCm13+65R+Hfqlas7tJ4uvj66diVXkm9PMDgtu1LJTC4UWD1HNBv9WzQb/dqzv++IAxV2KMzEyuAvf765FXyNFRu+rqo9W1owZE/TY4/Uyfe9NnzFXZcqU0q+718vqb9Ws2fP005YdjuNbrVYNGdxbjZu2lyStW79Zb3TrqIP7t2rjj9v0558HTblub+Rzz70y4i6mJGiywVr3JUlS4vqFGTdKvK6EuWMV0LSz5OsrJSfpxteTZFy+4GjiW66yjMTrsp84lLLLlpXK93wPyWLRjVUZJxngnKc61tddxYJVqf7jqlT/ccf6T9q9r9YjXtWgDR/KsNl1aNuf2jhjpSSpQZ/nJUlrJi3R2snfqPWIVzVg7Xj5+vnq9+93phqCVrRUmGJPpT+lQfl/P6Qb167r+G8pT7raNOs7tR3fTRZZtHzkXHddMm7Bd3ve5CnDzSxGRjWGTtqzZ4+WLFmikSNHOn0sP2sxF0SEvGL+PXXMDgE57FPfO5hbAR5ja/QBs0NADktOPO3S49HXwP/VpT5pHxkOz/bOIipgvNHUM1vMDgE5zNV9jTtxvn5tlx2r6NrNLjvWnXLbxNWVK1dW5cqV3XV4AADg5ehrAAAAuBZPNwMAAAAAAHCCpww3c8vTzQAAAAAAALyFYXfd606sWrVKjRo1Ur169TR//vw0248cOaL27durWbNmeu2113T58uVMj0eSCAAAAAAAII+JiorSpEmTtGDBAi1fvlyLFi3S4cOHHdsNw9Abb7yhiIgIrVy5Ug888IBmzpyZ6TEZbgYAAAAAAOAEVw43i4uLU1xc2iceBwUFKSgoyLG8fft2Va9eXUWKFJEk1a9fX2vWrFGPHj0kSfv27VP+/PlVq1YtSVK3bt3SPe6tSBIBAAAAAAA4w7C47FBffvmlpk2blmZ9jx491LNnT8dydHS0goODHcshISHas2ePY/nEiRMqWrSoBg8erAMHDqhMmTJ65513Mj03SSIAAAAAAIBcomPHjmrZsmWa9bdWEUmS3W6XxXIzOWUYRqrl5ORk/fzzz/rqq69UqVIlTZ48WWPHjtXYsWMzPDdJIgAAAAAAACe4crjZ7cPKMhIWFqZdu3Y5lmNiYhQSEuJYDg4OVsmSJVWpUiVJUpMmTdSrV69Mj8nE1QAAAAAAAE4w7BaXvbKrRo0aioyMVGxsrBISErRu3TrH/EOS9Mgjjyg2NlYHDx6UJG3cuFEVK1bM9JhUEgEAAAAAADjBlZVE2RUaGqo+ffqoQ4cOSkpKUps2bVS5cmVFRESoV69eqlSpkj7++GMNHTpUCQkJCgsL07hx4zI9JkkiAAAAAACAPKhp06Zq2rRpqnWzZs1y/H+VKlX0zTffZPt4JIkAAAAAAACcYLjw6WZmIkkEAAAAAADgBDOGm7kDE1cDAAAAAACASiIAAAAAAABn3MlTyXIzkkQAAAAAAABOMAyzI3ANhpsBAAAAAAAg40qiS5cuZbpjkSJFXBwKAADwJvQ1AACAp/D44WbVq1eXxWKRkU7NlMVi0YEDB9waGAAA8Gz0NQAAgKfw+CTRwYMHczIOAADgZehrAAAAT+E1cxLZ7XZ99tlnGjRokOLj4zVjxgzZbLaciA0AAHgB+hoAAAC5Q5ZPNxs3bpxiY2O1d+9eGYahLVu2KCYmRkOHDs2J+AAAgIejrwEAAPI6TxlulmUlUWRkpMaOHauAgAAVKlRIn3/+ubZt25YTsQEAAC9AXwMAAOR1hmFx2ctMWSaJ/Pz85ONzs5nVapWfX5YFSAAAANlCXwMAACB3yLIHVr58ec2fP182m01HjhzRnDlzVKFChZyIDQAAeAH6GgAAIK8z7GZH4BpZVhINGTJE+/bt04ULF9S2bVtdvXpVgwcPzonYAACAF6CvAQAA8jq7YXHZy0xZVhIVLFhQo0ePzolYAACAF6KvAQAAkDtkWUl04cIF9e3bV9WqVdNTTz2lwYMHKy4uLidiAwAAXoC+BgAAyOu8ZuLqoUOHqkSJEvrmm2/01VdfqXDhwho2bFhOxAYAALwAfQ0AAJDXGXaLy15mynK42enTp/Xpp586lgcOHKimTZu6NSgAAOA96GsAAADkDllWEoWEhOjkyZOO5XPnzik4ONitQQEAAO9BXwMAAOR1huG6l5kyrCTq1q2bJCk2NlYtWrRQjRo15OPjo507d+r+++/PsQABAIBnoq8BAAA8hdnDxFwlwyRR/fr1011fp04dd8UCAAC8CH0NAADgKcx+dL2rZJgkatmyZbrrDcPQ8ePH3RYQAADwDvQ1AAAAcpcsJ65euHChxo0bp4SEBMe6u+++W9u2bXNrYAAAwDvQ1wAAAHmd2Y+ud5Usk0QzZ87UF198oU8//VRvvfWWfvzxR507dy4nYgMAAF6AvgYAAMjrzJ5w2lWyfLpZkSJFVKVKFT3wwAO6cOGC3njjDf3yyy85ERsAAPAC9DUAAAByhyyTRH5+frp8+bJKliypPXv2SJJsNpvbAwMAAN6BvgYAAMjr7IbFZS8zZZkkeuGFF9S1a1fVqVNHixYtUqtWrVSmTJmciA0AAHgB+hoAACCvMwyLy15mynJOojZt2qhRo0bKnz+/Fi1apL1796pmzZo5ERsAAPAC9DUAAAByhwyTRF988UWGOy1YsECvvvqqWwICAADegb4GAADwFJ4ycXWGSaJDhw7lZBwAAMDL0NcAAACewuy5hFzFYhi5P9/lZy1mdggA3CjhzBazQ4AJAsMZTuRtkhNPmx1ChuhrAJ6NvoZ3oq/hfczsa+wq3sJlx3rs1HKXHetOZTknEQAAAAAAADJm9oTTrkKSCAAAAAAAwAmeMtyMJBEAAAAAAIATcv08Ptnkk1UDu92u2bNna+DAgYqPj9eMGTNks9lyIjYAAOAF6GsAAADkDllWEo0bN06xsbHau3evJGnLli2KiYnR0KFD3R4cAADwfPQ1AABAXucpw82yrCSKjIzU2LFjFRAQoIIFC+rzzz/Xtm3bciI2AADgBehrAACAvM4wLC57mSnLJJGfn598fG42s1qt8vNjKiMAAOAa9DUAAAByhyx7YOXLl9f8+fNls9l05MgRzZkzRxUqVMiJ2AAAgBegrwEAAPI6u9kBuEiWlURDhgzRvn37dOHCBbVt21ZXr17V4MGDcyI2AADgBehrAACAvM6QxWUvM2VZSVSwYEGNHj06J2IBAABeiL4GAABA7pBlkuj9999Pdz1PHAEAAK5AXwMAAOR1dsPsCFwjy+FmRYoUcbwKFCign3/+OSfiAgAAXoK+BgAAyOvssrjsZaYsK4l69OiRajkiIkJvvPGG2wICAADehb4GAADI68yeS8hVsqwkul3BggUVHR3tjlgAAADoawAAAJgky0qikSNHymJJyYgZhqF9+/apTJkybg8MAAB4B/oaAAAgr7ObHYCLZJkkuuuuu1ItN2vWTM2aNXNbQAAAwLvQ1wAAAHmdpww3yzJJdOLECY0bNy4nYgEAAF6IvgYAAEDukGWS6ODBgzIMw1EGDgAA4Er0NQAAQF7nNcPNgoOD1bhxY1WpUkUFChRwrB86dKhbAwMAAN6BvgYAAMjrPD5JlJiYKKvVqkceeUSPPPJITsYEAAC8AH0NAACA3CXDJNGLL76oZcuWqUePHjkZDwAA8BL0NQAAgKfw+ImrDcPIyTgAAICXoa8BAAA8hd0zckQZJ4lu3Lih/fv3Z9iBq1ixotuCAgAAno++BgAAQO6SYZLo5MmT6tmzZ7odN4vFog0bNrg1MAAA4NnoawAAAE9h9/ThZuXKldPy5ctzMBQAAOBN6GsAAABP4SmD6DNMEgEAAAAAACBrdrMDcBGfjDY89thjORkHAADwMvQ1AAAAcpcMK4mGDh2ak3EAAAAvQ18DAAB4CrvFw+ckAgAAAAAAQNY8ZU6iDIebAQAAAAAAwHtQSQQAAAAAAOAET5m4miQRAAAAAACAE+yeMSURw80AAAAAAADyolWrVqlRo0aqV6+e5s+fn2G7TZs26ZlnnsnyeFQSAQAAAAAAOMGunC8lioqK0qRJk7R06VJZrVa99NJLqlatmsqVK5eq3fnz5/XBBx9k65hUEgEAAAAAADjBcOEru7Zv367q1aurSJEiyp8/v+rXr681a9akaTd06FD16NEjW8ekkggAAAAAACCXiIuLU1xcXJr1QUFBCgoKcixHR0crODjYsRwSEqI9e/ak2mfu3Ll68MEHVaVKlWydmyQRAAAAAACAE1w5cfWXX36padOmpVnfo0cP9ezZ8+Y57XZZLDdPbBhGquVDhw5p3bp1mjNnjs6dO5etc5MkAgAAAAAAcILdhcfq2LGjWrZsmWb9rVVEkhQWFqZdu3Y5lmNiYhQSEuJYXrNmjWJiYtS6dWslJSUpOjpa7dq104IFCzI8N0kiAAAAAAAAJ9zJXEJZuX1YWUZq1KihqVOnKjY2VoGBgVq3bp1Gjhzp2N6rVy/16tVLknTq1Cl16NAh0wSRxMTVAAAAAAAAeU5oaKj69OmjDh06qEWLFmrSpIkqV66siIgI7d279/90TIthGK5MeLmFn7WY2SEAcKOEM1vMDgEmCAyvaXYIyGHJiafNDiFD9DUAz0ZfwzvR1/A+ZvY1Piv+isuO9dqpr1x2rDtFJVEu1Kjhs/p193rt+/MnLfx6hgoVKmh2SMgB3HfvYBiGBo+coC8WfCNJun7jhoaOnqgWr3RT85e7aujoibp+44bJUcJd+JzDHbLzvsqojY+Pjz6c8J7+3LtZB/dvVZeI9o59Il5/RX8d2KYdkd+rVKkSjvWrVsxVhQrl3H9hyBD33HPd3k+w2WwaO3m6mraNUMMXOmvRsu8cbY+fPK2Ob/ZXs5e76KXXe+vI8ZPpHjOzdkv/u1bNXu6iRi++phHjpyopOVmStGffQTVtG6GmbSP00/afHe2nf7FA365a645Lx234nOc9dhe+zESSKJcpWvRuzZ41US+82EUVH6qlo0ePa/SowWaHBTfjvnuHf46d0Gu93tb6TVsd62Z+uVA2m11L536ipXM/0Y0biZo9d5GJUcJd+JzDHbLzvsqsTZeI9ip/X2lVefgZVa/RWL16va7HH3tYkjSgf3dVfvgZTZw0XW926yRJat26iQ4c+FsHDx7OycvELbjnniu9fsKSFat1/ORpLZs3XQtnT9FXi5dr7/6/JEkD3xunF1o00sr5M9X9tVfUd8gopTdIJKN2fx85po8/+0pzpo3Tf7+epSvxVzVv0TJJ0mdfLdHIIX31xbQPNG12SkXD2XPR2rH7d7VqUi8Hfhrejc85zOS2JNEPP/ygefPm6cSJE6nWL1rEP34yU7dube3a9YcOHz4qSZo+Y67atU07qzk8C/fdOyz89r9q3bS+6j19s/S5apWH1LXjS/Lx8ZGvr68eKF9WZ85Fmxgl3IXPuWvRz0iRnfdVZm1aNG+gOXMXy2az6dKly1q8eIXatWslSUpKTlb+/IEqHBSkxKQkBQbmU78+XTXi/Yk5eIW4Hffcc6XXT/hh83a1aFxPfn6+KhxUSA2eq61VazcqKua8jh4/qYbP1ZYk1XzycV1LSNCBQ/+kOmZm7TZuidTTT1XX3XcVkY+Pj55v3kir1m6UJFmt/rp2LUFX4q/J3z/lWUfjp81SvzdfS/V4bbgHn/O8iUqiTEyYMEFfffWVjh07prZt22rFihWObQsXLnTHKT1GieLhOnnqjGP51KmzKlw4iCEJHo777h2G9HtTjes9nWrdv6tVVal/FZcknTkXpXmLlqveM4yf90R8zl2HfsZN2XlfZdameIlwnTqZelvx4vdKkoYMHaMNPyxRyxYN9dHU2Rr8dm99/OkcxcdfzYErQ0a4554rvX5CVHSMwkKKOpZDg4sqKvq8zkXFKKToPfLxufnPudCQlG23yqzduajzCgsJdqwPu2X/bp3a6uPPvtKgEeP0nx6vK/KX31SwQAFVevB+l14z0sfnPG8yLK57mcnPHQfdvHmzli1bJj8/P7Vv316dO3eW1WpVw4YN0y2BxE0+Pj7p/oxsNpsJ0SCncN+x7+Df6j14pNq2bqo6/65mdjhwAz7nrkM/46bsvK8ya3P7NovFIpst5W+Yy5Z9r2XLvpcklSlTUtWeeFTDho/ThxPeU/n7SmvDxq2aPGWmqy8JWeCeexe7YdxWuWPI19dHdsOQbqvoMQzJx9cnzf4ZtTMMe6pNhpFybEkqW7qk5s9IqSxJSk5Wpzf7a+oHw/XtqrX6YdNWhQQX1ZC+b8hqtbruYuHA5xxmckslkXHLl1mpUqU0Y8YMjRo1Sjt37qQ8MQsnTp5WeHioY7lYsTDFxl7UtWsJJkYFd+O+e7fvf9ikiLcGq0+3V9Wl40tmhwM34XPuOvQzbsrO+yqzNidPnNa9t2wLDw/V6VNn05xnwvjhGjBohJ57tqYKFSqgps07qEH9p1W2bCn3XBgyxD33LveGBiv6/AXHcvT5WIUGF9W9ocE6fyE2VSIg5vwFhQYXTbN/Ru3uDQ1R9PnYW46ddn9JmrdouRrWraN8AQGau3CpPh7/nsLDQrRq7Y+uvFTcgs953sRws0w0aNBA7du31549eyRJ9913n6ZMmaK33norzdwBSG39+s2q9sSjKleutCSpa5f2WrlqnclRwd24795r09YdGjtpumZOGpWmxByehc+569DPuCk776vM2qxctVavdnpJvr6+Klw4SC+80FwrVq5JtX/jRs/p9Olz+v33fQoICFBycspfsg3DUGBgPndfIm7DPfcuTz9VXcu+W6fkZJvirsRr9Q+b9UytJxUWEqwSxcK1esNmSdK2nbtlsVhU/rZ/3GfWrs5T1bVp6w5duHhJhmHomxWr9UytGqn2jzkfq41bItW2VRPZDbsMpSTpLRaLrl+/niM/A2/E5zxv8pQkkVuGm/Xo0UNVq1ZVgQIFHOuqVq2qpUuX6vPPP3fHKT1GTMwFvR7RV4sWzpTV6q8j/xxXp869zQ4LbsZ9914Tps2WIUPDx05xrHuk8oMa2q+7iVHBHficuw79jJsyel9VfbSyZsyYoMcer5fpe2/6jLkqU6aUft29XlZ/q2bNnqeftuxwHN9qtWrI4N5q3DTl8cnr1m/WG9066uD+rdr44zb9+edBU67bm3HPvcuLLZvo5Omzat3xTSUlJ+v55g31+COVJUnj3xuo4R9M0cw5C2W1WjXx/SGOuYdad+yu9wb11kMPlM+w3f3lSqvbq+30Ws9BSk5OVqWKFfTay8+nOv+Ej2erV5eO8vX1VcECBfRMzRpq+EJnhQYX1Udjh+X4z8Nb8DnPmzxlwLvFyAOD9/2sxcwOAYAbJZzZYnYIMEFgOBN0e5vkxNNmh5Ah+hqAZ6Ov4Z3oa3gfM/saU0u84rJj9Tz5lcuOdafcUkkEAAAAAADgLeweMi0iSSIAAAAAAAAnmD2XkKu4ZeJqAAAAAAAA5C1UEgEAAAAAADjBUyqJSBIBAAAAAAA4Idc/ESybGG4GAAAAAAAAKokAAAAAAACcwdPNAAAAAAAA4DFzEjHcDAAAAAAAAFQSAQAAAAAAOMNTJq4mSQQAAAAAAOAEu4ekiUgSAQAAAAAAOIE5iQAAAAAAAOAxqCQCAAAAAABwgmcMNiNJBAAAAAAA4BSGmwEAAAAAAMBjUEkEAAAAAADgBLvF7AhcgyQRAAAAAACAE+weMisRw80AAAAAAABAJREAAAAAAIAzPKOOiCQRAAAAAACAUzzl6WYkiQAAAAAAAJzAnEQAAAAAAADwGFQSAQAAAAAAOMEz6ohIEgEAAAAAADjFU+YkYrgZAAAAAAAAqCQCAAAAAABwhqdMXE2SCAAAAAAAwAmekSJiuBkAAAAAAABEJREAAAAAAIBTPGXiapJEAAAAAAAATjA8ZMAZw80AAAAAAABAJREAAAAAAIAzGG4GAAAAAAAA2T1kuBlJIgAAAAAAACd4RoqIOYkAAAAAAAAgKokAAAAAAACcwnAzAAAAAAAAeMzE1Qw3AwAAAAAAAJVEAAAAAAAAzjAYbgYAAAAAAABPGW5GkgiA6eo+3MXsEGCCEoWKmh0CAMBLXOtPX8MbvXdvHbNDAPIckkQAAAAAAABOYLgZAAAAAAAAPGa4GU83AwAAAAAAAJVEAAAAAAAAzrAbDDcDAAAAAADwep6RIiJJBAAAAAAA4BS7h6SJmJMIAAAAAAAAVBIBAAAAAAA4w/CQSiKSRAAAAAAAAE6wmx2AizDcDAAAAAAAAFQSAQAAAAAAOMNTJq4mSQQAAAAAAOAET5mTiOFmAAAAAAAAoJIIAAAAAADAGUxcDQAAAAAAABmG4bLXnVi1apUaNWqkevXqaf78+Wm2//DDD2revLmaNWumN998U5cvX870eCSJAAAAAAAAnGCX4bJXdkVFRWnSpElasGCBli9frkWLFunw4cOO7fHx8Xr33Xc1c+ZMrVy5Uvfff7+mTp2a6TFJEgEAAAAAAOQx27dvV/Xq1VWkSBHlz59f9evX15o1axzbk5KSNHz4cIWGhkqS7r//fp09ezbTYzInEQAAAAAAgBNcOSdRXFyc4uLi0qwPCgpSUFCQYzk6OlrBwcGO5ZCQEO3Zs8exfNddd6lu3bqSpOvXr2vmzJlq3759pucmSQQAAAAAAOAE4w6GiWXlyy+/1LRp09Ks79Gjh3r27OlYttvtslgsN2MwjFTL/3PlyhV1795dFSpUUMuWLTM9N0kiAAAAAACAXKJjx47pJnNurSKSpLCwMO3atcuxHBMTo5CQkFRtoqOj9dprr6l69eoaPHhwlucmSQQAAAAAAOCEO5lwOiu3DyvLSI0aNTR16lTFxsYqMDBQ69at08iRIx3bbTabunXrpoYNG+rNN9/M1rlJEgEAAAAAADjhTh9d7wqhoaHq06ePOnTooKSkJLVp00aVK1dWRESEevXqpXPnzmn//v2y2Wxau3atJOmhhx7SqFGjMjwmSSIAAAAAAIA8qGnTpmratGmqdbNmzZIkVapUSQcPHryj45EkAgAAAAAAcIIrn25mJpJEAAAAAAAATnDl083M5GN2AAAAAAAAADAflUQAAAAAAABOcOXTzcxEkggAAAAAAMAJZjzdzB1IEgEAAAAAADjBUyqJmJMIAAAAAAAAVBIBAAAAAAA4w1OebkaSCAAAAAAAwAl2D5mTiOFmAAAAAAAAoJIIAAAAAADAGZ5RR0SSCAAAAAAAwCk83QwAAAAAAAAeg0oiAAAAAAAAJ3hKJRFJIgAAAAAAACcYPN0MAAAAAAAAnoJKIgAAAAAAACcw3AwAAAAAAAAyPCRJxHCzXKhRw2f16+712vfnT1r49QwVKlTQ7JCQA7jv3qduq2c1e90MzV47XdOWT9H9lcubHRJyyISPRyqiewezw4CHyM7vj4za+Pj46MMJ7+nPvZt1cP9WdYlo79gn4vVX9NeBbdoR+b1KlSrhWL9qxVxVqFDO/ReGDHHPvYNP8dIqMPBDFXx3ugoM+1g+Je+TJFmfbqaC736qgqM+U2CXQZKff7r7p9fOJ/xfKvje9JuvkbNU+Isf5Ff1KcnXT/n7jFLBsV8qX8e3bsYRfK8K/GdcTlyy13usY111Wf+BItaN1fOz+ir/PUEKKBSoVp/2VsS6serywzg92a1Juvtm1q7kkw+q86qRen31aHVa9p7Cq5SRJPn4++rFOf31xuYP1XB0Z0f7Iv8KUbv5b7v3Yj2QYRgue5mJJFEuU7To3Zo9a6JeeLGLKj5US0ePHtfoUYPNDgtuxn33PiXKFFe3IV004JW39Xr9bpr30XyNmPWu2WHBzcqWL635y2epYdO6ZocCD5Gd3x+ZtekS0V7l7yutKg8/o+o1GqtXr9f1+GMPS5IG9O+uyg8/o4mTpuvNbp0kSa1bN9GBA3/r4MHDOXmZuAX33EtYA1Sg31jdWL1I8e92041V85W/69vyq/qUrM8119XxAxQ/9HVZ/AMUUK91mt0zamc/c0Lxw7s5Xsl/7lLijo1K3r1VfpUelz02RvGDOsrnnlD5FCslScrX9g0lLJqewz8A7xP2UClVi2isL1u9q1n1Bin22DnV7tdGtfs9rytnL2hWvUH6ouk7evSV51Ts0bRJ24za+fj7quW0Hvpu0GzNbjhYW6cuV7NJb0iSytauorgzF/Rp7X4qXKyogssXlyTVfecV/fD+/Jy8fOQibksSHTt2TFFRUZKkJUuW6P3339f333/vrtN5jLp1a2vXrj90+PBRSdL0GXPVrm1Lk6OCu3HfvU9SYpLG95+o2OhYSdJffxzS3cF3yc+fUcCerMNrL2nRvKX6fuU6s0PxCPQ1svf7I7M2LZo30Jy5i2Wz2XTp0mUtXrxC7dq1kiQlJScrf/5AFQ4KUmJSkgID86lfn64a8f7EHLxC3I577h38KlaVPfqskvf8LElK/m27rn0yUtYadXVj7Tcyrl6RDEMJcycrcfv6NPtnp53vfQ/J/7FaSvhycsqK5CRZAvJJvn6yWAOk5CT5Vakme2y07CePuPuSvd65P4/p0zr9dONKgnwD/FUo9C4lXIzXunfn6odRCyRJBUOKyC/ATzeuJKTZP6N29iSbPqrWU1H7jktKqRJKuBQvSbIlJsk/f4B8/H3lHxggW1Kyyj3ziOLOXlD0gRM5dOWewy7DZS8zueVfI3PmzNG8efNkt9tVvXp1nT17VnXr1tW3336ro0ePqnv37u44rUcoUTxcJ0+dcSyfOnVWhQsHqVChgrpyJd7EyOBO3Hfvc+5UlM6dinIsdx/eTdvXRyo5KdnEqOBuwweOkSTVfPpJkyPJ++hrpMjO74/M2hQvEa5TJ1Nvq1TpAUnSkKFjtOGHJTp3NlqdOvfW4Ld76+NP5yg+/moOXR3Swz33Dj5hxWVcjlXgq/3kU6KMdO2qEpbMlE9ocfkUKqL8fcfIp8g9Sj60V9cXz0q7fzba5Xuxq64v/Vy6fk2SlLxvt/wfr6WC781Q0q7Nsl+IVmDEIF2dyLCjnGJPtql8vapq/EGEbIlJ2jzxG0mSYbOr2eQ39EDDJ/TX2l268M+ZdPfPqJ092aYCRYP02nejFHhXIS3rMVWSdGTLn3qgcTW9vnqMDn63U5dPn1eziW9oYccPcuaCPYzZw8RcxS1Jom+//Vbff/+9zp8/ryZNmmjHjh0KCAjQ888/rzZt2nhNx+3/wsfHJ903l81mMyEa5BTuu/fKF5hPgyb1V0h4iAa8MsjscIA8g75Giuz8/sisze3bLBaLbDa7JGnZsu+1bFlKZVaZMiVV7YlHNWz4OH044T2Vv6+0NmzcqslTZrr6kpAF7rl3sPj6ya/yE7o67j+yHTkov0dqqECf0VLiDflVrKqrHw2TkhIV+PoA5Wv9qq5//WnqA/j5ZtrOt9yDshQqrKQdG2/uYxhK+OJm1VhA05eV+NNq+RQqrHyd/yP5+un6sjmyn2DooTsdWrdbh9bt1sMvPa228wbpk1p9JcPQyrc+1erBn6v19LdUs3cr/TTp23T3z6jd1fNx+qhaT4U9VErtFgzWnObDFHv0nL4bONux71O9Wuj3RZsUeHchNRnfRT7+ftr84RJHFRK8g1uGm9ntdlmtVhUrVkydO3dWQECAYxv/6M3ciZOnFR4e6lguVixMsbEXde1a2pJCeA7uu3cKCQ/RtBVTZLfZ9dYL/RQfx19qgeyir5EiO78/Mmtz8sRp3XvLtvDwUJ0+dTbNeSaMH64Bg0bouWdrqlChAmravIMa1H9aZcuWcs+FIUPcc+9gv3RB9rMnZDtyUFLKcDP5+EjWfEravTWl+seWrKTIDfIt+2Ca/Y2LFzJt5/9EHSVtXy9lUPlguTtEfg8+qqQtqxXQoqNurP1GCXMnK/Bl70jAm+GukqEq/tjNh5j8sXiTChcrqgcaV1PBkCKSpKRrN7R/ZaTCHiqVZv8ytSql2y6gUKDur/+Yo925P48pev9xBVcokWr/oPB7VOrfD+n3RZtUq28b7Zy9WqsHf6567/KgjezylOFmbkkS1atXT6+88opsNpt69uwpSTp48KDatWunhg0buuOUHmP9+s2q9sSjKleutCSpa5f2WrmKuSs8Hffd+wQWCNTkJR9qy+qtGtF9lBKvJ5odEpCn0NdIkZ3fH5m1WblqrV7t9JJ8fX1VuHCQXnihuVasXJNq/8aNntPp0+f0++/7FBAQoOTklCScYRgKDMzn7kvEbbjn3iF5z8+yFA1zPNHMt3wlyTB0Y9V8+T9RW/K3SpL8H/23bMf+SrN/0q4tmbbzu7+ykvf/luH5A1/qqutLZkuGIYufv2S3pfy/NSDDfeCcgiFF1HJaTwXelfIkwoda/Fsxf51UmVqVVPOtlHnDfK1+eqBJNR3bvi/N/g80qZ5uO7vNrsbjuzgSUEXvK6Z7yobrzG//pNr/uaEva+PYhZJhyM/qJ7vNJsNul38g9zy7DBf+Zya3DDfr3bu3fvnlF/n6+jrWWa1W9ezZU7Vr13bHKT1GTMwFvR7RV4sWzpTV6q8j/xxXp869zQ4LbsZ99z4tO7VQaPEQ1Wzwb9Vs8G/H+r4vDlDcpTgTIwPyBvoaKTL6/VH10cqaMWOCHnu8Xqa/Y6bPmKsyZUrp193rZfW3atbsefppyw7H8a1Wq4YM7q3GTVMek75u/Wa90a2jDu7fqo0/btOffx405bq9GffcOxhxF3Vt6nAFtu+VMpl0cpKuTXtPtsP7ZSlYSAWHfyr5+Mh2/G9dX5jy5LGAFh0lSTeWf6nEjSszbCdJPqHFZD9/Lt1z+z74qIzrCbIdOZByvLVLFPhaf0kWXV/4abr7wHknf/lL26Yt1yuLhspItutK9EUt6TJJ1y9fVcNRnRWxbqwk6dDaXfr587WSpFp9U55s99PEb/XD+/PTb2cY+iZiouoOe0W+fn5KTkzS8t4f68q5WMe5S/27ohKvXteZ31KGEu6Y9b2ajO8qi0VaP/KrnPwxIBewGHlgdiU/azGzQwDgRk+FPGB2CDDB8YQYs0NADjt64Q+zQ8gQfQ3As114mb6GN5q2MTTrRvAoQ47PN+3cD4VWd9mx/ozakXUjN+FZywAAAAAAAE4we5iYq5AkAgAAAAAAcII99w/Syha3TFwNAAAAAACAvIVKIgAAAAAAACcw3AwAAAAAAAAMNwMAAAAAAIDnoJIIAAAAAADACQw3AwAAAAAAAMPNAAAAAAAA4DmoJAIAAAAAAHACw80AAAAAAAAgw7CbHYJLMNwMAAAAAAAAVBIBAAAAAAA4w85wMwAAAAAAABge8nQzkkQAAAAAAABO8JRKIuYkAgAAAAAAAJVEAAAAAAAAzmC4GQAAAAAAAGT3kCQRw80AAAAAAABAJREAAAAAAIAzDA+ZuJokEQAAAAAAgBM8ZU4ihpsBAAAAAACASiIAAAAAAABn2BluBgAAAAAAAIabAQAAAAAAwGNQSQQAAAAAAOAEu4dUEpEkAgAAAAAAcIKnDDcjSQQAAAAAAOAET5m4mjmJAAAAAAAAQCURAAAAAACAMxhuBgAAAAAAAI+ZuJrhZgAAAAAAAKCSCAAAAAAAwBmGh0xcTZIIAAAAAADACQw3AwAAAAAAgMegkggAAAAAAMAJPN0MAAAAAAAAzEkEAAAAAAAAz6kkYk4iAAAAAACAPGjVqlVq1KiR6tWrp/nz56fZfuDAAbVq1Ur169fXkCFDlJycnOnxSBIBAAAAAAA4wTAMl72yKyoqSpMmTdKCBQu0fPlyLVq0SIcPH07Vpn///ho2bJjWrl0rwzC0ePHiTI9JkggAAAAAAMAJhgtfcXFxOnXqVJpXXFxcqnNu375d1atXV5EiRZQ/f37Vr19fa9ascWw/ffq0rl+/rocffliS1KpVq1Tb05Mn5iRKTjxtdggAAMCD0dcAAM8zxOwA4FVc2ZeYOnWqpk2blmZ9jx491LNnT8dydHS0goODHcshISHas2dPhtuDg4MVFRWV6bnzRJIIAAAAAADAG3Ts2FEtW7ZMsz4oKCjVst1ul8VicSwbhpFqOavt6SFJBAAAAAAAkEsEBQWlSQilJywsTLt27XIsx8TEKCQkJNX2mJgYx/L58+dTbU8PcxIBAAAAAADkMTVq1FBkZKRiY2OVkJCgdevWqVatWo7txYoVU0BAgHbv3i1JWrFiRart6bEYdzJ1NgAAAAAAAHKFVatWacaMGUpKSlKbNm0UERGhiIgI9erVS5UqVdLBgwc1dOhQxcfHq2LFihozZoysVmuGxyNJBAAAAAAAAIabAQAAAAAAgCQRAAAAAAAARJIIAAAAAAAAIkkEAAAAAAAAkSTKtVatWqVGjRqpXr16mj9/vtnhIIfEx8erSZMmOnXqlNmhIAdMmzZNjRs3VuPGjTVu3Dizw0EOmDJliho1aqTGjRvriy++MDsceDn6Gt6Hfob3oa/hfehrwFkkiXKhqKgoTZo0SQsWLNDy5cu1aNEiHT582Oyw4GZ//PGH2rZtq2PHjpkdCnLA9u3btXXrVi1btkzLly/Xvn37tH79erPDghv9/PPP2rFjh1auXKlvv/1W8+bN05EjR8wOC16Kvob3oZ/hfehreB/6GnAFkkS50Pbt21W9enUVKVJE+fPnV/369bVmzRqzw4KbLV68WMOHD1dISIjZoSAHBAcHa9CgQbJarfL391fZsmV15swZs8OCGz3xxBOaO3eu/Pz8dOHCBdlsNuXPn9/ssOCl6Gt4H/oZ3oe+hvehrwFX8DM7AKQVHR2t4OBgx3JISIj27NljYkTICaNGjTI7BOSg++67z/H/x44d0+rVq/X111+bGBFygr+/vz766CN9/vnnatCggUJDQ80OCV6Kvob3oZ/hfehreCf6GnAWlUS5kN1ul8VicSwbhpFqGYDn+Pvvv9W5c2cNGDBApUqVMjsc5IBevXopMjJSZ8+e1eLFi80OB16KvgbgPehreB/6GnAGSaJcKCwsTDExMY7lmJgYSoMBD7R792516tRJ/fr1U8uWLc0OB272zz//6MCBA5KkwMBA1atXT3/99ZfJUcFb0dcAvAN9De9CXwOuQJIoF6pRo4YiIyMVGxurhIQErVu3TrVq1TI7LAAudPbsWXXv3l0TJkxQ48aNzQ4HOeDUqVMaOnSoEhMTlZiYqA0bNqhq1apmhwUvRV8D8Hz0NbwPfQ24AnMS5UKhoaHq06ePOnTooKSkJLVp00aVK1c2OywALvTZZ5/pxo0bGjt2rGPdSy+9pLZt25oYFdypdu3a2rNnj1q0aCFfX1/Vq1ePTjtMQ18D8Hz0NbwPfQ24gsUwDMPsIAAAAAAAAGAuhpsBAAAAAACAJBEAAAAAAABIEgEAAAAAAEAkiQAAAAAAACCSRAAAAAAAABBJIsBrnDp1Sg888ICaN2/ueDVr1kzffPON08fu2rWrli5dKklq3ry54uLiMmx75coVdejQ4Y7PsWbNGrVv3z7N+p07d6pJkyZZ7n///fcrNjb2js45aNAgffbZZ3e0DwAA3oq+Bn0NAHmfn9kBAMg5+fLl04oVKxzLUVFRatKkiR566CFVqFDBJee49fjpuXz5svbu3euScwEAgNyFvgYA5G0kiQAvFhoaqpIlS+rYsWPav3+/vvnmGyUkJKhgwYKaN2+elixZoq+//lp2u11FihTRO++8o7JlyyoqKkqDBg1SdHS0wsPDdeHCBccx77//fkVGRuruu+/WjBkztGzZMvn5+alkyZIaO3as3n77bV2/fl3NmzfX0qVLdezYMY0aNUqXLl2SzWZT+/bt1aZNG0nSlClTtGrVKhUpUkQlS5bM8nqOHj2qESNG6OrVq4qJiVGFChU0efJkBQQESJImT56svXv3ym6366233tLTTz8tSRleJwAAcA59DfoaAPIWkkSAF/vtt9904sQJValSRZGRkTp8+LA2btyoggUL6ueff9by5cs1f/58BQYGauvWrerRo4dWr16tESNGqEqVKnrrrbd0/PhxtWjRIs2xN2zYoKVLl2rx4sUqXLiwxowZo6+++kpjxoxR06ZNtWLFCiUnJ6tXr14aN26cKlasqCtXrujFF19UuXLldP78ea1bt07Lly9Xvnz51L179yyvZ/HixWrRooWaN2+upKQktWrVSps2bVL9+vUlScWLF9eIESN06NAhtW/fXqtXr9bhw4czvE4AAOAc+hr0NQDkLSSJAC/yv7+qSZLNZtNdd92l8ePH695775WU8pe5ggULSpI2bdqk48eP66WXXnLsHxcXp0uXLmn79u0aOHCgJKlkyZKqVq1amnNFRkaqQYMGKly4sCTp7bfflpQyX8H/HDt2TCdOnNDgwYNTxbh//379888/qlu3riOe1q1ba968eZleX//+/bVt2zbNmjVLx44dU3R0tK5du+bY3rZtW0lS+fLlVbZsWf3222/avXt3htcJAADuDH0N+hoA8jaSRIAXuX2egNvlz5/f8f92u13NmzdX//79HcvR0dEqXLiwLBaLDMNwtPXzS/tV4uvrK4vF4liOi4tLM8mkzWZToUKFUsV0/vx5FSpUSOPGjUt1Dl9f3yyvr2/fvrLZbGrYsKHq1Kmjs2fPpjqGj8/Nufrtdrv8/PwyvU4AAHBn6GvQ1wCQt/F0MwDpeuqpp/Tdd98pOjpakvT111+rY8eOkqSaNWtq0aJFkqQzZ85o586dafavUaOG1q9fr/j4eEnS1KlTNWfOHPn5+clms8kwDJUuXTpVZ/Ls2bNq0qSJ/vzzT9WqVUtr1qxRXFyc7HZ7lpNUStLWrVvVvXt3NWrUSJL0xx9/yGazObYvW7ZMkrRv3z5H6Xtm1wkAANyHvgYA5D5UEgFI11NPPaWIiAh17txZFotFBQsW1LRp02SxWDR8+HC9/fbbatiwocLCwtJ9Wknt2rV1+PBhR9l1uXLlNHLkSAUGBqpy5cpq3Lix5s+fr08++USjRo3S7NmzlZycrN69e6tq1aqSpL/++kutW7dWUFCQKlSooIsXL2Yac58+fdS9e3flz59fBQsW1OOPP64TJ044tp88eVItWrSQxWLRxIkTVaRIkUyvEwAAuA99DfoaAHIfi3FrfSQAAAAAAAC8EsPNAAAAAAAAQJIIAAAAAAAAJIkAAAAAAAAgkkQAAAAAAAAQSSIAAAAAAACIJBEAAAAAAABEkggAAAAAAAAiSQQAAAAAAABJ/w+iKzCQ5zLjgQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # CNN Variables\n",
    "    # Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "    # Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = fv_train.shape[2] # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "signal = fv_train.shape[1]\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_all'\n",
    "\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1) \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(signal,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train, etiq_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"\\n\\n==================================== Modele evaluation ====================================\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===========================================================================================\\n\\n\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute une augmentation avec le SMOTE et on voit l'impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dataset_smote(path, etiq, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    fv_train_list = list()\n",
    "    fv_test_list = list()\n",
    "    etiq[\"class\"] = etiq[\"class\"].astype('category').cat.codes\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            fv_train, fv_test, etiq_train, etiq_test = train_test_split(monfichier, etiq, test_size=test_size, random_state=42)\n",
    "            fv_train_aug = sensor_augmentor(fv_train)\n",
    "            etiq_train_aug = etiq_augmentor(etiq_train)\n",
    "            sm = SMOTE(random_state=42)\n",
    "            fv_train_aug_res, etiq_train_aug_res = sm.fit_resample(fv_train_aug, etiq_train_aug)\n",
    "            fv_train_list.append(fv_train_aug_res)\n",
    "            fv_test_list.append(fv_test)\n",
    "    fv_train_list = np.dstack(fv_train_list)\n",
    "    fv_test_list = np.dstack(fv_test_list)\n",
    "    return fv_train_list, fv_test_list, etiq_train_aug_res, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1120, 4000, 8), (24, 4000, 8), (1120, 1), (24, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = stack_dataset_smote(path, etiq)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6394 - accuracy: 0.6808\n",
      "Epoch 1: accuracy improved from -inf to 0.68080, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 20s 86ms/step - loss: 0.6394 - accuracy: 0.6808 - val_loss: 1.3061 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.8382\n",
      "Epoch 2: accuracy improved from 0.68080 to 0.83817, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 21s 94ms/step - loss: 0.3738 - accuracy: 0.8382 - val_loss: 1.4232 - val_accuracy: 0.2277\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.8929\n",
      "Epoch 3: accuracy improved from 0.83817 to 0.89286, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 19s 86ms/step - loss: 0.2740 - accuracy: 0.8929 - val_loss: 0.7819 - val_accuracy: 0.5759\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.9107\n",
      "Epoch 4: accuracy improved from 0.89286 to 0.91071, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 19s 85ms/step - loss: 0.2201 - accuracy: 0.9107 - val_loss: 0.4924 - val_accuracy: 0.9688\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9375\n",
      "Epoch 5: accuracy improved from 0.91071 to 0.93750, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 24s 105ms/step - loss: 0.1739 - accuracy: 0.9375 - val_loss: 0.3144 - val_accuracy: 0.9777\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.9520\n",
      "Epoch 6: accuracy improved from 0.93750 to 0.95201, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 27s 121ms/step - loss: 0.1322 - accuracy: 0.9520 - val_loss: 0.6756 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9520\n",
      "Epoch 7: accuracy did not improve from 0.95201\n",
      "224/224 [==============================] - 23s 104ms/step - loss: 0.1409 - accuracy: 0.9520 - val_loss: 0.3857 - val_accuracy: 0.9509\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9487\n",
      "Epoch 8: accuracy did not improve from 0.95201\n",
      "224/224 [==============================] - 22s 97ms/step - loss: 0.1448 - accuracy: 0.9487 - val_loss: 0.2194 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9453\n",
      "Epoch 9: accuracy did not improve from 0.95201\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.1688 - accuracy: 0.9453 - val_loss: 0.4458 - val_accuracy: 0.9062\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9598\n",
      "Epoch 10: accuracy improved from 0.95201 to 0.95982, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 25s 113ms/step - loss: 0.1173 - accuracy: 0.9598 - val_loss: 0.4158 - val_accuracy: 0.9107\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9487\n",
      "Epoch 11: accuracy did not improve from 0.95982\n",
      "224/224 [==============================] - 25s 111ms/step - loss: 0.1236 - accuracy: 0.9487 - val_loss: 0.3319 - val_accuracy: 0.9911\n",
      "Epoch 12/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9721\n",
      "Epoch 12: accuracy improved from 0.95982 to 0.97210, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 25s 114ms/step - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.1277 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9587\n",
      "Epoch 13: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 24s 106ms/step - loss: 0.0900 - accuracy: 0.9587 - val_loss: 0.2154 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9520\n",
      "Epoch 14: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.1181 - accuracy: 0.9520 - val_loss: 0.1367 - val_accuracy: 0.9955\n",
      "Epoch 15/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.9699\n",
      "Epoch 15: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0903 - accuracy: 0.9699 - val_loss: 0.1643 - val_accuracy: 0.9821\n",
      "Epoch 16/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9587\n",
      "Epoch 16: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.0973 - accuracy: 0.9587 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0926 - accuracy: 0.9643\n",
      "Epoch 17: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 102ms/step - loss: 0.0926 - accuracy: 0.9643 - val_loss: 0.3111 - val_accuracy: 0.9732\n",
      "Epoch 18/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9688\n",
      "Epoch 18: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0958 - accuracy: 0.9688 - val_loss: 0.2453 - val_accuracy: 0.9821\n",
      "Epoch 19/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9565\n",
      "Epoch 19: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.1093 - accuracy: 0.9565 - val_loss: 0.3804 - val_accuracy: 0.8393\n",
      "Epoch 20/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0912 - accuracy: 0.9643\n",
      "Epoch 20: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0912 - accuracy: 0.9643 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9721\n",
      "Epoch 21: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0890 - accuracy: 0.9721 - val_loss: 0.1171 - val_accuracy: 0.9955\n",
      "Epoch 22/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.9598\n",
      "Epoch 22: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.1210 - accuracy: 0.9598 - val_loss: 0.2795 - val_accuracy: 0.9241\n",
      "Epoch 23/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9699\n",
      "Epoch 23: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0745 - accuracy: 0.9699 - val_loss: 0.0961 - val_accuracy: 0.9911\n",
      "Epoch 24/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9643\n",
      "Epoch 24: accuracy did not improve from 0.97210\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.0933 - accuracy: 0.9643 - val_loss: 0.1821 - val_accuracy: 0.9688\n",
      "Epoch 25/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9743\n",
      "Epoch 25: accuracy improved from 0.97210 to 0.97433, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 26s 118ms/step - loss: 0.0773 - accuracy: 0.9743 - val_loss: 0.1453 - val_accuracy: 0.9955\n",
      "Epoch 26/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9710\n",
      "Epoch 26: accuracy did not improve from 0.97433\n",
      "224/224 [==============================] - 25s 111ms/step - loss: 0.0767 - accuracy: 0.9710 - val_loss: 0.1464 - val_accuracy: 0.9911\n",
      "Epoch 27/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9754\n",
      "Epoch 27: accuracy improved from 0.97433 to 0.97545, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.2111 - val_accuracy: 0.9777\n",
      "Epoch 28/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9621\n",
      "Epoch 28: accuracy did not improve from 0.97545\n",
      "224/224 [==============================] - 24s 106ms/step - loss: 0.1090 - accuracy: 0.9621 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9777\n",
      "Epoch 29: accuracy improved from 0.97545 to 0.97768, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 26s 118ms/step - loss: 0.0583 - accuracy: 0.9777 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9654\n",
      "Epoch 30: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 24s 105ms/step - loss: 0.0929 - accuracy: 0.9654 - val_loss: 0.2799 - val_accuracy: 0.8795\n",
      "Epoch 31/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.9699\n",
      "Epoch 31: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 23s 103ms/step - loss: 0.1136 - accuracy: 0.9699 - val_loss: 0.1917 - val_accuracy: 0.9598\n",
      "Epoch 32/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9509\n",
      "Epoch 32: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 23s 102ms/step - loss: 0.1347 - accuracy: 0.9509 - val_loss: 0.1314 - val_accuracy: 0.9866\n",
      "Epoch 33/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9754\n",
      "Epoch 33: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.0713 - accuracy: 0.9754 - val_loss: 0.1124 - val_accuracy: 0.9866\n",
      "Epoch 34/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9754\n",
      "Epoch 34: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 23s 102ms/step - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9676\n",
      "Epoch 35: accuracy did not improve from 0.97768\n",
      "224/224 [==============================] - 23s 102ms/step - loss: 0.0865 - accuracy: 0.9676 - val_loss: 0.1021 - val_accuracy: 0.9866\n",
      "Epoch 36/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9788\n",
      "Epoch 36: accuracy improved from 0.97768 to 0.97879, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 27s 120ms/step - loss: 0.0669 - accuracy: 0.9788 - val_loss: 0.0893 - val_accuracy: 0.9955\n",
      "Epoch 37/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9799\n",
      "Epoch 37: accuracy improved from 0.97879 to 0.97991, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 27s 120ms/step - loss: 0.0578 - accuracy: 0.9799 - val_loss: 0.1123 - val_accuracy: 0.9777\n",
      "Epoch 38/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9732\n",
      "Epoch 38: accuracy did not improve from 0.97991\n",
      "224/224 [==============================] - 23s 102ms/step - loss: 0.0692 - accuracy: 0.9732 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9732\n",
      "Epoch 39: accuracy did not improve from 0.97991\n",
      "224/224 [==============================] - 17s 78ms/step - loss: 0.0638 - accuracy: 0.9732 - val_loss: 0.2299 - val_accuracy: 0.9018\n",
      "Epoch 40/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9810\n",
      "Epoch 40: accuracy improved from 0.97991 to 0.98103, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 20s 90ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.1309 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 41: accuracy improved from 0.98103 to 0.98549, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 21s 94ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.2066 - val_accuracy: 0.9821\n",
      "Epoch 42/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9710\n",
      "Epoch 42: accuracy did not improve from 0.98549\n",
      "224/224 [==============================] - 18s 80ms/step - loss: 0.1008 - accuracy: 0.9710 - val_loss: 0.0719 - val_accuracy: 0.9955\n",
      "Epoch 43/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9877\n",
      "Epoch 43: accuracy improved from 0.98549 to 0.98772, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 24s 106ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.0845 - val_accuracy: 0.9732\n",
      "Epoch 44/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.9799\n",
      "Epoch 44: accuracy did not improve from 0.98772\n",
      "224/224 [==============================] - 22s 99ms/step - loss: 0.0634 - accuracy: 0.9799 - val_loss: 0.1663 - val_accuracy: 0.9866\n",
      "Epoch 45/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9821\n",
      "Epoch 45: accuracy did not improve from 0.98772\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9810\n",
      "Epoch 46: accuracy did not improve from 0.98772\n",
      "224/224 [==============================] - 22s 100ms/step - loss: 0.0456 - accuracy: 0.9810 - val_loss: 0.3103 - val_accuracy: 0.8125\n",
      "Epoch 47/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9888\n",
      "Epoch 47: accuracy improved from 0.98772 to 0.98884, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 28s 123ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.0622 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9721\n",
      "Epoch 48: accuracy did not improve from 0.98884\n",
      "224/224 [==============================] - 24s 105ms/step - loss: 0.1016 - accuracy: 0.9721 - val_loss: 0.1284 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9676\n",
      "Epoch 49: accuracy did not improve from 0.98884\n",
      "224/224 [==============================] - 23s 101ms/step - loss: 0.1016 - accuracy: 0.9676 - val_loss: 0.1089 - val_accuracy: 0.9821\n",
      "Epoch 50/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9911\n",
      "Epoch 50: accuracy improved from 0.98884 to 0.99107, saving model to .\\Model_CNN1D_all_aug_smote\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all_aug_smote\\assets\n",
      "224/224 [==============================] - 27s 119ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0568 - val_accuracy: 0.9732\n",
      "\n",
      "\n",
      "==================================== Modele evaluation ====================================\n",
      "6/6 [==============================] - 1s 22ms/step - loss: 0.2208 - accuracy: 0.8750\n",
      "===========================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 8.959999999999994, 'Predicted label')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1224x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # CNN Variables\n",
    "    # Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "    # Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = fv_train.shape[2] # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "signal = fv_train.shape[1]\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_all_aug_smote'\n",
    "\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1) \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(signal,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train, etiq_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"\\n\\n==================================== Modele evaluation ====================================\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===========================================================================================\\n\\n\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(17, 6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.subplot(1,2,2)\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
