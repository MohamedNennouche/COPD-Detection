{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For data preparation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsaug.visualization import plot\n",
    "from tsaug import TimeWarp, Drift, AddNoise\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# For Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPool1D, GlobalAvgPool1D, Conv1D, Dropout, BatchNormalization\n",
    "\n",
    "# for callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0   0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  ...   \n",
       "1   0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  ...   \n",
       "2   0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  ...   \n",
       "3   0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  ...   \n",
       "4   0.311  0.311  0.310  0.310  0.311  0.311  0.311  0.311  0.310  0.310  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "73  0.534  0.534  0.534  0.533  0.534  0.534  0.534  0.534  0.534  0.534  ...   \n",
       "74  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  ...   \n",
       "75  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  ...   \n",
       "76  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  ...   \n",
       "77  0.499  0.498  0.498  0.500  0.501  0.500  0.499  0.498  0.498  0.500  ...   \n",
       "\n",
       "     3990   3991   3992   3993   3994   3995   3996   3997   3998   3999  \n",
       "0   0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  \n",
       "1   0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  \n",
       "2   0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  \n",
       "3   0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  \n",
       "4   0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "73  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  \n",
       "74  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  \n",
       "75  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  \n",
       "76  0.533  0.533  0.534  0.534  0.533  0.533  0.532  0.533  0.534  0.534  \n",
       "77  0.537  0.536  0.536  0.538  0.538  0.538  0.537  0.536  0.536  0.537  \n",
       "\n",
       "[78 rows x 4000 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur = pd.read_csv('./capteurs/capteur1.csv')\n",
    "moncapteur.drop(['class'], inplace=True, axis=1)\n",
    "moncapteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_augmentor(data, min_drift=0.01, max_drift=0.5, noise_scale=0.01) :\n",
    "    aug = list()\n",
    "    data_np = data.to_numpy()\n",
    "    my_augmenter = (\n",
    "    TimeWarp() * 9  # random time warping 5 times in parallel\n",
    "    + Drift(max_drift=(min_drift, max_drift), normalize=False) @ 0.8  # with 80% probability, random drift the signal up to 10% - 50%\n",
    "    + AddNoise(scale = noise_scale, normalize=False)\n",
    "    )\n",
    "    for i in range(len(data_np)) :\n",
    "        data_aug = my_augmenter.augment(data_np[i])\n",
    "        aug.append(data_np[i])\n",
    "        for j in range(len(data_aug)) :\n",
    "            aug.append(data_aug[j])\n",
    "    aug = pd.DataFrame(np.array(aug))\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364156</td>\n",
       "      <td>0.378683</td>\n",
       "      <td>0.372879</td>\n",
       "      <td>0.361974</td>\n",
       "      <td>0.362171</td>\n",
       "      <td>0.371224</td>\n",
       "      <td>0.344020</td>\n",
       "      <td>0.352066</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.365244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485993</td>\n",
       "      <td>0.463324</td>\n",
       "      <td>0.480339</td>\n",
       "      <td>0.476956</td>\n",
       "      <td>0.482231</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.469020</td>\n",
       "      <td>0.474191</td>\n",
       "      <td>0.468157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366862</td>\n",
       "      <td>0.356675</td>\n",
       "      <td>0.388042</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.349150</td>\n",
       "      <td>0.349274</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.338096</td>\n",
       "      <td>0.341106</td>\n",
       "      <td>0.343496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014765</td>\n",
       "      <td>-0.025081</td>\n",
       "      <td>-0.032131</td>\n",
       "      <td>-0.022032</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.048137</td>\n",
       "      <td>-0.029698</td>\n",
       "      <td>-0.017716</td>\n",
       "      <td>-0.032249</td>\n",
       "      <td>-0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351590</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.356407</td>\n",
       "      <td>0.362540</td>\n",
       "      <td>0.379932</td>\n",
       "      <td>0.366316</td>\n",
       "      <td>0.349279</td>\n",
       "      <td>0.355828</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.335954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384784</td>\n",
       "      <td>0.389841</td>\n",
       "      <td>0.390302</td>\n",
       "      <td>0.404228</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.419539</td>\n",
       "      <td>0.396586</td>\n",
       "      <td>0.410527</td>\n",
       "      <td>0.400557</td>\n",
       "      <td>0.385790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344956</td>\n",
       "      <td>0.336467</td>\n",
       "      <td>0.364882</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.375884</td>\n",
       "      <td>0.367871</td>\n",
       "      <td>0.364426</td>\n",
       "      <td>0.357146</td>\n",
       "      <td>0.364711</td>\n",
       "      <td>0.370581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.408257</td>\n",
       "      <td>0.414288</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.397301</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>0.404936</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.412672</td>\n",
       "      <td>0.411266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.497093</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>0.513879</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.517910</td>\n",
       "      <td>0.505985</td>\n",
       "      <td>0.502690</td>\n",
       "      <td>0.511066</td>\n",
       "      <td>0.491397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418397</td>\n",
       "      <td>0.428239</td>\n",
       "      <td>0.432160</td>\n",
       "      <td>0.429026</td>\n",
       "      <td>0.420147</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.438237</td>\n",
       "      <td>0.447698</td>\n",
       "      <td>0.416030</td>\n",
       "      <td>0.420932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.498814</td>\n",
       "      <td>0.488423</td>\n",
       "      <td>0.502799</td>\n",
       "      <td>0.499497</td>\n",
       "      <td>0.501253</td>\n",
       "      <td>0.493455</td>\n",
       "      <td>0.500181</td>\n",
       "      <td>0.505838</td>\n",
       "      <td>0.483716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577963</td>\n",
       "      <td>0.556866</td>\n",
       "      <td>0.556088</td>\n",
       "      <td>0.569385</td>\n",
       "      <td>0.562203</td>\n",
       "      <td>0.569491</td>\n",
       "      <td>0.573152</td>\n",
       "      <td>0.578188</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>0.551418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.494743</td>\n",
       "      <td>0.511701</td>\n",
       "      <td>0.509370</td>\n",
       "      <td>0.505052</td>\n",
       "      <td>0.509264</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.510799</td>\n",
       "      <td>0.484825</td>\n",
       "      <td>0.498904</td>\n",
       "      <td>0.485448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537978</td>\n",
       "      <td>0.548109</td>\n",
       "      <td>0.515739</td>\n",
       "      <td>0.553441</td>\n",
       "      <td>0.529777</td>\n",
       "      <td>0.544534</td>\n",
       "      <td>0.519150</td>\n",
       "      <td>0.529582</td>\n",
       "      <td>0.529647</td>\n",
       "      <td>0.544920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.493094</td>\n",
       "      <td>0.487513</td>\n",
       "      <td>0.515591</td>\n",
       "      <td>0.503687</td>\n",
       "      <td>0.504404</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>0.503241</td>\n",
       "      <td>0.497535</td>\n",
       "      <td>0.484604</td>\n",
       "      <td>0.505965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541662</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>0.521827</td>\n",
       "      <td>0.532745</td>\n",
       "      <td>0.526595</td>\n",
       "      <td>0.538083</td>\n",
       "      <td>0.524346</td>\n",
       "      <td>0.536636</td>\n",
       "      <td>0.552469</td>\n",
       "      <td>0.515137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.504833</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.503814</td>\n",
       "      <td>0.499123</td>\n",
       "      <td>0.488024</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>0.486648</td>\n",
       "      <td>0.501345</td>\n",
       "      <td>0.505648</td>\n",
       "      <td>0.501868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536016</td>\n",
       "      <td>0.530725</td>\n",
       "      <td>0.524395</td>\n",
       "      <td>0.519044</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.511505</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>0.524819</td>\n",
       "      <td>0.514952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    0.361000  0.361000  0.361000  0.361000  0.361000  0.361000  0.361000   \n",
       "1    0.364156  0.378683  0.372879  0.361974  0.362171  0.371224  0.344020   \n",
       "2    0.366862  0.356675  0.388042  0.352015  0.349150  0.349274  0.343032   \n",
       "3    0.351590  0.349079  0.356407  0.362540  0.379932  0.366316  0.349279   \n",
       "4    0.344956  0.336467  0.364882  0.368661  0.375884  0.367871  0.364426   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "775  0.497093  0.510929  0.513879  0.485446  0.477273  0.517910  0.505985   \n",
       "776  0.503185  0.498814  0.488423  0.502799  0.499497  0.501253  0.493455   \n",
       "777  0.494743  0.511701  0.509370  0.505052  0.509264  0.501589  0.510799   \n",
       "778  0.493094  0.487513  0.515591  0.503687  0.504404  0.492395  0.503241   \n",
       "779  0.504833  0.486870  0.503814  0.499123  0.488024  0.517235  0.486648   \n",
       "\n",
       "         7         8         9     ...      3990      3991      3992  \\\n",
       "0    0.361000  0.361000  0.361000  ...  0.405000  0.405000  0.405000   \n",
       "1    0.352066  0.356300  0.365244  ...  0.485993  0.463324  0.480339   \n",
       "2    0.338096  0.341106  0.343496  ... -0.014765 -0.025081 -0.032131   \n",
       "3    0.355828  0.361407  0.335954  ...  0.384784  0.389841  0.390302   \n",
       "4    0.357146  0.364711  0.370581  ...  0.418301  0.408257  0.414288   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "775  0.502690  0.511066  0.491397  ...  0.418397  0.428239  0.432160   \n",
       "776  0.500181  0.505838  0.483716  ...  0.577963  0.556866  0.556088   \n",
       "777  0.484825  0.498904  0.485448  ...  0.537978  0.548109  0.515739   \n",
       "778  0.497535  0.484604  0.505965  ...  0.541662  0.540490  0.521827   \n",
       "779  0.501345  0.505648  0.501868  ...  0.536016  0.530725  0.524395   \n",
       "\n",
       "         3993      3994      3995      3996      3997      3998      3999  \n",
       "0    0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  \n",
       "1    0.476956  0.482231  0.466606  0.464111  0.469020  0.474191  0.468157  \n",
       "2   -0.022032 -0.033654 -0.048137 -0.029698 -0.017716 -0.032249 -0.034994  \n",
       "3    0.404228  0.400156  0.419539  0.396586  0.410527  0.400557  0.385790  \n",
       "4    0.396241  0.397301  0.397942  0.404936  0.411167  0.412672  0.411266  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "775  0.429026  0.420147  0.423853  0.438237  0.447698  0.416030  0.420932  \n",
       "776  0.569385  0.562203  0.569491  0.573152  0.578188  0.568186  0.551418  \n",
       "777  0.553441  0.529777  0.544534  0.519150  0.529582  0.529647  0.544920  \n",
       "778  0.532745  0.526595  0.538083  0.524346  0.536636  0.552469  0.515137  \n",
       "779  0.519044  0.530628  0.511505  0.519417  0.532555  0.524819  0.514952  \n",
       "\n",
       "[780 rows x 4000 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur_aug = sensor_augmentor(moncapteur)\n",
    "moncapteur_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les signaux concaténés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataset(path, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    monDataset = list()\n",
    "    etiq = 0\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            monfichier.reset_index(inplace=True, drop=True)\n",
    "            monDataset.append(monfichier)\n",
    "        else :\n",
    "            monfichier = os.listdir(all_path)\n",
    "            all_path_etiq = os.path.join(all_path,monfichier[0])\n",
    "            etiq = pd.read_csv(all_path_etiq)\n",
    "            etiq[\"class\"] = etiq[\"class\"].astype('category').cat.codes\n",
    "    monDataset = pd.concat(monDataset, axis=1)\n",
    "    fv_train, fv_test, etiq_train, etiq_test = train_test_split(monDataset, etiq, test_size=test_size, random_state=42)\n",
    "    return fv_train, fv_test, etiq_train, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 32000), (24, 32000), (54, 1), (24, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./capteurs\"\n",
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 32000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_list = etiq_train.to_numpy()\n",
    "etiq_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "etiq_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.5255\n",
      "Epoch 1: accuracy improved from -inf to 0.52546, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 59s 529ms/step - loss: 1.2220 - accuracy: 0.5255 - val_loss: 1.2981 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1736 - accuracy: 0.5347\n",
      "Epoch 2: accuracy improved from 0.52546 to 0.53472, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 47s 441ms/step - loss: 1.1736 - accuracy: 0.5347 - val_loss: 1.2628 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6620\n",
      "Epoch 3: accuracy improved from 0.53472 to 0.66204, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 48s 447ms/step - loss: 0.8564 - accuracy: 0.6620 - val_loss: 0.9742 - val_accuracy: 0.5463\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6852\n",
      "Epoch 4: accuracy improved from 0.66204 to 0.68519, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 586ms/step - loss: 0.7615 - accuracy: 0.6852 - val_loss: 0.8974 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7106\n",
      "Epoch 5: accuracy improved from 0.68519 to 0.71065, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 53s 492ms/step - loss: 0.6782 - accuracy: 0.7106 - val_loss: 0.8265 - val_accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.7338\n",
      "Epoch 6: accuracy improved from 0.71065 to 0.73380, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 54s 499ms/step - loss: 0.6749 - accuracy: 0.7338 - val_loss: 0.8168 - val_accuracy: 0.6389\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7222\n",
      "Epoch 7: accuracy did not improve from 0.73380\n",
      "108/108 [==============================] - 52s 486ms/step - loss: 0.6923 - accuracy: 0.7222 - val_loss: 0.8588 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7569\n",
      "Epoch 8: accuracy improved from 0.73380 to 0.75694, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 70s 645ms/step - loss: 0.6460 - accuracy: 0.7569 - val_loss: 0.8738 - val_accuracy: 0.7315\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7106\n",
      "Epoch 9: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 66s 615ms/step - loss: 0.7092 - accuracy: 0.7106 - val_loss: 0.8857 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7500\n",
      "Epoch 10: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 68s 631ms/step - loss: 0.6209 - accuracy: 0.7500 - val_loss: 0.7919 - val_accuracy: 0.6296\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7454\n",
      "Epoch 11: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 635ms/step - loss: 0.6163 - accuracy: 0.7454 - val_loss: 0.8248 - val_accuracy: 0.5648\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7384\n",
      "Epoch 12: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.6250 - accuracy: 0.7384 - val_loss: 0.8651 - val_accuracy: 0.5926\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7315\n",
      "Epoch 13: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 67s 618ms/step - loss: 0.6576 - accuracy: 0.7315 - val_loss: 0.8066 - val_accuracy: 0.6111\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7685\n",
      "Epoch 14: accuracy improved from 0.75694 to 0.76852, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 580ms/step - loss: 0.5973 - accuracy: 0.7685 - val_loss: 0.7505 - val_accuracy: 0.6204\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7338\n",
      "Epoch 15: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 536ms/step - loss: 0.6462 - accuracy: 0.7338 - val_loss: 0.7762 - val_accuracy: 0.6111\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.7315\n",
      "Epoch 16: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 0.7790 - accuracy: 0.7315 - val_loss: 0.7598 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7477\n",
      "Epoch 17: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 63s 583ms/step - loss: 0.6375 - accuracy: 0.7477 - val_loss: 0.7674 - val_accuracy: 0.7685\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7431\n",
      "Epoch 18: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 541ms/step - loss: 0.6131 - accuracy: 0.7431 - val_loss: 0.8928 - val_accuracy: 0.5370\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.7454\n",
      "Epoch 19: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 54s 503ms/step - loss: 0.6195 - accuracy: 0.7454 - val_loss: 0.9111 - val_accuracy: 0.5370\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.7361\n",
      "Epoch 20: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 62s 577ms/step - loss: 1.6257 - accuracy: 0.7361 - val_loss: 0.8013 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.6829\n",
      "Epoch 21: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.7483 - accuracy: 0.6829 - val_loss: 0.7993 - val_accuracy: 0.5833\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7292\n",
      "Epoch 22: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.6588 - accuracy: 0.7292 - val_loss: 0.7822 - val_accuracy: 0.6204\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7523\n",
      "Epoch 23: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 644ms/step - loss: 0.6137 - accuracy: 0.7523 - val_loss: 0.7414 - val_accuracy: 0.6481\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7384\n",
      "Epoch 24: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 68s 626ms/step - loss: 0.6227 - accuracy: 0.7384 - val_loss: 0.7636 - val_accuracy: 0.6019\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7708\n",
      "Epoch 25: accuracy improved from 0.76852 to 0.77083, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 72s 662ms/step - loss: 0.5843 - accuracy: 0.7708 - val_loss: 0.7146 - val_accuracy: 0.6574\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7569\n",
      "Epoch 26: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.5474 - accuracy: 0.7569 - val_loss: 0.7628 - val_accuracy: 0.5741\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7454\n",
      "Epoch 27: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.5668 - accuracy: 0.7454 - val_loss: 0.6763 - val_accuracy: 0.6852\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7708\n",
      "Epoch 28: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 630ms/step - loss: 0.5229 - accuracy: 0.7708 - val_loss: 0.7059 - val_accuracy: 0.6204\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7593\n",
      "Epoch 29: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5250 - accuracy: 0.7593 - val_loss: 0.7393 - val_accuracy: 0.5741\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7569\n",
      "Epoch 30: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 639ms/step - loss: 0.5652 - accuracy: 0.7569 - val_loss: 0.8189 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7639\n",
      "Epoch 31: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 647ms/step - loss: 0.5143 - accuracy: 0.7639 - val_loss: 0.7004 - val_accuracy: 0.6111\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7708\n",
      "Epoch 32: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.6931 - val_accuracy: 0.6019\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7801\n",
      "Epoch 33: accuracy improved from 0.77083 to 0.78009, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 71s 662ms/step - loss: 0.4928 - accuracy: 0.7801 - val_loss: 0.7624 - val_accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7569\n",
      "Epoch 34: accuracy did not improve from 0.78009\n",
      "108/108 [==============================] - 70s 648ms/step - loss: 0.5300 - accuracy: 0.7569 - val_loss: 0.6581 - val_accuracy: 0.6389\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.7917\n",
      "Epoch 35: accuracy improved from 0.78009 to 0.79167, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4880 - accuracy: 0.7917 - val_loss: 0.5843 - val_accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7801\n",
      "Epoch 36: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4671 - accuracy: 0.7801 - val_loss: 0.6422 - val_accuracy: 0.6204\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.7778\n",
      "Epoch 37: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 679ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7940\n",
      "Epoch 38: accuracy improved from 0.79167 to 0.79398, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 79s 728ms/step - loss: 0.4951 - accuracy: 0.7940 - val_loss: 0.6788 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7778\n",
      "Epoch 39: accuracy did not improve from 0.79398\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4953 - accuracy: 0.7778 - val_loss: 0.6452 - val_accuracy: 0.6204\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7963\n",
      "Epoch 40: accuracy improved from 0.79398 to 0.79630, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 78s 725ms/step - loss: 0.4604 - accuracy: 0.7963 - val_loss: 0.5846 - val_accuracy: 0.6944\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7870\n",
      "Epoch 41: accuracy did not improve from 0.79630\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4502 - accuracy: 0.7870 - val_loss: 0.5741 - val_accuracy: 0.7130\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.8079\n",
      "Epoch 42: accuracy improved from 0.79630 to 0.80787, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 77s 716ms/step - loss: 0.4457 - accuracy: 0.8079 - val_loss: 0.5664 - val_accuracy: 0.6574\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7986\n",
      "Epoch 43: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 692ms/step - loss: 0.4567 - accuracy: 0.7986 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7801\n",
      "Epoch 44: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 690ms/step - loss: 0.4811 - accuracy: 0.7801 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7755\n",
      "Epoch 45: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 669ms/step - loss: 0.4563 - accuracy: 0.7755 - val_loss: 0.6284 - val_accuracy: 0.6296\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8056\n",
      "Epoch 46: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 671ms/step - loss: 0.4378 - accuracy: 0.8056 - val_loss: 0.5989 - val_accuracy: 0.6852\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8102\n",
      "Epoch 47: accuracy improved from 0.80787 to 0.81019, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.4459 - accuracy: 0.8102 - val_loss: 0.5648 - val_accuracy: 0.6852\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7894\n",
      "Epoch 48: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 75s 697ms/step - loss: 0.4452 - accuracy: 0.7894 - val_loss: 0.6263 - val_accuracy: 0.5926\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7894\n",
      "Epoch 49: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 74s 681ms/step - loss: 0.4409 - accuracy: 0.7894 - val_loss: 0.4967 - val_accuracy: 0.7407\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8148\n",
      "Epoch 50: accuracy improved from 0.81019 to 0.81481, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 81s 749ms/step - loss: 0.4634 - accuracy: 0.8148 - val_loss: 0.5925 - val_accuracy: 0.6574\n",
      "====== Modele evaluation ======\n",
      "6/6 [==============================] - 2s 179ms/step - loss: 0.5821 - accuracy: 0.7083\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec une autre disposition du dataset (on prend 50-50 test entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2876 - accuracy: 0.4744\n",
      "Epoch 1: accuracy improved from -inf to 0.47436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 44s 561ms/step - loss: 1.2876 - accuracy: 0.4744 - val_loss: 1.2897 - val_accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2548 - accuracy: 0.4872\n",
      "Epoch 2: accuracy improved from 0.47436 to 0.48718, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 48s 612ms/step - loss: 1.2548 - accuracy: 0.4872 - val_loss: 1.2656 - val_accuracy: 0.4872\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2293 - accuracy: 0.4872\n",
      "Epoch 3: accuracy did not improve from 0.48718\n",
      "78/78 [==============================] - 43s 551ms/step - loss: 1.2293 - accuracy: 0.4872 - val_loss: 1.2371 - val_accuracy: 0.4872\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1603 - accuracy: 0.5288\n",
      "Epoch 4: accuracy improved from 0.48718 to 0.52885, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 38s 491ms/step - loss: 1.1603 - accuracy: 0.5288 - val_loss: 1.0273 - val_accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8944 - accuracy: 0.6346\n",
      "Epoch 5: accuracy improved from 0.52885 to 0.63462, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 36s 460ms/step - loss: 0.8944 - accuracy: 0.6346 - val_loss: 0.8807 - val_accuracy: 0.6282\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8453 - accuracy: 0.6571\n",
      "Epoch 6: accuracy improved from 0.63462 to 0.65705, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.8453 - accuracy: 0.6571 - val_loss: 0.8299 - val_accuracy: 0.7179\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7266 - accuracy: 0.6859\n",
      "Epoch 7: accuracy improved from 0.65705 to 0.68590, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 35s 456ms/step - loss: 0.7266 - accuracy: 0.6859 - val_loss: 0.7660 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7929 - accuracy: 0.6378\n",
      "Epoch 8: accuracy did not improve from 0.68590\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.7929 - accuracy: 0.6378 - val_loss: 0.8949 - val_accuracy: 0.6026\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.7115\n",
      "Epoch 9: accuracy improved from 0.68590 to 0.71154, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 44s 560ms/step - loss: 0.6993 - accuracy: 0.7115 - val_loss: 0.9557 - val_accuracy: 0.5256\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7564 - accuracy: 0.6795\n",
      "Epoch 10: accuracy did not improve from 0.71154\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.7564 - accuracy: 0.6795 - val_loss: 0.8713 - val_accuracy: 0.6538\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.7147\n",
      "Epoch 11: accuracy improved from 0.71154 to 0.71474, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 43s 551ms/step - loss: 0.6728 - accuracy: 0.7147 - val_loss: 0.7354 - val_accuracy: 0.7308\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.7212\n",
      "Epoch 12: accuracy improved from 0.71474 to 0.72115, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 544ms/step - loss: 0.6372 - accuracy: 0.7212 - val_loss: 0.6706 - val_accuracy: 0.8077\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6402 - accuracy: 0.7019\n",
      "Epoch 13: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 522ms/step - loss: 0.6402 - accuracy: 0.7019 - val_loss: 0.6819 - val_accuracy: 0.7308\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6129 - accuracy: 0.7212\n",
      "Epoch 14: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 530ms/step - loss: 0.6129 - accuracy: 0.7212 - val_loss: 0.8202 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7051\n",
      "Epoch 15: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 0.6588 - accuracy: 0.7051 - val_loss: 0.8742 - val_accuracy: 0.6026\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6555 - accuracy: 0.6987\n",
      "Epoch 16: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 40s 510ms/step - loss: 0.6555 - accuracy: 0.6987 - val_loss: 0.7781 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.7212\n",
      "Epoch 17: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.6204 - accuracy: 0.7212 - val_loss: 0.7299 - val_accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6360 - accuracy: 0.7051\n",
      "Epoch 18: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.6360 - accuracy: 0.7051 - val_loss: 0.7110 - val_accuracy: 0.7308\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6318 - accuracy: 0.7179\n",
      "Epoch 19: accuracy did not improve from 0.72115\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 0.6318 - accuracy: 0.7179 - val_loss: 0.8609 - val_accuracy: 0.6026\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6297 - accuracy: 0.7244\n",
      "Epoch 20: accuracy improved from 0.72115 to 0.72436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.6297 - accuracy: 0.7244 - val_loss: 0.6788 - val_accuracy: 0.7308\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6132 - accuracy: 0.7244\n",
      "Epoch 21: accuracy did not improve from 0.72436\n",
      "78/78 [==============================] - 39s 504ms/step - loss: 0.6132 - accuracy: 0.7244 - val_loss: 0.6193 - val_accuracy: 0.7308\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.7340\n",
      "Epoch 22: accuracy improved from 0.72436 to 0.73397, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 531ms/step - loss: 0.6127 - accuracy: 0.7340 - val_loss: 0.6713 - val_accuracy: 0.7308\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.7115\n",
      "Epoch 23: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.6794 - accuracy: 0.7115 - val_loss: 0.5675 - val_accuracy: 0.7821\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.7083\n",
      "Epoch 24: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6427 - accuracy: 0.7083 - val_loss: 0.7387 - val_accuracy: 0.6538\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.7115\n",
      "Epoch 25: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.7141 - accuracy: 0.7115 - val_loss: 0.6177 - val_accuracy: 0.7692\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7179\n",
      "Epoch 26: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 40s 508ms/step - loss: 0.6191 - accuracy: 0.7179 - val_loss: 0.6374 - val_accuracy: 0.7436\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6098 - accuracy: 0.7147\n",
      "Epoch 27: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 33s 427ms/step - loss: 0.6098 - accuracy: 0.7147 - val_loss: 0.5601 - val_accuracy: 0.7436\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6116 - accuracy: 0.7051\n",
      "Epoch 28: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 32s 411ms/step - loss: 0.6116 - accuracy: 0.7051 - val_loss: 0.6067 - val_accuracy: 0.7179\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.6955\n",
      "Epoch 29: accuracy did not improve from 0.73397\n",
      "78/78 [==============================] - 32s 416ms/step - loss: 0.6346 - accuracy: 0.6955 - val_loss: 0.6143 - val_accuracy: 0.7436\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7500\n",
      "Epoch 30: accuracy improved from 0.73397 to 0.75000, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 37s 472ms/step - loss: 0.5588 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7308\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.7628\n",
      "Epoch 31: accuracy improved from 0.75000 to 0.76282, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 538ms/step - loss: 0.5247 - accuracy: 0.7628 - val_loss: 0.6115 - val_accuracy: 0.7179\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7276\n",
      "Epoch 32: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.5745 - accuracy: 0.7276 - val_loss: 0.6677 - val_accuracy: 0.6538\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5732 - accuracy: 0.7115\n",
      "Epoch 33: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 39s 497ms/step - loss: 0.5732 - accuracy: 0.7115 - val_loss: 0.5990 - val_accuracy: 0.8462\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5522 - accuracy: 0.7596\n",
      "Epoch 34: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 38s 492ms/step - loss: 0.5522 - accuracy: 0.7596 - val_loss: 0.6097 - val_accuracy: 0.7179\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7821\n",
      "Epoch 35: accuracy improved from 0.76282 to 0.78205, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 522ms/step - loss: 0.5238 - accuracy: 0.7821 - val_loss: 0.7427 - val_accuracy: 0.7051\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7500\n",
      "Epoch 36: accuracy did not improve from 0.78205\n",
      "78/78 [==============================] - 39s 496ms/step - loss: 0.5312 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7436\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4932 - accuracy: 0.7821\n",
      "Epoch 37: accuracy did not improve from 0.78205\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 0.4932 - accuracy: 0.7821 - val_loss: 0.4978 - val_accuracy: 0.7436\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.7949\n",
      "Epoch 38: accuracy improved from 0.78205 to 0.79487, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 40s 519ms/step - loss: 0.4802 - accuracy: 0.7949 - val_loss: 0.5058 - val_accuracy: 0.9103\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.7404\n",
      "Epoch 39: accuracy did not improve from 0.79487\n",
      "78/78 [==============================] - 40s 509ms/step - loss: 0.5290 - accuracy: 0.7404 - val_loss: 0.5708 - val_accuracy: 0.7821\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8141\n",
      "Epoch 40: accuracy improved from 0.79487 to 0.81410, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 526ms/step - loss: 0.4459 - accuracy: 0.8141 - val_loss: 0.4636 - val_accuracy: 0.8205\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.8045\n",
      "Epoch 41: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 39s 499ms/step - loss: 0.4801 - accuracy: 0.8045 - val_loss: 0.4322 - val_accuracy: 0.8462\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8109\n",
      "Epoch 42: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 40s 517ms/step - loss: 0.4358 - accuracy: 0.8109 - val_loss: 0.4631 - val_accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.7853\n",
      "Epoch 43: accuracy did not improve from 0.81410\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.4529 - accuracy: 0.7853 - val_loss: 0.4692 - val_accuracy: 0.8590\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.8173\n",
      "Epoch 44: accuracy improved from 0.81410 to 0.81731, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 0.4334 - accuracy: 0.8173 - val_loss: 0.4261 - val_accuracy: 0.8205\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8205\n",
      "Epoch 45: accuracy improved from 0.81731 to 0.82051, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 545ms/step - loss: 0.4072 - accuracy: 0.8205 - val_loss: 0.6082 - val_accuracy: 0.7692\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4761 - accuracy: 0.7821\n",
      "Epoch 46: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 41s 528ms/step - loss: 0.4761 - accuracy: 0.7821 - val_loss: 0.4299 - val_accuracy: 0.8718\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.7949\n",
      "Epoch 47: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.4353 - accuracy: 0.7949 - val_loss: 0.5750 - val_accuracy: 0.7949\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.7885\n",
      "Epoch 48: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 40s 512ms/step - loss: 0.4605 - accuracy: 0.7885 - val_loss: 0.5117 - val_accuracy: 0.8205\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4186 - accuracy: 0.8109\n",
      "Epoch 49: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 498ms/step - loss: 0.4186 - accuracy: 0.8109 - val_loss: 0.5938 - val_accuracy: 0.7821\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4579 - accuracy: 0.8013\n",
      "Epoch 50: accuracy did not improve from 0.82051\n",
      "78/78 [==============================] - 39s 505ms/step - loss: 0.4579 - accuracy: 0.8013 - val_loss: 0.5292 - val_accuracy: 0.7692\n",
      "====== Modele evaluation ======\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 0.4963 - accuracy: 0.8205\n",
      "===============================\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024A629D3A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.5)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tente maintenant de rééquilibrer les classes et voir l'impact d'une telle opération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    190\n",
       "1    100\n",
       "0     60\n",
       "3     40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_train_aug.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 32000, 1), (390, 32000))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train_aug_res = np.add.reduce(fv_train_aug, axis=2)\n",
    "fv_train_aug.shape, fv_train_aug_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    190\n",
       "1    190\n",
       "2    190\n",
       "3    190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "fv_train_aug_res, etiq_train_aug_res = sm.fit_resample(fv_train_aug_res, etiq_train_aug)\n",
    "etiq_train_aug_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On restructure la matrices des caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_train_aug_res = np.expand_dims(fv_train_aug_res, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 1.2420 - accuracy: 0.3569\n",
      "Epoch 1: accuracy improved from -inf to 0.35691, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 512ms/step - loss: 1.2420 - accuracy: 0.3569 - val_loss: 1.7605 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.8672 - accuracy: 0.6382\n",
      "Epoch 2: accuracy improved from 0.35691 to 0.63816, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 84s 557ms/step - loss: 0.8672 - accuracy: 0.6382 - val_loss: 1.5540 - val_accuracy: 0.0066\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6582 - accuracy: 0.7155\n",
      "Epoch 3: accuracy improved from 0.63816 to 0.71546, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 84s 553ms/step - loss: 0.6582 - accuracy: 0.7155 - val_loss: 1.4605 - val_accuracy: 0.0066\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.7319\n",
      "Epoch 4: accuracy improved from 0.71546 to 0.73191, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 82s 542ms/step - loss: 0.6249 - accuracy: 0.7319 - val_loss: 1.2720 - val_accuracy: 0.0066\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.7368\n",
      "Epoch 5: accuracy improved from 0.73191 to 0.73684, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 527ms/step - loss: 0.5970 - accuracy: 0.7368 - val_loss: 1.2002 - val_accuracy: 0.0066\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.7336\n",
      "Epoch 6: accuracy did not improve from 0.73684\n",
      "152/152 [==============================] - 77s 510ms/step - loss: 0.5893 - accuracy: 0.7336 - val_loss: 1.3993 - val_accuracy: 0.0066\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5684 - accuracy: 0.7434\n",
      "Epoch 7: accuracy improved from 0.73684 to 0.74342, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 82s 537ms/step - loss: 0.5684 - accuracy: 0.7434 - val_loss: 1.0069 - val_accuracy: 0.0066\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.7303\n",
      "Epoch 8: accuracy did not improve from 0.74342\n",
      "152/152 [==============================] - 79s 523ms/step - loss: 0.6518 - accuracy: 0.7303 - val_loss: 1.3450 - val_accuracy: 0.0132\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.7549\n",
      "Epoch 9: accuracy improved from 0.74342 to 0.75493, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 83s 550ms/step - loss: 0.5685 - accuracy: 0.7549 - val_loss: 0.9886 - val_accuracy: 0.0066\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5838 - accuracy: 0.7385\n",
      "Epoch 10: accuracy did not improve from 0.75493\n",
      "152/152 [==============================] - 81s 534ms/step - loss: 0.5838 - accuracy: 0.7385 - val_loss: 1.0963 - val_accuracy: 0.0066\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7582\n",
      "Epoch 11: accuracy improved from 0.75493 to 0.75822, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 85s 560ms/step - loss: 0.5368 - accuracy: 0.7582 - val_loss: 1.3550 - val_accuracy: 0.0132\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7484\n",
      "Epoch 12: accuracy did not improve from 0.75822\n",
      "152/152 [==============================] - 78s 511ms/step - loss: 0.5236 - accuracy: 0.7484 - val_loss: 1.0154 - val_accuracy: 0.0132\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.7796\n",
      "Epoch 13: accuracy improved from 0.75822 to 0.77961, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 524ms/step - loss: 0.4800 - accuracy: 0.7796 - val_loss: 1.3345 - val_accuracy: 0.0066\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.7401\n",
      "Epoch 14: accuracy did not improve from 0.77961\n",
      "152/152 [==============================] - 70s 464ms/step - loss: 0.5595 - accuracy: 0.7401 - val_loss: 1.2105 - val_accuracy: 0.0132\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4543 - accuracy: 0.7911\n",
      "Epoch 15: accuracy improved from 0.77961 to 0.79112, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 64s 424ms/step - loss: 0.4543 - accuracy: 0.7911 - val_loss: 1.3838 - val_accuracy: 0.0066\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8174\n",
      "Epoch 16: accuracy improved from 0.79112 to 0.81743, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 73s 480ms/step - loss: 0.4134 - accuracy: 0.8174 - val_loss: 1.2903 - val_accuracy: 0.1645\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.7993\n",
      "Epoch 17: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 78s 515ms/step - loss: 0.4412 - accuracy: 0.7993 - val_loss: 1.2466 - val_accuracy: 0.1908\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.7796\n",
      "Epoch 18: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 79s 523ms/step - loss: 0.4343 - accuracy: 0.7796 - val_loss: 1.3134 - val_accuracy: 0.1908\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.7993\n",
      "Epoch 19: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 80s 524ms/step - loss: 0.3976 - accuracy: 0.7993 - val_loss: 1.2405 - val_accuracy: 0.3092\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4972 - accuracy: 0.7961\n",
      "Epoch 20: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 80s 525ms/step - loss: 0.4972 - accuracy: 0.7961 - val_loss: 1.2137 - val_accuracy: 0.2171\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8125\n",
      "Epoch 21: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 77s 506ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 1.7915 - val_accuracy: 0.0724\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.8026\n",
      "Epoch 22: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 76s 499ms/step - loss: 0.4262 - accuracy: 0.8026 - val_loss: 2.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8043\n",
      "Epoch 23: accuracy did not improve from 0.81743\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.4009 - accuracy: 0.8043 - val_loss: 1.8837 - val_accuracy: 0.1447\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3741 - accuracy: 0.8355\n",
      "Epoch 24: accuracy improved from 0.81743 to 0.83553, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 521ms/step - loss: 0.3741 - accuracy: 0.8355 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.8158\n",
      "Epoch 25: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 78s 511ms/step - loss: 0.3864 - accuracy: 0.8158 - val_loss: 1.4892 - val_accuracy: 0.2171\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8141\n",
      "Epoch 26: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 78s 514ms/step - loss: 0.3871 - accuracy: 0.8141 - val_loss: 1.0401 - val_accuracy: 0.4276\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8306\n",
      "Epoch 27: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 79s 521ms/step - loss: 0.3736 - accuracy: 0.8306 - val_loss: 1.3841 - val_accuracy: 0.2632\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3818 - accuracy: 0.7993\n",
      "Epoch 28: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.3818 - accuracy: 0.7993 - val_loss: 1.8269 - val_accuracy: 0.2105\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.8224\n",
      "Epoch 29: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 76s 500ms/step - loss: 0.3597 - accuracy: 0.8224 - val_loss: 1.2364 - val_accuracy: 0.2697\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8240\n",
      "Epoch 30: accuracy did not improve from 0.83553\n",
      "152/152 [==============================] - 77s 505ms/step - loss: 0.3517 - accuracy: 0.8240 - val_loss: 1.3795 - val_accuracy: 0.2434\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.8421\n",
      "Epoch 31: accuracy improved from 0.83553 to 0.84211, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 79s 518ms/step - loss: 0.3399 - accuracy: 0.8421 - val_loss: 1.8186 - val_accuracy: 0.2368\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.8322\n",
      "Epoch 32: accuracy did not improve from 0.84211\n",
      "152/152 [==============================] - 77s 510ms/step - loss: 0.3475 - accuracy: 0.8322 - val_loss: 1.8173 - val_accuracy: 0.2171\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3739 - accuracy: 0.8503\n",
      "Epoch 33: accuracy improved from 0.84211 to 0.85033, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 80s 527ms/step - loss: 0.3739 - accuracy: 0.8503 - val_loss: 2.9008 - val_accuracy: 0.0921\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8257\n",
      "Epoch 34: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 79s 519ms/step - loss: 0.3684 - accuracy: 0.8257 - val_loss: 1.1877 - val_accuracy: 0.4145\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.8289\n",
      "Epoch 35: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 76s 499ms/step - loss: 0.3629 - accuracy: 0.8289 - val_loss: 1.5839 - val_accuracy: 0.2632\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8438\n",
      "Epoch 36: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 73s 479ms/step - loss: 0.3401 - accuracy: 0.8438 - val_loss: 1.8477 - val_accuracy: 0.2039\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.8224\n",
      "Epoch 37: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 435ms/step - loss: 0.3424 - accuracy: 0.8224 - val_loss: 1.2970 - val_accuracy: 0.3553\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8405\n",
      "Epoch 38: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 437ms/step - loss: 0.3501 - accuracy: 0.8405 - val_loss: 1.5855 - val_accuracy: 0.3092\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8339\n",
      "Epoch 39: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 66s 433ms/step - loss: 0.3587 - accuracy: 0.8339 - val_loss: 1.6373 - val_accuracy: 0.2961\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3482 - accuracy: 0.8257\n",
      "Epoch 40: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 68s 448ms/step - loss: 0.3482 - accuracy: 0.8257 - val_loss: 1.9749 - val_accuracy: 0.2368\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.7928\n",
      "Epoch 41: accuracy did not improve from 0.85033\n",
      "152/152 [==============================] - 68s 447ms/step - loss: 0.3764 - accuracy: 0.7928 - val_loss: 1.5320 - val_accuracy: 0.3355\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8569\n",
      "Epoch 42: accuracy improved from 0.85033 to 0.85691, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 72s 472ms/step - loss: 0.3333 - accuracy: 0.8569 - val_loss: 1.3635 - val_accuracy: 0.3553\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.8355\n",
      "Epoch 43: accuracy did not improve from 0.85691\n",
      "152/152 [==============================] - 72s 476ms/step - loss: 0.3628 - accuracy: 0.8355 - val_loss: 1.5731 - val_accuracy: 0.3026\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8651\n",
      "Epoch 44: accuracy improved from 0.85691 to 0.86513, saving model to .\\Model_CNN1D_32000_aug_4\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_4\\assets\n",
      "152/152 [==============================] - 75s 496ms/step - loss: 0.3113 - accuracy: 0.8651 - val_loss: 1.4154 - val_accuracy: 0.3421\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.8454\n",
      "Epoch 45: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 72s 473ms/step - loss: 0.3355 - accuracy: 0.8454 - val_loss: 2.1457 - val_accuracy: 0.2039\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8306\n",
      "Epoch 46: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 76s 501ms/step - loss: 0.3815 - accuracy: 0.8306 - val_loss: 1.9493 - val_accuracy: 0.2566\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8470\n",
      "Epoch 47: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 78s 516ms/step - loss: 0.3528 - accuracy: 0.8470 - val_loss: 2.0758 - val_accuracy: 0.2434\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3241 - accuracy: 0.8388\n",
      "Epoch 48: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 83s 544ms/step - loss: 0.3241 - accuracy: 0.8388 - val_loss: 1.7179 - val_accuracy: 0.2105\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8651\n",
      "Epoch 49: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 82s 539ms/step - loss: 0.3055 - accuracy: 0.8651 - val_loss: 2.6262 - val_accuracy: 0.1842\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8339\n",
      "Epoch 50: accuracy did not improve from 0.86513\n",
      "152/152 [==============================] - 82s 541ms/step - loss: 0.3311 - accuracy: 0.8339 - val_loss: 1.6475 - val_accuracy: 0.3224\n",
      "====== Modele evaluation ======\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.4125 - accuracy: 0.8462\n",
      "===============================\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024A62C70430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_4'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug_res, etiq_train_aug_res, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "cmn = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essai maintenant avec un ratio 60% de test - 40% d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.2785 - accuracy: 0.4718\n",
      "Epoch 1: accuracy improved from -inf to 0.47177, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 536ms/step - loss: 1.2785 - accuracy: 0.4718 - val_loss: 1.2889 - val_accuracy: 0.4839\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.2400 - accuracy: 0.4839\n",
      "Epoch 2: accuracy improved from 0.47177 to 0.48387, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 535ms/step - loss: 1.2400 - accuracy: 0.4839 - val_loss: 1.2202 - val_accuracy: 0.4839\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 1.0836 - accuracy: 0.5726\n",
      "Epoch 3: accuracy improved from 0.48387 to 0.57258, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 566ms/step - loss: 1.0836 - accuracy: 0.5726 - val_loss: 0.9509 - val_accuracy: 0.6452\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.8477 - accuracy: 0.6895\n",
      "Epoch 4: accuracy improved from 0.57258 to 0.68952, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 570ms/step - loss: 0.8477 - accuracy: 0.6895 - val_loss: 0.8375 - val_accuracy: 0.7097\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.7584 - accuracy: 0.7218\n",
      "Epoch 5: accuracy improved from 0.68952 to 0.72177, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 584ms/step - loss: 0.7584 - accuracy: 0.7218 - val_loss: 0.9001 - val_accuracy: 0.6290\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.7379\n",
      "Epoch 6: accuracy improved from 0.72177 to 0.73790, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 38s 607ms/step - loss: 0.6992 - accuracy: 0.7379 - val_loss: 0.7414 - val_accuracy: 0.7903\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.7419\n",
      "Epoch 7: accuracy improved from 0.73790 to 0.74194, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 565ms/step - loss: 0.6853 - accuracy: 0.7419 - val_loss: 0.8746 - val_accuracy: 0.7097\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.7742\n",
      "Epoch 8: accuracy improved from 0.74194 to 0.77419, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 40s 641ms/step - loss: 0.5776 - accuracy: 0.7742 - val_loss: 0.7738 - val_accuracy: 0.7097\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7500\n",
      "Epoch 9: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 508ms/step - loss: 0.6071 - accuracy: 0.7500 - val_loss: 0.7004 - val_accuracy: 0.7258\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.7460\n",
      "Epoch 10: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 503ms/step - loss: 0.5984 - accuracy: 0.7460 - val_loss: 0.6509 - val_accuracy: 0.7742\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7581\n",
      "Epoch 11: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 504ms/step - loss: 0.5692 - accuracy: 0.7581 - val_loss: 0.6081 - val_accuracy: 0.8065\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.7621\n",
      "Epoch 12: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 31s 505ms/step - loss: 0.5429 - accuracy: 0.7621 - val_loss: 0.5334 - val_accuracy: 0.9032\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5655 - accuracy: 0.7621\n",
      "Epoch 13: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 521ms/step - loss: 0.5655 - accuracy: 0.7621 - val_loss: 0.6077 - val_accuracy: 0.7903\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.7621\n",
      "Epoch 14: accuracy did not improve from 0.77419\n",
      "62/62 [==============================] - 32s 523ms/step - loss: 0.5263 - accuracy: 0.7621 - val_loss: 0.5933 - val_accuracy: 0.7742\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.7944\n",
      "Epoch 15: accuracy improved from 0.77419 to 0.79435, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 587ms/step - loss: 0.4744 - accuracy: 0.7944 - val_loss: 0.6004 - val_accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.7661\n",
      "Epoch 16: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 43s 690ms/step - loss: 0.5270 - accuracy: 0.7661 - val_loss: 0.7878 - val_accuracy: 0.6935\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.7782\n",
      "Epoch 17: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 40s 646ms/step - loss: 0.4915 - accuracy: 0.7782 - val_loss: 0.8171 - val_accuracy: 0.6613\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.7903\n",
      "Epoch 18: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 43s 692ms/step - loss: 0.5114 - accuracy: 0.7903 - val_loss: 0.5651 - val_accuracy: 0.7742\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4820 - accuracy: 0.7863\n",
      "Epoch 19: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 33s 540ms/step - loss: 0.4820 - accuracy: 0.7863 - val_loss: 0.5375 - val_accuracy: 0.8065\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.7661\n",
      "Epoch 20: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 516ms/step - loss: 0.4686 - accuracy: 0.7661 - val_loss: 0.6606 - val_accuracy: 0.7581\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.7379\n",
      "Epoch 21: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 520ms/step - loss: 0.5800 - accuracy: 0.7379 - val_loss: 0.6668 - val_accuracy: 0.6452\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7782\n",
      "Epoch 22: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 524ms/step - loss: 0.4928 - accuracy: 0.7782 - val_loss: 0.6197 - val_accuracy: 0.7581\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.7903\n",
      "Epoch 23: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.4386 - accuracy: 0.7903 - val_loss: 0.4940 - val_accuracy: 0.8226\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.7823\n",
      "Epoch 24: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 32s 523ms/step - loss: 0.4565 - accuracy: 0.7823 - val_loss: 0.5896 - val_accuracy: 0.7419\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.7702\n",
      "Epoch 25: accuracy did not improve from 0.79435\n",
      "62/62 [==============================] - 38s 607ms/step - loss: 0.5017 - accuracy: 0.7702 - val_loss: 0.6688 - val_accuracy: 0.7581\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8065\n",
      "Epoch 26: accuracy improved from 0.79435 to 0.80645, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 40s 647ms/step - loss: 0.4315 - accuracy: 0.8065 - val_loss: 0.7249 - val_accuracy: 0.6935\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.7903\n",
      "Epoch 27: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.4878 - accuracy: 0.7903 - val_loss: 0.6290 - val_accuracy: 0.7258\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.7984\n",
      "Epoch 28: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 561ms/step - loss: 0.4322 - accuracy: 0.7984 - val_loss: 0.6581 - val_accuracy: 0.7258\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4647 - accuracy: 0.8024\n",
      "Epoch 29: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 563ms/step - loss: 0.4647 - accuracy: 0.8024 - val_loss: 0.6840 - val_accuracy: 0.6774\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8065\n",
      "Epoch 30: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 35s 563ms/step - loss: 0.4415 - accuracy: 0.8065 - val_loss: 0.4839 - val_accuracy: 0.7903\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4318 - accuracy: 0.8065\n",
      "Epoch 31: accuracy did not improve from 0.80645\n",
      "62/62 [==============================] - 30s 491ms/step - loss: 0.4318 - accuracy: 0.8065 - val_loss: 0.5981 - val_accuracy: 0.7419\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.8105\n",
      "Epoch 32: accuracy improved from 0.80645 to 0.81048, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 36s 576ms/step - loss: 0.4260 - accuracy: 0.8105 - val_loss: 0.5798 - val_accuracy: 0.7581\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4334 - accuracy: 0.7903\n",
      "Epoch 33: accuracy did not improve from 0.81048\n",
      "62/62 [==============================] - 32s 509ms/step - loss: 0.4334 - accuracy: 0.7903 - val_loss: 0.6283 - val_accuracy: 0.7581\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.8145\n",
      "Epoch 34: accuracy improved from 0.81048 to 0.81452, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 35s 571ms/step - loss: 0.4169 - accuracy: 0.8145 - val_loss: 0.6161 - val_accuracy: 0.7258\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.7500\n",
      "Epoch 35: accuracy did not improve from 0.81452\n",
      "62/62 [==============================] - 32s 513ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.5458 - val_accuracy: 0.7903\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4028 - accuracy: 0.7903\n",
      "Epoch 36: accuracy did not improve from 0.81452\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.4028 - accuracy: 0.7903 - val_loss: 0.5064 - val_accuracy: 0.7903\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.8468\n",
      "Epoch 37: accuracy improved from 0.81452 to 0.84677, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.3756 - accuracy: 0.8468 - val_loss: 0.4874 - val_accuracy: 0.7742\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8024\n",
      "Epoch 38: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 30s 482ms/step - loss: 0.4148 - accuracy: 0.8024 - val_loss: 0.5318 - val_accuracy: 0.7903\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8387\n",
      "Epoch 39: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 31s 509ms/step - loss: 0.3586 - accuracy: 0.8387 - val_loss: 0.5351 - val_accuracy: 0.7903\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.7588 - accuracy: 0.7903\n",
      "Epoch 40: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 30s 487ms/step - loss: 0.7588 - accuracy: 0.7903 - val_loss: 0.6496 - val_accuracy: 0.6935\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.8347\n",
      "Epoch 41: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 528ms/step - loss: 0.4307 - accuracy: 0.8347 - val_loss: 0.3593 - val_accuracy: 0.8871\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.8266\n",
      "Epoch 42: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 532ms/step - loss: 0.3742 - accuracy: 0.8266 - val_loss: 0.8458 - val_accuracy: 0.6613\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8266\n",
      "Epoch 43: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 33s 532ms/step - loss: 0.3964 - accuracy: 0.8266 - val_loss: 0.4944 - val_accuracy: 0.7581\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8065\n",
      "Epoch 44: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 32s 521ms/step - loss: 0.3805 - accuracy: 0.8065 - val_loss: 0.3971 - val_accuracy: 0.7581\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8347\n",
      "Epoch 45: accuracy did not improve from 0.84677\n",
      "62/62 [==============================] - 31s 502ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.5147 - val_accuracy: 0.7903\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.8629\n",
      "Epoch 46: accuracy improved from 0.84677 to 0.86290, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 529ms/step - loss: 0.3253 - accuracy: 0.8629 - val_loss: 0.4234 - val_accuracy: 0.8226\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.8468\n",
      "Epoch 47: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 28s 453ms/step - loss: 0.3553 - accuracy: 0.8468 - val_loss: 0.5469 - val_accuracy: 0.7419\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.8468\n",
      "Epoch 48: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 29s 475ms/step - loss: 0.3287 - accuracy: 0.8468 - val_loss: 0.5762 - val_accuracy: 0.7419\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 0.8629\n",
      "Epoch 49: accuracy did not improve from 0.86290\n",
      "62/62 [==============================] - 32s 511ms/step - loss: 0.3263 - accuracy: 0.8629 - val_loss: 0.3746 - val_accuracy: 0.7903\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8710\n",
      "Epoch 50: accuracy improved from 0.86290 to 0.87097, saving model to .\\Model_CNN1D_32000_aug_3\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_3\\assets\n",
      "62/62 [==============================] - 33s 527ms/step - loss: 0.3401 - accuracy: 0.8710 - val_loss: 0.4033 - val_accuracy: 0.7903\n",
      "====== Modele evaluation ======\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.4510 - accuracy: 0.8085\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.6)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat/np.sum(con_mat), annot=True, fmt='.2%')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signaux empilés"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
