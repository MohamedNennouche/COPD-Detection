{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For data preparation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tsaug.visualization import plot\n",
    "from tsaug import TimeWarp, Drift, AddNoise\n",
    "\n",
    "\n",
    "# For Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPool1D, GlobalAvgPool1D, Conv1D, Dropout, BatchNormalization\n",
    "\n",
    "# for callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0   0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  0.361  ...   \n",
       "1   0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  0.365  ...   \n",
       "2   0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  0.371  ...   \n",
       "3   0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  0.346  ...   \n",
       "4   0.311  0.311  0.310  0.310  0.311  0.311  0.311  0.311  0.310  0.310  ...   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "73  0.534  0.534  0.534  0.533  0.534  0.534  0.534  0.534  0.534  0.534  ...   \n",
       "74  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  0.528  ...   \n",
       "75  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  0.542  ...   \n",
       "76  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  0.532  ...   \n",
       "77  0.499  0.498  0.498  0.500  0.501  0.500  0.499  0.498  0.498  0.500  ...   \n",
       "\n",
       "     3990   3991   3992   3993   3994   3995   3996   3997   3998   3999  \n",
       "0   0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  0.405  \n",
       "1   0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  0.366  \n",
       "2   0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  0.360  \n",
       "3   0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  0.392  \n",
       "4   0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  0.342  \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "73  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  0.534  \n",
       "74  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  0.536  \n",
       "75  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  0.537  \n",
       "76  0.533  0.533  0.534  0.534  0.533  0.533  0.532  0.533  0.534  0.534  \n",
       "77  0.537  0.536  0.536  0.538  0.538  0.538  0.537  0.536  0.536  0.537  \n",
       "\n",
       "[78 rows x 4000 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur = pd.read_csv('./capteurs/capteur1.csv')\n",
    "moncapteur.drop(['class'], inplace=True, axis=1)\n",
    "moncapteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_augmentor(data, min_drift=0.01, max_drift=0.5, noise_scale=0.01) :\n",
    "    aug = list()\n",
    "    data_np = data.to_numpy()\n",
    "    my_augmenter = (\n",
    "    TimeWarp() * 9  # random time warping 5 times in parallel\n",
    "    + Drift(max_drift=(min_drift, max_drift), normalize=False) @ 0.8  # with 80% probability, random drift the signal up to 10% - 50%\n",
    "    + AddNoise(scale = noise_scale, normalize=False)\n",
    "    )\n",
    "    for i in range(len(data_np)) :\n",
    "        data_aug = my_augmenter.augment(data_np[i])\n",
    "        aug.append(data_np[i])\n",
    "        for j in range(len(data_aug)) :\n",
    "            aug.append(data_aug[j])\n",
    "    aug = pd.DataFrame(np.array(aug))\n",
    "    return aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364156</td>\n",
       "      <td>0.378683</td>\n",
       "      <td>0.372879</td>\n",
       "      <td>0.361974</td>\n",
       "      <td>0.362171</td>\n",
       "      <td>0.371224</td>\n",
       "      <td>0.344020</td>\n",
       "      <td>0.352066</td>\n",
       "      <td>0.356300</td>\n",
       "      <td>0.365244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485993</td>\n",
       "      <td>0.463324</td>\n",
       "      <td>0.480339</td>\n",
       "      <td>0.476956</td>\n",
       "      <td>0.482231</td>\n",
       "      <td>0.466606</td>\n",
       "      <td>0.464111</td>\n",
       "      <td>0.469020</td>\n",
       "      <td>0.474191</td>\n",
       "      <td>0.468157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366862</td>\n",
       "      <td>0.356675</td>\n",
       "      <td>0.388042</td>\n",
       "      <td>0.352015</td>\n",
       "      <td>0.349150</td>\n",
       "      <td>0.349274</td>\n",
       "      <td>0.343032</td>\n",
       "      <td>0.338096</td>\n",
       "      <td>0.341106</td>\n",
       "      <td>0.343496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014765</td>\n",
       "      <td>-0.025081</td>\n",
       "      <td>-0.032131</td>\n",
       "      <td>-0.022032</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>-0.048137</td>\n",
       "      <td>-0.029698</td>\n",
       "      <td>-0.017716</td>\n",
       "      <td>-0.032249</td>\n",
       "      <td>-0.034994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351590</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.356407</td>\n",
       "      <td>0.362540</td>\n",
       "      <td>0.379932</td>\n",
       "      <td>0.366316</td>\n",
       "      <td>0.349279</td>\n",
       "      <td>0.355828</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.335954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384784</td>\n",
       "      <td>0.389841</td>\n",
       "      <td>0.390302</td>\n",
       "      <td>0.404228</td>\n",
       "      <td>0.400156</td>\n",
       "      <td>0.419539</td>\n",
       "      <td>0.396586</td>\n",
       "      <td>0.410527</td>\n",
       "      <td>0.400557</td>\n",
       "      <td>0.385790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.344956</td>\n",
       "      <td>0.336467</td>\n",
       "      <td>0.364882</td>\n",
       "      <td>0.368661</td>\n",
       "      <td>0.375884</td>\n",
       "      <td>0.367871</td>\n",
       "      <td>0.364426</td>\n",
       "      <td>0.357146</td>\n",
       "      <td>0.364711</td>\n",
       "      <td>0.370581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.408257</td>\n",
       "      <td>0.414288</td>\n",
       "      <td>0.396241</td>\n",
       "      <td>0.397301</td>\n",
       "      <td>0.397942</td>\n",
       "      <td>0.404936</td>\n",
       "      <td>0.411167</td>\n",
       "      <td>0.412672</td>\n",
       "      <td>0.411266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.497093</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>0.513879</td>\n",
       "      <td>0.485446</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.517910</td>\n",
       "      <td>0.505985</td>\n",
       "      <td>0.502690</td>\n",
       "      <td>0.511066</td>\n",
       "      <td>0.491397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418397</td>\n",
       "      <td>0.428239</td>\n",
       "      <td>0.432160</td>\n",
       "      <td>0.429026</td>\n",
       "      <td>0.420147</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.438237</td>\n",
       "      <td>0.447698</td>\n",
       "      <td>0.416030</td>\n",
       "      <td>0.420932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.498814</td>\n",
       "      <td>0.488423</td>\n",
       "      <td>0.502799</td>\n",
       "      <td>0.499497</td>\n",
       "      <td>0.501253</td>\n",
       "      <td>0.493455</td>\n",
       "      <td>0.500181</td>\n",
       "      <td>0.505838</td>\n",
       "      <td>0.483716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577963</td>\n",
       "      <td>0.556866</td>\n",
       "      <td>0.556088</td>\n",
       "      <td>0.569385</td>\n",
       "      <td>0.562203</td>\n",
       "      <td>0.569491</td>\n",
       "      <td>0.573152</td>\n",
       "      <td>0.578188</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>0.551418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.494743</td>\n",
       "      <td>0.511701</td>\n",
       "      <td>0.509370</td>\n",
       "      <td>0.505052</td>\n",
       "      <td>0.509264</td>\n",
       "      <td>0.501589</td>\n",
       "      <td>0.510799</td>\n",
       "      <td>0.484825</td>\n",
       "      <td>0.498904</td>\n",
       "      <td>0.485448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537978</td>\n",
       "      <td>0.548109</td>\n",
       "      <td>0.515739</td>\n",
       "      <td>0.553441</td>\n",
       "      <td>0.529777</td>\n",
       "      <td>0.544534</td>\n",
       "      <td>0.519150</td>\n",
       "      <td>0.529582</td>\n",
       "      <td>0.529647</td>\n",
       "      <td>0.544920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.493094</td>\n",
       "      <td>0.487513</td>\n",
       "      <td>0.515591</td>\n",
       "      <td>0.503687</td>\n",
       "      <td>0.504404</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>0.503241</td>\n",
       "      <td>0.497535</td>\n",
       "      <td>0.484604</td>\n",
       "      <td>0.505965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541662</td>\n",
       "      <td>0.540490</td>\n",
       "      <td>0.521827</td>\n",
       "      <td>0.532745</td>\n",
       "      <td>0.526595</td>\n",
       "      <td>0.538083</td>\n",
       "      <td>0.524346</td>\n",
       "      <td>0.536636</td>\n",
       "      <td>0.552469</td>\n",
       "      <td>0.515137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.504833</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.503814</td>\n",
       "      <td>0.499123</td>\n",
       "      <td>0.488024</td>\n",
       "      <td>0.517235</td>\n",
       "      <td>0.486648</td>\n",
       "      <td>0.501345</td>\n",
       "      <td>0.505648</td>\n",
       "      <td>0.501868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536016</td>\n",
       "      <td>0.530725</td>\n",
       "      <td>0.524395</td>\n",
       "      <td>0.519044</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.511505</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.532555</td>\n",
       "      <td>0.524819</td>\n",
       "      <td>0.514952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    0.361000  0.361000  0.361000  0.361000  0.361000  0.361000  0.361000   \n",
       "1    0.364156  0.378683  0.372879  0.361974  0.362171  0.371224  0.344020   \n",
       "2    0.366862  0.356675  0.388042  0.352015  0.349150  0.349274  0.343032   \n",
       "3    0.351590  0.349079  0.356407  0.362540  0.379932  0.366316  0.349279   \n",
       "4    0.344956  0.336467  0.364882  0.368661  0.375884  0.367871  0.364426   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "775  0.497093  0.510929  0.513879  0.485446  0.477273  0.517910  0.505985   \n",
       "776  0.503185  0.498814  0.488423  0.502799  0.499497  0.501253  0.493455   \n",
       "777  0.494743  0.511701  0.509370  0.505052  0.509264  0.501589  0.510799   \n",
       "778  0.493094  0.487513  0.515591  0.503687  0.504404  0.492395  0.503241   \n",
       "779  0.504833  0.486870  0.503814  0.499123  0.488024  0.517235  0.486648   \n",
       "\n",
       "         7         8         9     ...      3990      3991      3992  \\\n",
       "0    0.361000  0.361000  0.361000  ...  0.405000  0.405000  0.405000   \n",
       "1    0.352066  0.356300  0.365244  ...  0.485993  0.463324  0.480339   \n",
       "2    0.338096  0.341106  0.343496  ... -0.014765 -0.025081 -0.032131   \n",
       "3    0.355828  0.361407  0.335954  ...  0.384784  0.389841  0.390302   \n",
       "4    0.357146  0.364711  0.370581  ...  0.418301  0.408257  0.414288   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "775  0.502690  0.511066  0.491397  ...  0.418397  0.428239  0.432160   \n",
       "776  0.500181  0.505838  0.483716  ...  0.577963  0.556866  0.556088   \n",
       "777  0.484825  0.498904  0.485448  ...  0.537978  0.548109  0.515739   \n",
       "778  0.497535  0.484604  0.505965  ...  0.541662  0.540490  0.521827   \n",
       "779  0.501345  0.505648  0.501868  ...  0.536016  0.530725  0.524395   \n",
       "\n",
       "         3993      3994      3995      3996      3997      3998      3999  \n",
       "0    0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  0.405000  \n",
       "1    0.476956  0.482231  0.466606  0.464111  0.469020  0.474191  0.468157  \n",
       "2   -0.022032 -0.033654 -0.048137 -0.029698 -0.017716 -0.032249 -0.034994  \n",
       "3    0.404228  0.400156  0.419539  0.396586  0.410527  0.400557  0.385790  \n",
       "4    0.396241  0.397301  0.397942  0.404936  0.411167  0.412672  0.411266  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "775  0.429026  0.420147  0.423853  0.438237  0.447698  0.416030  0.420932  \n",
       "776  0.569385  0.562203  0.569491  0.573152  0.578188  0.568186  0.551418  \n",
       "777  0.553441  0.529777  0.544534  0.519150  0.529582  0.529647  0.544920  \n",
       "778  0.532745  0.526595  0.538083  0.524346  0.536636  0.552469  0.515137  \n",
       "779  0.519044  0.530628  0.511505  0.519417  0.532555  0.524819  0.514952  \n",
       "\n",
       "[780 rows x 4000 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moncapteur_aug = sensor_augmentor(moncapteur)\n",
    "moncapteur_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les signaux concaténés "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataset(path, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    monDataset = list()\n",
    "    etiq = 0\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            monfichier.reset_index(inplace=True, drop=True)\n",
    "            monDataset.append(monfichier)\n",
    "        else :\n",
    "            monfichier = os.listdir(all_path)\n",
    "            all_path_etiq = os.path.join(all_path,monfichier[0])\n",
    "            etiq = pd.read_csv(all_path_etiq)\n",
    "            etiq[\"class\"] = etiq[\"class\"].astype('category').cat.codes\n",
    "    monDataset = pd.concat(monDataset, axis=1)\n",
    "    fv_train, fv_test, etiq_train, etiq_test = train_test_split(monDataset, etiq, test_size=test_size, random_state=42)\n",
    "    return fv_train, fv_test, etiq_train, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54, 32000), (24, 32000), (54, 1), (24, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./capteurs\"\n",
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 32000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_list = etiq_train.to_numpy()\n",
    "etiq_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "etiq_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.2220 - accuracy: 0.5255\n",
      "Epoch 1: accuracy improved from -inf to 0.52546, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 59s 529ms/step - loss: 1.2220 - accuracy: 0.5255 - val_loss: 1.2981 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.1736 - accuracy: 0.5347\n",
      "Epoch 2: accuracy improved from 0.52546 to 0.53472, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 47s 441ms/step - loss: 1.1736 - accuracy: 0.5347 - val_loss: 1.2628 - val_accuracy: 0.4444\n",
      "Epoch 3/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.8564 - accuracy: 0.6620\n",
      "Epoch 3: accuracy improved from 0.53472 to 0.66204, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 48s 447ms/step - loss: 0.8564 - accuracy: 0.6620 - val_loss: 0.9742 - val_accuracy: 0.5463\n",
      "Epoch 4/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7615 - accuracy: 0.6852\n",
      "Epoch 4: accuracy improved from 0.66204 to 0.68519, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 586ms/step - loss: 0.7615 - accuracy: 0.6852 - val_loss: 0.8974 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.7106\n",
      "Epoch 5: accuracy improved from 0.68519 to 0.71065, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 53s 492ms/step - loss: 0.6782 - accuracy: 0.7106 - val_loss: 0.8265 - val_accuracy: 0.6111\n",
      "Epoch 6/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.7338\n",
      "Epoch 6: accuracy improved from 0.71065 to 0.73380, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 54s 499ms/step - loss: 0.6749 - accuracy: 0.7338 - val_loss: 0.8168 - val_accuracy: 0.6389\n",
      "Epoch 7/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7222\n",
      "Epoch 7: accuracy did not improve from 0.73380\n",
      "108/108 [==============================] - 52s 486ms/step - loss: 0.6923 - accuracy: 0.7222 - val_loss: 0.8588 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.7569\n",
      "Epoch 8: accuracy improved from 0.73380 to 0.75694, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 70s 645ms/step - loss: 0.6460 - accuracy: 0.7569 - val_loss: 0.8738 - val_accuracy: 0.7315\n",
      "Epoch 9/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7092 - accuracy: 0.7106\n",
      "Epoch 9: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 66s 615ms/step - loss: 0.7092 - accuracy: 0.7106 - val_loss: 0.8857 - val_accuracy: 0.5556\n",
      "Epoch 10/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6209 - accuracy: 0.7500\n",
      "Epoch 10: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 68s 631ms/step - loss: 0.6209 - accuracy: 0.7500 - val_loss: 0.7919 - val_accuracy: 0.6296\n",
      "Epoch 11/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6163 - accuracy: 0.7454\n",
      "Epoch 11: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 635ms/step - loss: 0.6163 - accuracy: 0.7454 - val_loss: 0.8248 - val_accuracy: 0.5648\n",
      "Epoch 12/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.7384\n",
      "Epoch 12: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.6250 - accuracy: 0.7384 - val_loss: 0.8651 - val_accuracy: 0.5926\n",
      "Epoch 13/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.7315\n",
      "Epoch 13: accuracy did not improve from 0.75694\n",
      "108/108 [==============================] - 67s 618ms/step - loss: 0.6576 - accuracy: 0.7315 - val_loss: 0.8066 - val_accuracy: 0.6111\n",
      "Epoch 14/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7685\n",
      "Epoch 14: accuracy improved from 0.75694 to 0.76852, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 63s 580ms/step - loss: 0.5973 - accuracy: 0.7685 - val_loss: 0.7505 - val_accuracy: 0.6204\n",
      "Epoch 15/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6462 - accuracy: 0.7338\n",
      "Epoch 15: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 536ms/step - loss: 0.6462 - accuracy: 0.7338 - val_loss: 0.7762 - val_accuracy: 0.6111\n",
      "Epoch 16/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7790 - accuracy: 0.7315\n",
      "Epoch 16: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 59s 547ms/step - loss: 0.7790 - accuracy: 0.7315 - val_loss: 0.7598 - val_accuracy: 0.6944\n",
      "Epoch 17/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.7477\n",
      "Epoch 17: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 63s 583ms/step - loss: 0.6375 - accuracy: 0.7477 - val_loss: 0.7674 - val_accuracy: 0.7685\n",
      "Epoch 18/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.7431\n",
      "Epoch 18: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 58s 541ms/step - loss: 0.6131 - accuracy: 0.7431 - val_loss: 0.8928 - val_accuracy: 0.5370\n",
      "Epoch 19/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6195 - accuracy: 0.7454\n",
      "Epoch 19: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 54s 503ms/step - loss: 0.6195 - accuracy: 0.7454 - val_loss: 0.9111 - val_accuracy: 0.5370\n",
      "Epoch 20/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 1.6257 - accuracy: 0.7361\n",
      "Epoch 20: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 62s 577ms/step - loss: 1.6257 - accuracy: 0.7361 - val_loss: 0.8013 - val_accuracy: 0.5556\n",
      "Epoch 21/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.6829\n",
      "Epoch 21: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 69s 640ms/step - loss: 0.7483 - accuracy: 0.6829 - val_loss: 0.7993 - val_accuracy: 0.5833\n",
      "Epoch 22/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.7292\n",
      "Epoch 22: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.6588 - accuracy: 0.7292 - val_loss: 0.7822 - val_accuracy: 0.6204\n",
      "Epoch 23/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7523\n",
      "Epoch 23: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 70s 644ms/step - loss: 0.6137 - accuracy: 0.7523 - val_loss: 0.7414 - val_accuracy: 0.6481\n",
      "Epoch 24/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.7384\n",
      "Epoch 24: accuracy did not improve from 0.76852\n",
      "108/108 [==============================] - 68s 626ms/step - loss: 0.6227 - accuracy: 0.7384 - val_loss: 0.7636 - val_accuracy: 0.6019\n",
      "Epoch 25/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.7708\n",
      "Epoch 25: accuracy improved from 0.76852 to 0.77083, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 72s 662ms/step - loss: 0.5843 - accuracy: 0.7708 - val_loss: 0.7146 - val_accuracy: 0.6574\n",
      "Epoch 26/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5474 - accuracy: 0.7569\n",
      "Epoch 26: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 634ms/step - loss: 0.5474 - accuracy: 0.7569 - val_loss: 0.7628 - val_accuracy: 0.5741\n",
      "Epoch 27/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.7454\n",
      "Epoch 27: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 636ms/step - loss: 0.5668 - accuracy: 0.7454 - val_loss: 0.6763 - val_accuracy: 0.6852\n",
      "Epoch 28/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7708\n",
      "Epoch 28: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 68s 630ms/step - loss: 0.5229 - accuracy: 0.7708 - val_loss: 0.7059 - val_accuracy: 0.6204\n",
      "Epoch 29/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.7593\n",
      "Epoch 29: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 652ms/step - loss: 0.5250 - accuracy: 0.7593 - val_loss: 0.7393 - val_accuracy: 0.5741\n",
      "Epoch 30/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7569\n",
      "Epoch 30: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 69s 639ms/step - loss: 0.5652 - accuracy: 0.7569 - val_loss: 0.8189 - val_accuracy: 0.5556\n",
      "Epoch 31/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5143 - accuracy: 0.7639\n",
      "Epoch 31: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 647ms/step - loss: 0.5143 - accuracy: 0.7639 - val_loss: 0.7004 - val_accuracy: 0.6111\n",
      "Epoch 32/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7708\n",
      "Epoch 32: accuracy did not improve from 0.77083\n",
      "108/108 [==============================] - 70s 646ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.6931 - val_accuracy: 0.6019\n",
      "Epoch 33/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.7801\n",
      "Epoch 33: accuracy improved from 0.77083 to 0.78009, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 71s 662ms/step - loss: 0.4928 - accuracy: 0.7801 - val_loss: 0.7624 - val_accuracy: 0.5833\n",
      "Epoch 34/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.5300 - accuracy: 0.7569\n",
      "Epoch 34: accuracy did not improve from 0.78009\n",
      "108/108 [==============================] - 70s 648ms/step - loss: 0.5300 - accuracy: 0.7569 - val_loss: 0.6581 - val_accuracy: 0.6389\n",
      "Epoch 35/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4880 - accuracy: 0.7917\n",
      "Epoch 35: accuracy improved from 0.78009 to 0.79167, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4880 - accuracy: 0.7917 - val_loss: 0.5843 - val_accuracy: 0.7222\n",
      "Epoch 36/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.7801\n",
      "Epoch 36: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 676ms/step - loss: 0.4671 - accuracy: 0.7801 - val_loss: 0.6422 - val_accuracy: 0.6204\n",
      "Epoch 37/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.7778\n",
      "Epoch 37: accuracy did not improve from 0.79167\n",
      "108/108 [==============================] - 73s 679ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.5928 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.7940\n",
      "Epoch 38: accuracy improved from 0.79167 to 0.79398, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 79s 728ms/step - loss: 0.4951 - accuracy: 0.7940 - val_loss: 0.6788 - val_accuracy: 0.6389\n",
      "Epoch 39/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7778\n",
      "Epoch 39: accuracy did not improve from 0.79398\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4953 - accuracy: 0.7778 - val_loss: 0.6452 - val_accuracy: 0.6204\n",
      "Epoch 40/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7963\n",
      "Epoch 40: accuracy improved from 0.79398 to 0.79630, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 78s 725ms/step - loss: 0.4604 - accuracy: 0.7963 - val_loss: 0.5846 - val_accuracy: 0.6944\n",
      "Epoch 41/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7870\n",
      "Epoch 41: accuracy did not improve from 0.79630\n",
      "108/108 [==============================] - 74s 689ms/step - loss: 0.4502 - accuracy: 0.7870 - val_loss: 0.5741 - val_accuracy: 0.7130\n",
      "Epoch 42/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4457 - accuracy: 0.8079\n",
      "Epoch 42: accuracy improved from 0.79630 to 0.80787, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 77s 716ms/step - loss: 0.4457 - accuracy: 0.8079 - val_loss: 0.5664 - val_accuracy: 0.6574\n",
      "Epoch 43/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.7986\n",
      "Epoch 43: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 692ms/step - loss: 0.4567 - accuracy: 0.7986 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 44/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7801\n",
      "Epoch 44: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 75s 690ms/step - loss: 0.4811 - accuracy: 0.7801 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 45/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4563 - accuracy: 0.7755\n",
      "Epoch 45: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 669ms/step - loss: 0.4563 - accuracy: 0.7755 - val_loss: 0.6284 - val_accuracy: 0.6296\n",
      "Epoch 46/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4378 - accuracy: 0.8056\n",
      "Epoch 46: accuracy did not improve from 0.80787\n",
      "108/108 [==============================] - 72s 671ms/step - loss: 0.4378 - accuracy: 0.8056 - val_loss: 0.5989 - val_accuracy: 0.6852\n",
      "Epoch 47/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8102\n",
      "Epoch 47: accuracy improved from 0.80787 to 0.81019, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.4459 - accuracy: 0.8102 - val_loss: 0.5648 - val_accuracy: 0.6852\n",
      "Epoch 48/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4452 - accuracy: 0.7894\n",
      "Epoch 48: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 75s 697ms/step - loss: 0.4452 - accuracy: 0.7894 - val_loss: 0.6263 - val_accuracy: 0.5926\n",
      "Epoch 49/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.7894\n",
      "Epoch 49: accuracy did not improve from 0.81019\n",
      "108/108 [==============================] - 74s 681ms/step - loss: 0.4409 - accuracy: 0.7894 - val_loss: 0.4967 - val_accuracy: 0.7407\n",
      "Epoch 50/50\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.4634 - accuracy: 0.8148\n",
      "Epoch 50: accuracy improved from 0.81019 to 0.81481, saving model to .\\Model_CNN1D_32000_aug\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug\\assets\n",
      "108/108 [==============================] - 81s 749ms/step - loss: 0.4634 - accuracy: 0.8148 - val_loss: 0.5925 - val_accuracy: 0.6574\n",
      "====== Modele evaluation ======\n",
      "6/6 [==============================] - 2s 179ms/step - loss: 0.5821 - accuracy: 0.7083\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec une autre disposition du dataset (on prend 50-50 test entrainement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2872 - accuracy: 0.4744\n",
      "Epoch 1: accuracy improved from -inf to 0.47436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 533ms/step - loss: 1.2872 - accuracy: 0.4744 - val_loss: 1.2905 - val_accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2352 - accuracy: 0.4872\n",
      "Epoch 2: accuracy improved from 0.47436 to 0.48718, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 43s 548ms/step - loss: 1.2352 - accuracy: 0.4872 - val_loss: 1.2690 - val_accuracy: 0.4872\n",
      "Epoch 3/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1123 - accuracy: 0.5288\n",
      "Epoch 3: accuracy improved from 0.48718 to 0.52885, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 1.1123 - accuracy: 0.5288 - val_loss: 1.1106 - val_accuracy: 0.4872\n",
      "Epoch 4/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8843 - accuracy: 0.6474\n",
      "Epoch 4: accuracy improved from 0.52885 to 0.64744, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.8843 - accuracy: 0.6474 - val_loss: 0.8856 - val_accuracy: 0.6795\n",
      "Epoch 5/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.6603\n",
      "Epoch 5: accuracy improved from 0.64744 to 0.66026, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 36s 458ms/step - loss: 0.8355 - accuracy: 0.6603 - val_loss: 0.9076 - val_accuracy: 0.7564\n",
      "Epoch 6/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7539 - accuracy: 0.6763\n",
      "Epoch 6: accuracy improved from 0.66026 to 0.67628, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 431ms/step - loss: 0.7539 - accuracy: 0.6763 - val_loss: 0.7807 - val_accuracy: 0.7692\n",
      "Epoch 7/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7365 - accuracy: 0.7051\n",
      "Epoch 7: accuracy improved from 0.67628 to 0.70513, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 437ms/step - loss: 0.7365 - accuracy: 0.7051 - val_loss: 0.7647 - val_accuracy: 0.7564\n",
      "Epoch 8/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7503 - accuracy: 0.6859\n",
      "Epoch 8: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 33s 421ms/step - loss: 0.7503 - accuracy: 0.6859 - val_loss: 0.7960 - val_accuracy: 0.8333\n",
      "Epoch 9/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.6987\n",
      "Epoch 9: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 32s 414ms/step - loss: 0.6746 - accuracy: 0.6987 - val_loss: 0.7632 - val_accuracy: 0.7436\n",
      "Epoch 10/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.7019\n",
      "Epoch 10: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 33s 418ms/step - loss: 0.6740 - accuracy: 0.7019 - val_loss: 0.7580 - val_accuracy: 0.7564\n",
      "Epoch 11/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6693 - accuracy: 0.7051\n",
      "Epoch 11: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 34s 434ms/step - loss: 0.6693 - accuracy: 0.7051 - val_loss: 0.7548 - val_accuracy: 0.7179\n",
      "Epoch 12/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6460 - accuracy: 0.6955\n",
      "Epoch 12: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 40s 510ms/step - loss: 0.6460 - accuracy: 0.6955 - val_loss: 0.7411 - val_accuracy: 0.6923\n",
      "Epoch 13/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6488 - accuracy: 0.7051\n",
      "Epoch 13: accuracy did not improve from 0.70513\n",
      "78/78 [==============================] - 40s 511ms/step - loss: 0.6488 - accuracy: 0.7051 - val_loss: 0.7865 - val_accuracy: 0.6795\n",
      "Epoch 14/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.7244\n",
      "Epoch 14: accuracy improved from 0.70513 to 0.72436, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 41s 531ms/step - loss: 0.6240 - accuracy: 0.7244 - val_loss: 0.7623 - val_accuracy: 0.6923\n",
      "Epoch 15/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6106 - accuracy: 0.7115\n",
      "Epoch 15: accuracy did not improve from 0.72436\n",
      "78/78 [==============================] - 39s 500ms/step - loss: 0.6106 - accuracy: 0.7115 - val_loss: 0.6986 - val_accuracy: 0.7436\n",
      "Epoch 16/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.6955\n",
      "Epoch 16: accuracy did not improve from 0.72436\n",
      "78/78 [==============================] - 39s 501ms/step - loss: 0.6543 - accuracy: 0.6955 - val_loss: 0.7297 - val_accuracy: 0.7179\n",
      "Epoch 17/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5788 - accuracy: 0.7500\n",
      "Epoch 17: accuracy improved from 0.72436 to 0.75000, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 542ms/step - loss: 0.5788 - accuracy: 0.7500 - val_loss: 0.7232 - val_accuracy: 0.7051\n",
      "Epoch 18/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5930 - accuracy: 0.7244\n",
      "Epoch 18: accuracy did not improve from 0.75000\n",
      "78/78 [==============================] - 41s 521ms/step - loss: 0.5930 - accuracy: 0.7244 - val_loss: 0.7550 - val_accuracy: 0.6795\n",
      "Epoch 19/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.7308\n",
      "Epoch 19: accuracy did not improve from 0.75000\n",
      "78/78 [==============================] - 41s 523ms/step - loss: 0.5733 - accuracy: 0.7308 - val_loss: 0.6820 - val_accuracy: 0.7436\n",
      "Epoch 20/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5726 - accuracy: 0.7404\n",
      "Epoch 20: accuracy did not improve from 0.75000\n",
      "78/78 [==============================] - 41s 524ms/step - loss: 0.5726 - accuracy: 0.7404 - val_loss: 0.6903 - val_accuracy: 0.7436\n",
      "Epoch 21/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.7372\n",
      "Epoch 21: accuracy did not improve from 0.75000\n",
      "78/78 [==============================] - 40s 519ms/step - loss: 0.5846 - accuracy: 0.7372 - val_loss: 0.7358 - val_accuracy: 0.7179\n",
      "Epoch 22/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.7628\n",
      "Epoch 22: accuracy improved from 0.75000 to 0.76282, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 541ms/step - loss: 0.5514 - accuracy: 0.7628 - val_loss: 0.6945 - val_accuracy: 0.7308\n",
      "Epoch 23/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.7532\n",
      "Epoch 23: accuracy did not improve from 0.76282\n",
      "78/78 [==============================] - 40s 515ms/step - loss: 0.5672 - accuracy: 0.7532 - val_loss: 0.6908 - val_accuracy: 0.7308\n",
      "Epoch 24/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7660\n",
      "Epoch 24: accuracy improved from 0.76282 to 0.76603, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 537ms/step - loss: 0.5355 - accuracy: 0.7660 - val_loss: 0.6441 - val_accuracy: 0.7564\n",
      "Epoch 25/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.7276\n",
      "Epoch 25: accuracy did not improve from 0.76603\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.5954 - accuracy: 0.7276 - val_loss: 0.6641 - val_accuracy: 0.7436\n",
      "Epoch 26/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7692\n",
      "Epoch 26: accuracy improved from 0.76603 to 0.76923, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 536ms/step - loss: 0.5193 - accuracy: 0.7692 - val_loss: 0.6432 - val_accuracy: 0.7436\n",
      "Epoch 27/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5382 - accuracy: 0.7724\n",
      "Epoch 27: accuracy improved from 0.76923 to 0.77244, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 44s 561ms/step - loss: 0.5382 - accuracy: 0.7724 - val_loss: 0.6677 - val_accuracy: 0.7564\n",
      "Epoch 28/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4993 - accuracy: 0.7885\n",
      "Epoch 28: accuracy improved from 0.77244 to 0.78846, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 42s 541ms/step - loss: 0.4993 - accuracy: 0.7885 - val_loss: 0.7333 - val_accuracy: 0.7051\n",
      "Epoch 29/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.7885\n",
      "Epoch 29: accuracy did not improve from 0.78846\n",
      "78/78 [==============================] - 40s 516ms/step - loss: 0.5236 - accuracy: 0.7885 - val_loss: 0.6125 - val_accuracy: 0.7821\n",
      "Epoch 30/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.7853\n",
      "Epoch 30: accuracy did not improve from 0.78846\n",
      "78/78 [==============================] - 39s 502ms/step - loss: 0.5066 - accuracy: 0.7853 - val_loss: 0.6700 - val_accuracy: 0.7308\n",
      "Epoch 31/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.7885\n",
      "Epoch 31: accuracy did not improve from 0.78846\n",
      "78/78 [==============================] - 40s 512ms/step - loss: 0.5032 - accuracy: 0.7885 - val_loss: 0.7254 - val_accuracy: 0.6923\n",
      "Epoch 32/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.7743 - accuracy: 0.7340\n",
      "Epoch 32: accuracy did not improve from 0.78846\n",
      "78/78 [==============================] - 41s 520ms/step - loss: 0.7743 - accuracy: 0.7340 - val_loss: 0.6363 - val_accuracy: 0.7436\n",
      "Epoch 33/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.7660\n",
      "Epoch 33: accuracy did not improve from 0.78846\n",
      "78/78 [==============================] - 40s 514ms/step - loss: 0.5012 - accuracy: 0.7660 - val_loss: 0.6938 - val_accuracy: 0.7179\n",
      "Epoch 34/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.7917\n",
      "Epoch 34: accuracy improved from 0.78846 to 0.79167, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 40s 513ms/step - loss: 0.4791 - accuracy: 0.7917 - val_loss: 0.6650 - val_accuracy: 0.7308\n",
      "Epoch 35/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4878 - accuracy: 0.7788\n",
      "Epoch 35: accuracy did not improve from 0.79167\n",
      "78/78 [==============================] - 34s 437ms/step - loss: 0.4878 - accuracy: 0.7788 - val_loss: 0.6133 - val_accuracy: 0.7436\n",
      "Epoch 36/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.7885\n",
      "Epoch 36: accuracy did not improve from 0.79167\n",
      "78/78 [==============================] - 33s 426ms/step - loss: 0.4605 - accuracy: 0.7885 - val_loss: 0.6015 - val_accuracy: 0.8462\n",
      "Epoch 37/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.7596\n",
      "Epoch 37: accuracy did not improve from 0.79167\n",
      "78/78 [==============================] - 32s 414ms/step - loss: 0.5358 - accuracy: 0.7596 - val_loss: 0.6936 - val_accuracy: 0.7051\n",
      "Epoch 38/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.7981\n",
      "Epoch 38: accuracy improved from 0.79167 to 0.79808, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 437ms/step - loss: 0.4825 - accuracy: 0.7981 - val_loss: 0.6153 - val_accuracy: 0.7564\n",
      "Epoch 39/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4762 - accuracy: 0.7885\n",
      "Epoch 39: accuracy did not improve from 0.79808\n",
      "78/78 [==============================] - 33s 425ms/step - loss: 0.4762 - accuracy: 0.7885 - val_loss: 0.5996 - val_accuracy: 0.7692\n",
      "Epoch 40/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4586 - accuracy: 0.8013\n",
      "Epoch 40: accuracy improved from 0.79808 to 0.80128, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 435ms/step - loss: 0.4586 - accuracy: 0.8013 - val_loss: 0.5891 - val_accuracy: 0.7436\n",
      "Epoch 41/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8269\n",
      "Epoch 41: accuracy improved from 0.80128 to 0.82692, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 440ms/step - loss: 0.4597 - accuracy: 0.8269 - val_loss: 0.6518 - val_accuracy: 0.7436\n",
      "Epoch 42/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8301\n",
      "Epoch 42: accuracy improved from 0.82692 to 0.83013, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 34s 435ms/step - loss: 0.4276 - accuracy: 0.8301 - val_loss: 0.6094 - val_accuracy: 0.7949\n",
      "Epoch 43/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4713 - accuracy: 0.8045\n",
      "Epoch 43: accuracy did not improve from 0.83013\n",
      "78/78 [==============================] - 32s 412ms/step - loss: 0.4713 - accuracy: 0.8045 - val_loss: 0.6699 - val_accuracy: 0.7308\n",
      "Epoch 44/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.7917\n",
      "Epoch 44: accuracy did not improve from 0.83013\n",
      "78/78 [==============================] - 32s 416ms/step - loss: 0.4644 - accuracy: 0.7917 - val_loss: 0.6543 - val_accuracy: 0.7692\n",
      "Epoch 45/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8526\n",
      "Epoch 45: accuracy improved from 0.83013 to 0.85256, saving model to .\\Model_CNN1D_32000_aug_2\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_32000_aug_2\\assets\n",
      "78/78 [==============================] - 33s 420ms/step - loss: 0.4037 - accuracy: 0.8526 - val_loss: 0.5929 - val_accuracy: 0.7564\n",
      "Epoch 46/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.8237\n",
      "Epoch 46: accuracy did not improve from 0.85256\n",
      "78/78 [==============================] - 32s 415ms/step - loss: 0.4139 - accuracy: 0.8237 - val_loss: 0.5678 - val_accuracy: 0.7821\n",
      "Epoch 47/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4105 - accuracy: 0.8269\n",
      "Epoch 47: accuracy did not improve from 0.85256\n",
      "78/78 [==============================] - 32s 411ms/step - loss: 0.4105 - accuracy: 0.8269 - val_loss: 0.5495 - val_accuracy: 0.7821\n",
      "Epoch 48/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4289 - accuracy: 0.7981\n",
      "Epoch 48: accuracy did not improve from 0.85256\n",
      "78/78 [==============================] - 32s 406ms/step - loss: 0.4289 - accuracy: 0.7981 - val_loss: 0.6569 - val_accuracy: 0.7436\n",
      "Epoch 49/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8077\n",
      "Epoch 49: accuracy did not improve from 0.85256\n",
      "78/78 [==============================] - 32s 411ms/step - loss: 0.4628 - accuracy: 0.8077 - val_loss: 0.7429 - val_accuracy: 0.6410\n",
      "Epoch 50/50\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.4322 - accuracy: 0.8141\n",
      "Epoch 50: accuracy did not improve from 0.85256\n",
      "78/78 [==============================] - 32s 417ms/step - loss: 0.4322 - accuracy: 0.8141 - val_loss: 0.6137 - val_accuracy: 0.7564\n",
      "====== Modele evaluation ======\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.4689 - accuracy: 0.8718\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.5)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essai maintenant avec un ratio 65% de test - 35% d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2887 - accuracy: 0.4815"
     ]
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test = concat_dataset(path, test_size=0.65)\n",
    "\n",
    "fv_train_aug = sensor_augmentor(fv_train, min_drift=0.01, max_drift=0.5, noise_scale=0.01)\n",
    "fv_train_aug.shape\n",
    "\n",
    "etiq_list = etiq_train.to_numpy()\n",
    "\n",
    "etiq_train_aug = list()\n",
    "for i in range(len(etiq_list)) :\n",
    "    for j in range(10) :\n",
    "        etiq_train_aug.append(etiq_list[i])\n",
    "etiq_train_aug = pd.DataFrame(etiq_train_aug)\n",
    "\n",
    "# Normalisation\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(np.transpose(fv_train_aug))\n",
    "fv_train_aug = np.transpose(scaler.transform(np.transpose(fv_train_aug)))\n",
    "scaler2 = MinMaxScaler(feature_range=(0,1))\n",
    "scaler2.fit(np.transpose(fv_test))\n",
    "fv_test = np.transpose(scaler2.transform(np.transpose(fv_test)))\n",
    "\n",
    "# Reshaping \n",
    "fv_train_aug = np.expand_dims(fv_train_aug, axis=2)\n",
    "fv_test = np.expand_dims(fv_test, axis=2)\n",
    "\n",
    "\n",
    "# CNN Variables\n",
    "# Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "# Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = 1 # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 50\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_32000_aug_2'\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1\n",
    ") \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(32000,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train_aug, etiq_train_aug, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"====== Modele evaluation ======\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===============================\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signaux empilés"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
