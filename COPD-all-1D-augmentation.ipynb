{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For data preparation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPool1D, GlobalAvgPool1D, Conv1D, Dropout, BatchNormalization\n",
    "\n",
    "# for callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A travers ce notebook on tente de faire plusieurs techniques d'augmentation des données pour améliorer le résultat trouvé dans le fichier COPD-all-1D-signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "monfichier = pd.read_csv(\"./capteurs/capteur1.csv\")\n",
    "macolonne = monfichier[\"class\"]\n",
    "macolonne.to_csv(\"./capteurs/labels/labels.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     smoker\n",
       "1     smoker\n",
       "2     smoker\n",
       "3     smoker\n",
       "4     smoker\n",
       "       ...  \n",
       "73       air\n",
       "74       air\n",
       "75       air\n",
       "76       air\n",
       "77       air\n",
       "Name: class, Length: 78, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macolonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dataset_balanced(path, etiq, test_size=0.3) :\n",
    "    listefichier = os.listdir(path)\n",
    "    fv_train = list()\n",
    "    fv_test = list()\n",
    "    etiq = etiq.astype('category').cat.codes\n",
    "\n",
    "    for file in listefichier :\n",
    "        all_path = os.path.join(path,file)\n",
    "        if not os.path.isdir(all_path) :\n",
    "            monfichier = pd.read_csv(all_path)\n",
    "            monfichier.drop([\"class\"], axis=1, inplace=True)\n",
    "            features_train, features_test, etiq_train, etiq_test = train_test_split(monfichier, etiq, test_size=test_size, random_state=42)\n",
    "            sm = SMOTE(random_state = 2, k_neighbors=3)\n",
    "            features_train_res, etiq_train_res = sm.fit_sample(features_train, etiq_train.ravel())\n",
    "            fv_train.append(features_train_res)\n",
    "            fv_test.append(features_test)\n",
    "    fv_train = np.dstack(fv_train)\n",
    "    fv_test = np.dstack(fv_test)\n",
    "    etiq_train_res = np.expand_dims(etiq_train_res, axis=1)\n",
    "    etiq_test = np.expand_dims(etiq_test, axis=1)\n",
    "    return fv_train, fv_test, etiq_train_res, etiq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 4000, 8), (24, 4000, 8), (112, 1), (24, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv_train, fv_test, etiq_train, etiq_test =stack_dataset_balanced(\"./capteurs\", macolonne)\n",
    "fv_train.shape, fv_test.shape, etiq_train.shape, etiq_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 1.1665 - accuracy: 0.4659\n",
      "Epoch 1: accuracy improved from -inf to 0.47191, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 7s 216ms/step - loss: 1.1579 - accuracy: 0.4719 - val_loss: 1.9726 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.6853 - accuracy: 0.6932\n",
      "Epoch 2: accuracy improved from 0.47191 to 0.68539, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 6s 255ms/step - loss: 0.6872 - accuracy: 0.6854 - val_loss: 1.6292 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.5261 - accuracy: 0.8068\n",
      "Epoch 3: accuracy improved from 0.68539 to 0.80899, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.5283 - accuracy: 0.8090 - val_loss: 1.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.5681 - accuracy: 0.7386\n",
      "Epoch 4: accuracy did not improve from 0.80899\n",
      "23/23 [==============================] - 2s 94ms/step - loss: 0.5617 - accuracy: 0.7416 - val_loss: 1.3220 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.4268 - accuracy: 0.8182\n",
      "Epoch 5: accuracy improved from 0.80899 to 0.82022, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 214ms/step - loss: 0.4263 - accuracy: 0.8202 - val_loss: 1.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3979 - accuracy: 0.8409\n",
      "Epoch 6: accuracy improved from 0.82022 to 0.84270, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 225ms/step - loss: 0.3944 - accuracy: 0.8427 - val_loss: 1.2293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3407 - accuracy: 0.8636\n",
      "Epoch 7: accuracy improved from 0.84270 to 0.86517, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 211ms/step - loss: 0.3369 - accuracy: 0.8652 - val_loss: 1.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2918 - accuracy: 0.8523\n",
      "Epoch 8: accuracy did not improve from 0.86517\n",
      "23/23 [==============================] - 2s 104ms/step - loss: 0.3076 - accuracy: 0.8427 - val_loss: 0.7599 - val_accuracy: 0.2609\n",
      "Epoch 9/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.7593 - accuracy: 0.6136\n",
      "Epoch 9: accuracy did not improve from 0.86517\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.7554 - accuracy: 0.6180 - val_loss: 0.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3765 - accuracy: 0.8523\n",
      "Epoch 10: accuracy did not improve from 0.86517\n",
      "23/23 [==============================] - 2s 88ms/step - loss: 0.3778 - accuracy: 0.8539 - val_loss: 0.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2356 - accuracy: 0.9091\n",
      "Epoch 11: accuracy improved from 0.86517 to 0.91011, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 4s 195ms/step - loss: 0.2332 - accuracy: 0.9101 - val_loss: 1.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2035 - accuracy: 0.8977\n",
      "Epoch 12: accuracy did not improve from 0.91011\n",
      "23/23 [==============================] - 2s 108ms/step - loss: 0.2016 - accuracy: 0.8989 - val_loss: 0.4168 - val_accuracy: 1.0000\n",
      "Epoch 13/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2274 - accuracy: 0.9205\n",
      "Epoch 13: accuracy did not improve from 0.91011\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.2359 - accuracy: 0.9101 - val_loss: 0.9776 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1682 - accuracy: 0.9091\n",
      "Epoch 14: accuracy did not improve from 0.91011\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1677 - accuracy: 0.9101 - val_loss: 0.5641 - val_accuracy: 1.0000\n",
      "Epoch 15/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1493 - accuracy: 0.9432\n",
      "Epoch 15: accuracy improved from 0.91011 to 0.94382, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.1477 - accuracy: 0.9438 - val_loss: 0.8212 - val_accuracy: 0.0435\n",
      "Epoch 16/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1530 - accuracy: 0.9318\n",
      "Epoch 16: accuracy did not improve from 0.94382\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.1513 - accuracy: 0.9326 - val_loss: 0.6506 - val_accuracy: 0.9565\n",
      "Epoch 17/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1063 - accuracy: 0.9773\n",
      "Epoch 17: accuracy improved from 0.94382 to 0.97753, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 203ms/step - loss: 0.1055 - accuracy: 0.9775 - val_loss: 0.5518 - val_accuracy: 1.0000\n",
      "Epoch 18/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1378 - accuracy: 0.9432\n",
      "Epoch 18: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 86ms/step - loss: 0.1366 - accuracy: 0.9438 - val_loss: 0.7740 - val_accuracy: 0.0435\n",
      "Epoch 19/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1931 - accuracy: 0.9205\n",
      "Epoch 19: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.1910 - accuracy: 0.9213 - val_loss: 0.6572 - val_accuracy: 0.8261\n",
      "Epoch 20/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1557 - accuracy: 0.9545\n",
      "Epoch 20: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.1540 - accuracy: 0.9551 - val_loss: 0.6028 - val_accuracy: 1.0000\n",
      "Epoch 21/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1345 - accuracy: 0.9432\n",
      "Epoch 21: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1330 - accuracy: 0.9438 - val_loss: 0.6311 - val_accuracy: 0.7826\n",
      "Epoch 22/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1155 - accuracy: 0.9318\n",
      "Epoch 22: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.1142 - accuracy: 0.9326 - val_loss: 0.4046 - val_accuracy: 1.0000\n",
      "Epoch 23/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1075 - accuracy: 0.9432\n",
      "Epoch 23: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.1063 - accuracy: 0.9438 - val_loss: 0.7534 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1023 - accuracy: 0.9545\n",
      "Epoch 24: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.1011 - accuracy: 0.9551 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
      "Epoch 25/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0600 - accuracy: 0.9773\n",
      "Epoch 25: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.0594 - accuracy: 0.9775 - val_loss: 0.5849 - val_accuracy: 1.0000\n",
      "Epoch 26/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2711 - accuracy: 0.8977\n",
      "Epoch 26: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 89ms/step - loss: 0.2755 - accuracy: 0.8989 - val_loss: 0.9208 - val_accuracy: 0.0435\n",
      "Epoch 27/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2601 - accuracy: 0.9205\n",
      "Epoch 27: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 97ms/step - loss: 0.2580 - accuracy: 0.9213 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
      "Epoch 28/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.9545\n",
      "Epoch 28: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.1435 - accuracy: 0.9551 - val_loss: 0.7251 - val_accuracy: 0.3913\n",
      "Epoch 29/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1263 - accuracy: 0.9432\n",
      "Epoch 29: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1251 - accuracy: 0.9438 - val_loss: 0.5519 - val_accuracy: 1.0000\n",
      "Epoch 30/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1057 - accuracy: 0.9545\n",
      "Epoch 30: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.1045 - accuracy: 0.9551 - val_loss: 0.5345 - val_accuracy: 1.0000\n",
      "Epoch 31/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0846 - accuracy: 0.9773\n",
      "Epoch 31: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.0838 - accuracy: 0.9775 - val_loss: 0.5295 - val_accuracy: 1.0000\n",
      "Epoch 32/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0716 - accuracy: 0.9659\n",
      "Epoch 32: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 90ms/step - loss: 0.0710 - accuracy: 0.9663 - val_loss: 0.6550 - val_accuracy: 0.7391\n",
      "Epoch 33/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1165 - accuracy: 0.9659\n",
      "Epoch 33: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.1152 - accuracy: 0.9663 - val_loss: 1.4089 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.3018 - accuracy: 0.8636\n",
      "Epoch 34: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 96ms/step - loss: 0.2990 - accuracy: 0.8652 - val_loss: 0.6703 - val_accuracy: 0.9565\n",
      "Epoch 35/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.2189 - accuracy: 0.9091\n",
      "Epoch 35: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.2165 - accuracy: 0.9101 - val_loss: 0.5781 - val_accuracy: 1.0000\n",
      "Epoch 36/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1406 - accuracy: 0.9432\n",
      "Epoch 36: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 87ms/step - loss: 0.1390 - accuracy: 0.9438 - val_loss: 0.8253 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0903 - accuracy: 0.9773\n",
      "Epoch 37: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 93ms/step - loss: 0.0893 - accuracy: 0.9775 - val_loss: 0.7444 - val_accuracy: 0.2609\n",
      "Epoch 38/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0940 - accuracy: 0.9659\n",
      "Epoch 38: accuracy did not improve from 0.97753\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.0931 - accuracy: 0.9663 - val_loss: 0.6180 - val_accuracy: 1.0000\n",
      "Epoch 39/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0538 - accuracy: 0.9886\n",
      "Epoch 39: accuracy improved from 0.97753 to 0.98876, saving model to .\\Model_CNN1D_all\n",
      "INFO:tensorflow:Assets written to: .\\Model_CNN1D_all\\assets\n",
      "23/23 [==============================] - 5s 242ms/step - loss: 0.0532 - accuracy: 0.9888 - val_loss: 0.7031 - val_accuracy: 0.4348\n",
      "Epoch 40/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.0719 - accuracy: 0.9886\n",
      "Epoch 40: accuracy did not improve from 0.98876\n",
      "23/23 [==============================] - 2s 98ms/step - loss: 0.0711 - accuracy: 0.9888 - val_loss: 0.6353 - val_accuracy: 0.7826\n",
      "Epoch 41/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1029 - accuracy: 0.9545\n",
      "Epoch 41: accuracy did not improve from 0.98876\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.1019 - accuracy: 0.9551 - val_loss: 0.7830 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/42\n",
      "22/23 [===========================>..] - ETA: 0s - loss: 0.1366 - accuracy: 0.9432\n",
      "Epoch 42: accuracy did not improve from 0.98876\n",
      "23/23 [==============================] - 2s 92ms/step - loss: 0.1351 - accuracy: 0.9438 - val_loss: 0.6848 - val_accuracy: 0.7826\n",
      "\n",
      "\n",
      "==================================== Modele evaluation ====================================\n",
      "6/6 [==============================] - 1s 16ms/step - loss: 0.2604 - accuracy: 0.9167\n",
      "===========================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # CNN Variables\n",
    "    # Première couche du CNN\n",
    "filter_size1 = 5\n",
    "num_filters1 = 64\n",
    "    # Deuxième couche du CNN \n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "\n",
    "batch_size = 4\n",
    "num_channels = fv_train.shape[2] # ! paramètre sur lequel on pourrait jouer si on ajoute les autres capteurs\n",
    "n_epochs = 42\n",
    "signal = fv_train.shape[1]\n",
    "    \n",
    "\n",
    "# CNN\n",
    "path_to_save_model = './Model_CNN1D_all'\n",
    "\n",
    "ckpt_saver = ModelCheckpoint(\n",
    "path_to_save_model,\n",
    "monitor='accuracy', # sur quoi on se base pour voir le meilleur\n",
    "mode = 'max', # max de l'accuracy sur la validation\n",
    "save_best_only = True,\n",
    "save_freq='epoch', # ne voit qu'à la fin de l'époque\n",
    "verbose=1) \n",
    "\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    Input(shape=(signal,num_channels)), # format d'entrée\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size2, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    Conv1D(filters=num_filters1, kernel_size=filter_size1, activation='relu'),\n",
    "    Conv1D(filters=num_filters2, kernel_size=filter_size1, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    #BatchNormalization(),\n",
    "    GlobalAvgPool1D(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "]\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(fv_train, etiq_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=[ckpt_saver])\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"\\n\\n==================================== Modele evaluation ====================================\")\n",
    "model.evaluate(fv_test,etiq_test, batch_size=batch_size)\n",
    "print(\"===========================================================================================\\n\\n\")\n",
    "y_model=model.predict(fv_test)\n",
    "y_model_max = np.argmax(y_model, axis=1)\n",
    "con_mat = tf.math.confusion_matrix(labels=etiq_test, predictions=y_model_max).numpy()\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style='darkgrid')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(con_mat, annot=True)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'avec le SMOTE on n'améliore pas les résultats et donc on va opter pour une autre méthode (on pourrait essayer d'appliquer le SMOTE sur les autres manière d'aborder le projet)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
